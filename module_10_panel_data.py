"""
Laborat√≥rio de Econometria - Module 10: Panel Data
Aplicativo educacional interativo para dados em painel, efeitos fixos/aleat√≥rios e aplica√ß√µes.
P√∫blico-alvo: alunos de MBA com perfis quantitativos heterog√™neos.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy import stats

# =============================================================================
# FUN√á√ïES AUXILIARES PARA SIMULA√á√ÉO E C√ÅLCULOS
# =============================================================================

def make_panel_data(n_entities: int = 10, n_periods: int = 20, beta: float = 0.5,
                    fe_variance: float = 2.0, error_variance: float = 1.0,
                    seed: int = 42) -> pd.DataFrame:
    """
    Gera painel balanceado com efeitos fixos.
    y_it = alpha_i + beta * x_it + epsilon_it
    """
    np.random.seed(seed)
    
    # Efeitos fixos por entidade
    alpha = np.random.normal(0, np.sqrt(fe_variance), n_entities)
    
    data = []
    for i in range(n_entities):
        for t in range(n_periods):
            x = np.random.normal(5, 2)
            epsilon = np.random.normal(0, np.sqrt(error_variance))
            y = alpha[i] + beta * x + epsilon
            
            data.append({
                'entity': f'Banco_{i+1}',
                'entity_id': i,
                'period': t + 1,
                'x': x,
                'y': y,
                'alpha_true': alpha[i]
            })
    
    return pd.DataFrame(data)


def make_unbalanced_panel(n_entities: int = 10, n_periods: int = 20, 
                          missing_prob: float = 0.2, seed: int = 42) -> pd.DataFrame:
    """Gera painel n√£o balanceado com observa√ß√µes faltantes."""
    np.random.seed(seed)
    
    df = make_panel_data(n_entities, n_periods, seed=seed)
    
    # Remover observa√ß√µes aleatoriamente
    mask = np.random.random(len(df)) > missing_prob
    df_unbalanced = df[mask].copy()
    
    return df_unbalanced


def make_sur_data(n_obs: int = 100, rho: float = 0.7, seed: int = 42) -> dict:
    """
    Gera dados para SUR (Seemingly Unrelated Regressions).
    Duas equa√ß√µes com erros correlacionados.
    """
    np.random.seed(seed)
    
    # Regressores
    x1 = np.random.normal(0, 1, n_obs)
    x2 = np.random.normal(0, 1, n_obs)
    
    # Erros correlacionados
    e1 = np.random.normal(0, 1, n_obs)
    e2 = rho * e1 + np.sqrt(1 - rho**2) * np.random.normal(0, 1, n_obs)
    
    # Equa√ß√µes
    y1 = 2 + 1.5 * x1 + e1  # Equa√ß√£o 1
    y2 = 1 + 0.8 * x2 + e2  # Equa√ß√£o 2
    
    return {
        'y1': y1, 'y2': y2,
        'x1': x1, 'x2': x2,
        'e1': e1, 'e2': e2,
        'rho_true': rho
    }


def fit_ols_simple(y: np.ndarray, X: np.ndarray) -> dict:
    """OLS simples."""
    n = len(y)
    k = X.shape[1]
    
    XtX_inv = np.linalg.inv(X.T @ X)
    beta = XtX_inv @ X.T @ y
    
    y_hat = X @ beta
    residuals = y - y_hat
    
    sse = np.sum(residuals**2)
    sst = np.sum((y - np.mean(y))**2)
    r_squared = 1 - sse / sst
    
    s2 = sse / (n - k)
    se = np.sqrt(s2 * np.diag(XtX_inv))
    
    return {
        'beta': beta,
        'se': se,
        'r_squared': r_squared,
        'residuals': residuals,
        'y_hat': y_hat,
        's2': s2
    }


def fit_pooled_ols(df: pd.DataFrame) -> dict:
    """Pooled OLS (ignora estrutura de painel)."""
    y = df['y'].values
    X = np.column_stack([np.ones(len(df)), df['x'].values])
    
    result = fit_ols_simple(y, X)
    
    return {
        'intercept': result['beta'][0],
        'beta': result['beta'][1],
        'se_beta': result['se'][1],
        'r_squared': result['r_squared'],
        'residuals': result['residuals']
    }


def fit_fe_simple(df: pd.DataFrame) -> dict:
    """
    Efeitos Fixos via transforma√ß√£o Within.
    Remove a m√©dia de cada entidade.
    """
    # Calcular m√©dias por entidade
    entity_means = df.groupby('entity_id')[['y', 'x']].transform('mean')
    
    # Transforma√ß√£o within
    y_within = df['y'].values - entity_means['y'].values
    x_within = df['x'].values - entity_means['x'].values
    
    # OLS sem intercepto
    X = x_within.reshape(-1, 1)
    y = y_within
    
    beta = np.sum(x_within * y_within) / np.sum(x_within**2)
    
    # Res√≠duos e R¬≤
    y_hat = beta * x_within
    residuals = y_within - y_hat
    
    sse = np.sum(residuals**2)
    sst = np.sum(y_within**2)
    r_squared_within = 1 - sse / sst if sst > 0 else 0
    
    # Erro padr√£o
    n = len(df)
    n_entities = df['entity_id'].nunique()
    k = 1
    dof = n - n_entities - k
    s2 = sse / dof if dof > 0 else sse / n
    se_beta = np.sqrt(s2 / np.sum(x_within**2))
    
    # Estimar efeitos fixos
    y_means = df.groupby('entity_id')['y'].mean()
    x_means = df.groupby('entity_id')['x'].mean()
    alphas = y_means - beta * x_means
    
    return {
        'beta': beta,
        'se_beta': se_beta,
        'r_squared_within': r_squared_within,
        'alphas': alphas.values,
        'residuals': residuals,
        'n_entities': n_entities
    }


def fit_re_simple(df: pd.DataFrame) -> dict:
    """
    Efeitos Aleat√≥rios via GLS simplificado.
    Usa transforma√ß√£o parcial baseada em theta.
    """
    n = len(df)
    n_entities = df['entity_id'].nunique()
    T_avg = n / n_entities
    
    # Primeiro estimar FE para obter sigma¬≤_epsilon
    fe = fit_fe_simple(df)
    sigma2_epsilon = np.var(fe['residuals'])
    
    # Estimar sigma¬≤_alpha (entre entidades)
    entity_means = df.groupby('entity_id')['y'].mean()
    sigma2_between = np.var(entity_means)
    sigma2_alpha = max(sigma2_between - sigma2_epsilon / T_avg, 0.001)
    
    # Theta para transforma√ß√£o
    theta = 1 - np.sqrt(sigma2_epsilon / (sigma2_epsilon + T_avg * sigma2_alpha))
    
    # Transforma√ß√£o parcial
    entity_means_y = df.groupby('entity_id')['y'].transform('mean')
    entity_means_x = df.groupby('entity_id')['x'].transform('mean')
    
    y_re = df['y'].values - theta * entity_means_y.values
    x_re = df['x'].values - theta * entity_means_x.values
    
    # OLS na vari√°vel transformada
    X = np.column_stack([np.ones(n) * (1 - theta), x_re])
    result = fit_ols_simple(y_re, X)
    
    return {
        'intercept': result['beta'][0],
        'beta': result['beta'][1],
        'se_beta': result['se'][1],
        'r_squared': result['r_squared'],
        'theta': theta,
        'sigma2_alpha': sigma2_alpha,
        'sigma2_epsilon': sigma2_epsilon,
        'residuals': result['residuals']
    }


def hausman_test_simple(df: pd.DataFrame) -> dict:
    """
    Teste de Hausman: FE vs RE.
    H0: RE √© consistente e eficiente (prefer√≠vel)
    H1: RE √© inconsistente (usar FE)
    """
    fe = fit_fe_simple(df)
    re = fit_re_simple(df)
    
    # Diferen√ßa entre coeficientes
    diff = fe['beta'] - re['beta']
    
    # Vari√¢ncia da diferen√ßa (simplificado)
    var_diff = fe['se_beta']**2 - re['se_beta']**2
    var_diff = max(var_diff, 0.0001)  # Garantir positivo
    
    # Estat√≠stica de Hausman
    H = diff**2 / var_diff
    
    # P-valor (chi-quadrado com 1 gl)
    p_value = 1 - stats.chi2.cdf(H, 1)
    
    return {
        'H_stat': H,
        'p_value': p_value,
        'beta_fe': fe['beta'],
        'beta_re': re['beta'],
        'diff': diff,
        'recommendation': 'FE' if p_value < 0.05 else 'RE'
    }


def fit_sur_simple(data: dict) -> dict:
    """
    SUR simplificado: estima equa√ß√µes considerando correla√ß√£o de erros.
    Na pr√°tica, usa OLS em cada equa√ß√£o e reporta correla√ß√£o residual.
    """
    # OLS em cada equa√ß√£o
    X1 = np.column_stack([np.ones(len(data['y1'])), data['x1']])
    X2 = np.column_stack([np.ones(len(data['y2'])), data['x2']])
    
    ols1 = fit_ols_simple(data['y1'], X1)
    ols2 = fit_ols_simple(data['y2'], X2)
    
    # Correla√ß√£o entre res√≠duos
    rho_estimated = np.corrcoef(ols1['residuals'], ols2['residuals'])[0, 1]
    
    return {
        'beta1': ols1['beta'],
        'beta2': ols2['beta'],
        'se1': ols1['se'],
        'se2': ols2['se'],
        'r2_eq1': ols1['r_squared'],
        'r2_eq2': ols2['r_squared'],
        'rho_residuals': rho_estimated,
        'residuals1': ols1['residuals'],
        'residuals2': ols2['residuals']
    }


def panel_unit_root_test_simple(df: pd.DataFrame, variable: str = 'y') -> dict:
    """
    Teste de raiz unit√°ria em painel simplificado (tipo LLC).
    Testa se a vari√°vel √© estacion√°ria no painel.
    """
    entities = df['entity_id'].unique()
    adf_stats = []
    
    for entity in entities:
        entity_data = df[df['entity_id'] == entity][variable].values
        if len(entity_data) > 10:
            # ADF simplificado para cada entidade
            dy = np.diff(entity_data)
            y_lag = entity_data[:-1]
            
            if len(dy) > 2:
                X = np.column_stack([np.ones(len(dy)), y_lag])
                try:
                    result = fit_ols_simple(dy, X)
                    t_stat = result['beta'][1] / result['se'][1]
                    adf_stats.append(t_stat)
                except:
                    pass
    
    if len(adf_stats) > 0:
        # M√©dia das estat√≠sticas (LLC-type)
        avg_stat = np.mean(adf_stats)
        # P-valor aproximado
        p_value = stats.norm.cdf(avg_stat)
    else:
        avg_stat = 0
        p_value = 0.5
    
    return {
        'avg_stat': avg_stat,
        'p_value': p_value,
        'n_entities': len(adf_stats),
        'individual_stats': adf_stats
    }


def panel_cointegration_test_simple(df: pd.DataFrame) -> dict:
    """
    Teste de cointegra√ß√£o em painel simplificado.
    Testa se y e x s√£o cointegrados no painel.
    """
    # Estimar rela√ß√£o de longo prazo por entidade
    entities = df['entity_id'].unique()
    residuals_all = []
    
    for entity in entities:
        entity_data = df[df['entity_id'] == entity]
        if len(entity_data) > 5:
            X = np.column_stack([np.ones(len(entity_data)), entity_data['x'].values])
            result = fit_ols_simple(entity_data['y'].values, X)
            residuals_all.extend(result['residuals'])
    
    residuals_all = np.array(residuals_all)
    
    # Testar estacionaridade dos res√≠duos
    if len(residuals_all) > 20:
        dy = np.diff(residuals_all)
        y_lag = residuals_all[:-1]
        X = np.column_stack([np.ones(len(dy)), y_lag])
        result = fit_ols_simple(dy, X)
        t_stat = result['beta'][1] / result['se'][1]
        
        # Valores cr√≠ticos aproximados para painel
        critical_5 = -1.95
        p_value = stats.norm.cdf(t_stat)
    else:
        t_stat = 0
        p_value = 0.5
        critical_5 = -1.95
    
    return {
        't_stat': t_stat,
        'p_value': p_value,
        'critical_5': critical_5,
        'cointegrated': t_stat < critical_5
    }


def make_banking_case_data(n_banks: int = 15, n_years: int = 10, seed: int = 42) -> pd.DataFrame:
    """Gera dados sint√©ticos de bancos para estudo de caso."""
    np.random.seed(seed)
    
    data = []
    
    for i in range(n_banks):
        # Caracter√≠sticas fixas do banco
        size_effect = np.random.normal(0, 1)
        efficiency = np.random.uniform(0.7, 1.0)
        
        for t in range(n_years):
            # Vari√°veis que mudam no tempo
            market_share = np.random.uniform(0.02, 0.15) + 0.001 * t
            cost_income = np.random.uniform(0.4, 0.7) - 0.005 * efficiency
            credit_growth = np.random.normal(0.08, 0.05)
            npl_ratio = np.random.uniform(0.02, 0.08)
            
            # ROE como vari√°vel dependente
            roe = (0.05 + 0.1 * market_share - 0.15 * cost_income 
                   + 0.02 * credit_growth - 0.3 * npl_ratio 
                   + 0.02 * size_effect + np.random.normal(0, 0.02))
            
            data.append({
                'banco': f'Banco_{chr(65+i)}',
                'banco_id': i,
                'ano': 2014 + t,
                'roe': roe * 100,  # Em %
                'market_share': market_share * 100,
                'cost_income': cost_income * 100,
                'credit_growth': credit_growth * 100,
                'npl_ratio': npl_ratio * 100,
                'size_effect': size_effect
            })
    
    return pd.DataFrame(data)


def make_credit_case_data(n_countries: int = 20, n_years: int = 15, seed: int = 42) -> pd.DataFrame:
    """Gera dados sint√©ticos de cr√©dito e crescimento para estudo de caso."""
    np.random.seed(seed)
    
    data = []
    
    for i in range(n_countries):
        # Efeito fixo do pa√≠s
        country_effect = np.random.normal(0, 0.5)
        base_gdp = np.random.uniform(8, 12)  # Log do PIB inicial
        
        gdp = base_gdp
        credit = base_gdp - 1  # Cr√©dito como % do PIB (em log)
        
        for t in range(n_years):
            # Crescimento
            gdp_growth = 0.02 + 0.01 * country_effect + np.random.normal(0, 0.02)
            credit_growth = gdp_growth + 0.005 + np.random.normal(0, 0.03)
            
            # Crise em alguns anos
            if t in [5, 6] and i < n_countries // 2:
                gdp_growth -= 0.03
                credit_growth -= 0.05
            
            gdp += gdp_growth
            credit += credit_growth
            
            data.append({
                'pais': f'Pa√≠s_{i+1}',
                'pais_id': i,
                'ano': 2005 + t,
                'log_gdp': gdp,
                'log_credit': credit,
                'gdp_growth': gdp_growth * 100,
                'credit_gdp_ratio': np.exp(credit - gdp) * 100,
                'country_effect': country_effect
            })
    
    return pd.DataFrame(data)


# =============================================================================
# FUN√á√ïES DE RENDERIZA√á√ÉO POR SE√á√ÉO
# =============================================================================

def render_section_S1():
    """S1: Introdu√ß√£o aos Dados em Painel"""
    st.header("üìä Introdu√ß√£o aos Dados em Painel")
    
    st.markdown("""
    **Dados em painel** combinam duas dimens√µes:
    - **Cross-section:** M√∫ltiplas unidades (empresas, pa√≠ses, pessoas)
    - **S√©ries temporais:** Observa√ß√µes ao longo do tempo
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("O que √© um Painel?")
        
        st.markdown("""
        **Defini√ß√£o:**
        > Observa√ß√µes repetidas das **mesmas entidades** ao longo do **tempo**.
        
        **Exemplos:**
        - 50 bancos observados por 10 anos
        - 100 pa√≠ses medidos trimestralmente por 20 anos
        - 1000 funcion√°rios avaliados mensalmente por 5 anos
        
        **Nota√ß√£o:**
        - i = entidade (1, 2, ..., N)
        - t = tempo (1, 2, ..., T)
        - y_it = valor de y para entidade i no tempo t
        """)
    
    with col2:
        st.subheader("Compara√ß√£o Visual")
        
        # Criar dados para visualiza√ß√£o
        fig = make_subplots(rows=1, cols=3, 
                           subplot_titles=["Cross-Section", "S√©rie Temporal", "Painel"])
        
        # Cross-section: v√°rias entidades, um per√≠odo
        np.random.seed(42)
        entities_cs = [f'E{i}' for i in range(1, 8)]
        values_cs = np.random.normal(10, 2, 7)
        fig.add_trace(go.Bar(x=entities_cs, y=values_cs, marker_color='steelblue'), 
                     row=1, col=1)
        
        # S√©rie temporal: uma entidade, v√°rios per√≠odos
        time_ts = list(range(1, 8))
        values_ts = np.cumsum(np.random.normal(0.5, 1, 7)) + 10
        fig.add_trace(go.Scatter(x=time_ts, y=values_ts, mode='lines+markers',
                                line=dict(color='steelblue')), row=1, col=2)
        
        # Painel: v√°rias entidades, v√°rios per√≠odos
        for i in range(3):
            values_panel = np.cumsum(np.random.normal(0.3, 0.8, 7)) + 8 + i*2
            fig.add_trace(go.Scatter(x=time_ts, y=values_panel, mode='lines+markers',
                                    name=f'Entidade {i+1}'), row=1, col=3)
        
        fig.update_layout(height=300, showlegend=False)
        fig.update_xaxes(title_text="Entidade", row=1, col=1)
        fig.update_xaxes(title_text="Tempo", row=1, col=2)
        fig.update_xaxes(title_text="Tempo", row=1, col=3)
        st.plotly_chart(fig, use_container_width=True)
    
    st.subheader("Quando Pain√©is Resolvem Problemas?")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **üîç Heterogeneidade n√£o observada**
        
        Cada banco tem caracter√≠sticas pr√≥prias (cultura, gest√£o) dif√≠ceis de medir.
        
        Painel: Controla via efeitos fixos.
        """)
    
    with col2:
        st.markdown("""
        **üìà Din√¢mica temporal**
        
        Decis√µes de hoje afetam resultados de amanh√£.
        
        Painel: Captura ajustamentos ao longo do tempo.
        """)
    
    with col3:
        st.markdown("""
        **üí™ Mais poder estat√≠stico**
        
        Cross-section: N observa√ß√µes
        S√©rie: T observa√ß√µes
        
        Painel: N √ó T observa√ß√µes!
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa pain√©is quando quer comparar unidades ao longo do tempo
    - Controla para caracter√≠sticas fixas de cada unidade
    - Aumenta confian√ßa nas conclus√µes causais
    """)


def render_section_S2():
    """S2: Vantagens Gerenciais dos Pain√©is"""
    st.header("üí™ Vantagens dos Dados em Painel")
    
    st.markdown("""
    Por que pain√©is s√£o t√£o poderosos para an√°lise gerencial?
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Vantagem 1: Mais Dados")
        
        n_entities = st.slider("N√∫mero de bancos", 5, 30, 15, key="n_ent_v")
        n_periods = st.slider("N√∫mero de anos", 3, 20, 10, key="n_per_v")
        
        st.markdown(f"""
        **Cross-section:** {n_entities} observa√ß√µes
        
        **S√©rie temporal:** {n_periods} observa√ß√µes
        
        **Painel:** {n_entities} √ó {n_periods} = **{n_entities * n_periods}** observa√ß√µes
        
        Mais dados = menor vari√¢ncia = estimativas mais precisas!
        """)
    
    with col2:
        # Visualizar aumento de dados
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=['Cross-Section', 'S√©rie Temporal', 'Painel'],
            y=[n_entities, n_periods, n_entities * n_periods],
            marker_color=['steelblue', 'orange', 'green']
        ))
        
        fig.update_layout(
            title="N√∫mero de Observa√ß√µes",
            yaxis_title="N",
            height=300
        )
        st.plotly_chart(fig, use_container_width=True, key=f"vant_{n_entities}_{n_periods}")
    
    st.subheader("Vantagem 2: Controle de Vari√°vel Omitida")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        **O problema cl√°ssico:**
        
        Queremos estimar: ROE = Œ≤‚ÇÄ + Œ≤‚ÇÅ √ó Cr√©dito + Œµ
        
        Mas "qualidade da gest√£o" afeta tanto Cr√©dito quanto ROE!
        
        **Cross-section:** Vi√©s de vari√°vel omitida
        
        **Painel com efeitos fixos:** Cada banco tem seu intercepto pr√≥prio (Œ±_i), 
        que absorve a qualidade de gest√£o (constante no tempo).
        """)
    
    with col2:
        # Simular vi√©s
        np.random.seed(42)
        n = 50
        
        # Qualidade de gest√£o (n√£o observada)
        quality = np.random.normal(0, 1, n)
        
        # Cr√©dito correlacionado com qualidade
        credit = 5 + 2 * quality + np.random.normal(0, 1, n)
        
        # ROE depende de cr√©dito E qualidade
        roe = 10 + 0.5 * credit + 3 * quality + np.random.normal(0, 1, n)
        
        # OLS viesado
        X = np.column_stack([np.ones(n), credit])
        result = fit_ols_simple(roe, X)
        beta_biased = result['beta'][1]
        
        st.metric("Œ≤ verdadeiro (Cr√©dito ‚Üí ROE)", "0.50")
        st.metric("Œ≤ OLS (vi√©s de var. omitida)", f"{beta_biased:.2f}",
                 delta=f"Vi√©s: {beta_biased - 0.5:.2f}")
        
        st.warning("‚ö†Ô∏è OLS superestima o efeito porque captura parte do efeito de 'qualidade'!")
    
    with st.expander("üìñ Como FE resolve o vi√©s?"):
        st.markdown("""
        **Efeitos Fixos eliminam varia√ß√£o entre entidades:**
        
        Transforma√ß√£o Within:
        $$y_{it} - \\bar{y}_i = \\beta (x_{it} - \\bar{x}_i) + (\\varepsilon_{it} - \\bar{\\varepsilon}_i)$$
        
        - O efeito fixo Œ±_i (incluindo qualidade de gest√£o) **some na transforma√ß√£o**
        - Usamos apenas varia√ß√£o **dentro** de cada entidade ao longo do tempo
        - Se qualidade √© constante, n√£o confunde mais o efeito de cr√©dito
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa pain√©is para isolar efeitos de vari√°veis de interesse
    - Reconhece que cross-section pode ter vi√©s de sele√ß√£o
    - Prefere an√°lises que controlem por caracter√≠sticas fixas
    """)


def render_section_S3():
    """S3: Estrutura dos Dados: Balanceado vs N√£o Balanceado"""
    st.header("üìã Estrutura: Balanceado vs N√£o Balanceado")
    
    st.markdown("""
    Na pr√°tica, pain√©is raramente s√£o perfeitamente completos.
    """)
    
    tab1, tab2 = st.tabs(["üìä Painel Balanceado", "üî≤ Painel N√£o Balanceado"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Painel Balanceado")
            
            st.markdown("""
            **Defini√ß√£o:** Todas as entidades observadas em todos os per√≠odos.
            
            **Estrutura:**
            - N entidades √ó T per√≠odos = N√óT observa√ß√µes
            - Sem dados faltantes
            - Estima√ß√£o mais simples
            
            **Quando ocorre:**
            - Pesquisas controladas
            - Dados administrativos completos
            - S√©ries financeiras padronizadas
            """)
            
            n_ent = st.slider("Entidades", 3, 10, 5, key="n_ent_bal")
            n_per = st.slider("Per√≠odos", 3, 8, 4, key="n_per_bal")
        
        with col2:
            # Gerar painel balanceado
            df_bal = make_panel_data(n_entities=n_ent, n_periods=n_per, seed=42)
            
            # Criar matriz visual
            pivot = df_bal.pivot(index='entity', columns='period', values='y')
            
            fig = px.imshow(pivot.notna().astype(int), 
                           labels=dict(x="Per√≠odo", y="Entidade", color="Observado"),
                           color_continuous_scale=['white', 'steelblue'],
                           aspect='auto')
            fig.update_layout(title="Matriz de Observa√ß√µes (Balanceado)", height=300)
            st.plotly_chart(fig, use_container_width=True)
            
            st.metric("Total de observa√ß√µes", f"{len(df_bal)}")
            st.metric("Completude", "100%")
    
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Painel N√£o Balanceado")
            
            st.markdown("""
            **Defini√ß√£o:** Algumas observa√ß√µes faltantes.
            
            **Causas comuns:**
            - Entrada/sa√≠da de entidades (fus√µes, fal√™ncias)
            - Dados n√£o reportados
            - Mudan√ßas de amostragem
            
            **Implica√ß√µes:**
            - Estima√ß√£o ainda poss√≠vel (com ajustes)
            - Verificar se missings s√£o aleat√≥rios
            - Pode indicar vi√©s de sobreviv√™ncia
            """)
            
            missing_prob = st.slider("Prob. de missing", 0.0, 0.5, 0.2, 0.05, key="miss_prob")
        
        with col2:
            # Gerar painel n√£o balanceado
            df_unbal = make_unbalanced_panel(n_entities=n_ent, n_periods=n_per, 
                                            missing_prob=missing_prob, seed=42)
            
            # Recriar piv√¥
            df_full = make_panel_data(n_entities=n_ent, n_periods=n_per, seed=42)
            df_full['observed'] = 0
            
            for _, row in df_unbal.iterrows():
                mask = (df_full['entity'] == row['entity']) & (df_full['period'] == row['period'])
                df_full.loc[mask, 'observed'] = 1
            
            pivot_unbal = df_full.pivot(index='entity', columns='period', values='observed')
            
            fig = px.imshow(pivot_unbal, 
                           labels=dict(x="Per√≠odo", y="Entidade", color="Observado"),
                           color_continuous_scale=['white', 'steelblue'],
                           aspect='auto')
            fig.update_layout(title="Matriz de Observa√ß√µes (N√£o Balanceado)", height=300)
            st.plotly_chart(fig, use_container_width=True, key=f"unbal_{missing_prob}")
            
            completude = len(df_unbal) / len(df_full) * 100
            st.metric("Total de observa√ß√µes", f"{len(df_unbal)}")
            st.metric("Completude", f"{completude:.1f}%")
    
    with st.expander("‚ö†Ô∏è Cuidado: Vi√©s de Sobreviv√™ncia"):
        st.markdown("""
        **Se missings n√£o s√£o aleat√≥rios:**
        
        - Bancos que faliram saem da amostra ‚Üí superestima rentabilidade
        - Empresas que param de reportar ‚Üí amostra enviesada
        - Pa√≠ses em crise com dados atrasados ‚Üí subestima efeito de crises
        
        **Solu√ß√µes:**
        - Verificar padr√£o de missings
        - Testar se missings s√£o aleat√≥rios (MCAR, MAR, MNAR)
        - Usar m√©todos robustos (imputa√ß√£o, Heckman)
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Sempre verifica completude do painel
    - Investiga motivos de observa√ß√µes faltantes
    - Considera vi√©s de sobreviv√™ncia nas conclus√µes
    """)


def render_section_S4():
    """S4: Regress√µes SUR: Erros que Conversam"""
    st.header("üîó SUR: Seemingly Unrelated Regressions")
    
    st.markdown("""
    **SUR** modela sistemas de equa√ß√µes onde os erros s√£o correlacionados entre equa√ß√µes.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Intui√ß√£o")
        
        st.markdown("""
        **Cen√°rio:** Dois bancos concorrentes no mesmo mercado.
        
        - Equa√ß√£o 1: Fluxo_A = Œ±‚ÇÅ + Œ≤‚ÇÅ√óTaxa_A + Œµ‚ÇÅ
        - Equa√ß√£o 2: Fluxo_B = Œ±‚ÇÇ + Œ≤‚ÇÇ√óTaxa_B + Œµ‚ÇÇ
        
        **O que conecta as equa√ß√µes?**
        
        Um choque no mercado (crise, regula√ß√£o) afeta **ambos** os bancos simultaneamente!
        
        ‚Üí Corr(Œµ‚ÇÅ, Œµ‚ÇÇ) ‚â† 0
        
        **SUR aproveita essa informa√ß√£o:**
        - Estima equa√ß√µes conjuntamente
        - Ganha efici√™ncia (erros padr√£o menores)
        """)
        
        rho = st.slider("Correla√ß√£o entre erros (œÅ)", 0.0, 0.95, 0.7, 0.05, key="rho_sur")
    
    with col2:
        # Gerar dados SUR
        data = make_sur_data(n_obs=100, rho=rho, seed=42)
        
        # Estimar
        sur = fit_sur_simple(data)
        
        st.markdown("**Resultado SUR:**")
        
        col_m1, col_m2 = st.columns(2)
        col_m1.metric("œÅ verdadeiro", f"{data['rho_true']:.2f}")
        col_m2.metric("œÅ estimado (res√≠duos)", f"{sur['rho_residuals']:.2f}")
        
        # Scatter de res√≠duos
        fig = px.scatter(x=sur['residuals1'], y=sur['residuals2'], opacity=0.5,
                        labels={'x': 'Res√≠duos Eq. 1', 'y': 'Res√≠duos Eq. 2'})
        
        # Linha de tend√™ncia
        z = np.polyfit(sur['residuals1'], sur['residuals2'], 1)
        x_line = np.linspace(sur['residuals1'].min(), sur['residuals1'].max(), 50)
        fig.add_trace(go.Scatter(x=x_line, y=z[0]*x_line + z[1], mode='lines',
                                line=dict(color='red', dash='dash'), name='Tend√™ncia'))
        
        fig.update_layout(title="Correla√ß√£o entre Res√≠duos", height=350)
        st.plotly_chart(fig, use_container_width=True, key=f"sur_{rho}")
    
    with st.expander("üìñ Quando SUR agrega valor?"):
        st.markdown("""
        **SUR √© √∫til quando:**
        1. Equa√ß√µes t√™m erros correlacionados
        2. Regressores s√£o diferentes entre equa√ß√µes
        
        **Se regressores s√£o iguais:** SUR = OLS equa√ß√£o por equa√ß√£o
        
        **Ganho de efici√™ncia:**
        - Maior quando œÅ √© alto e regressores s√£o diferentes
        - Menor quando œÅ √© baixo ou regressores s√£o iguais
        
        **Aplica√ß√µes em finan√ßas:**
        - Retornos de ativos do mesmo setor
        - Bancos no mesmo mercado
        - Subsidi√°rias do mesmo grupo
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Reconhece quando choques afetam m√∫ltiplas unidades
    - Usa SUR para estima√ß√£o mais eficiente
    - Interpreta correla√ß√£o de erros como exposi√ß√£o comum
    """)


def render_section_S5():
    """S5: Efeitos Fixos vs Aleat√≥rios"""
    st.header("‚öñÔ∏è Efeitos Fixos vs Aleat√≥rios")
    
    st.markdown("""
    Os dois principais modelos para pain√©is diferem em como tratam a heterogeneidade entre entidades.
    """)
    
    tab1, tab2 = st.tabs(["üîí Efeitos Fixos (FE)", "üé≤ Efeitos Aleat√≥rios (RE)"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Efeitos Fixos (FE)")
            
            st.markdown("""
            **Intui√ß√£o:**
            > "Cada entidade tem sua pr√≥pria linha de base"
            
            **Modelo:**
            $$y_{it} = \\alpha_i + \\beta x_{it} + \\varepsilon_{it}$$
            
            - Œ±_i = intercepto espec√≠fico da entidade i
            - Captura tudo que √© constante no tempo
            - Pode ser correlacionado com x_it
            
            **Quando usar:**
            - Interesse em efeito **dentro** das entidades
            - Œ±_i pode estar correlacionado com regressores
            - Amostra √© a popula√ß√£o de interesse
            """)
        
        with col2:
            # Visualiza√ß√£o FE
            np.random.seed(42)
            n_ent = 4
            n_per = 15
            
            fig = go.Figure()
            
            for i in range(n_ent):
                alpha = 5 + i * 3  # Interceptos diferentes
                x = np.linspace(0, 10, n_per) + np.random.normal(0, 0.5, n_per)
                y = alpha + 0.5 * x + np.random.normal(0, 0.5, n_per)
                
                fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name=f'Entidade {i+1}'))
                
                # Linha de regress√£o para cada entidade
                x_line = np.linspace(x.min(), x.max(), 10)
                fig.add_trace(go.Scatter(x=x_line, y=alpha + 0.5 * x_line, 
                                        mode='lines', line=dict(dash='dash'),
                                        showlegend=False))
            
            fig.update_layout(title="FE: Interceptos Diferentes, Mesma Inclina√ß√£o",
                             xaxis_title="X", yaxis_title="Y", height=350)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Efeitos Aleat√≥rios (RE)")
            
            st.markdown("""
            **Intui√ß√£o:**
            > "Entidades s√£o sorteios aleat√≥rios de uma popula√ß√£o maior"
            
            **Modelo:**
            $$y_{it} = \\alpha + u_i + \\beta x_{it} + \\varepsilon_{it}$$
            
            - u_i ~ N(0, œÉ¬≤_u) = componente aleat√≥rio
            - u_i **n√£o pode** estar correlacionado com x_it
            - Usa informa√ß√£o entre E dentro das entidades
            
            **Quando usar:**
            - Entidades s√£o amostra de popula√ß√£o maior
            - u_i n√£o correlacionado com regressores
            - Interesse em efeito m√©dio da popula√ß√£o
            """)
        
        with col2:
            # Visualiza√ß√£o RE
            fig = go.Figure()
            
            alpha_comum = 10
            for i in range(n_ent):
                u = np.random.normal(0, 2)  # Efeito aleat√≥rio
                x = np.linspace(0, 10, n_per) + np.random.normal(0, 0.5, n_per)
                y = alpha_comum + u + 0.5 * x + np.random.normal(0, 0.5, n_per)
                
                fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name=f'Entidade {i+1}'))
            
            # Linha de regress√£o m√©dia
            x_line = np.linspace(0, 12, 50)
            fig.add_trace(go.Scatter(x=x_line, y=alpha_comum + 0.5 * x_line, 
                                    mode='lines', line=dict(color='black', width=2),
                                    name='M√©dia Populacional'))
            
            fig.update_layout(title="RE: Varia√ß√£o em Torno da M√©dia Populacional",
                             xaxis_title="X", yaxis_title="Y", height=350)
            st.plotly_chart(fig, use_container_width=True)
    
    # Compara√ß√£o com dados
    st.subheader("Exemplo: Produtividade Banc√°ria")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        fe_variance = st.slider("Vari√¢ncia dos efeitos fixos", 0.5, 5.0, 2.0, 0.5, key="fe_var")
        
        df = make_panel_data(n_entities=10, n_periods=15, beta=0.5, 
                            fe_variance=fe_variance, seed=42)
        
        # Estimar ambos
        pooled = fit_pooled_ols(df)
        fe = fit_fe_simple(df)
        re = fit_re_simple(df)
        
        st.markdown("**Œ≤ verdadeiro:** 0.50")
    
    with col2:
        results_df = pd.DataFrame({
            'Modelo': ['Pooled OLS', 'Efeitos Fixos', 'Efeitos Aleat√≥rios'],
            'Œ≤ estimado': [f"{pooled['beta']:.3f}", f"{fe['beta']:.3f}", f"{re['beta']:.3f}"],
            'Erro Padr√£o': [f"{pooled['se_beta']:.3f}", f"{fe['se_beta']:.3f}", f"{re['se_beta']:.3f}"]
        })
        st.dataframe(results_df, use_container_width=True, hide_index=True)
        
        st.info(f"""
        üí° **Observa√ß√£o:** Com vari√¢ncia de FE = {fe_variance:.1f}:
        - Pooled OLS pode estar enviesado se Œ±_i correlacionado com x
        - FE controla para diferen√ßas entre bancos
        - RE √© mais eficiente se suposi√ß√µes v√°lidas
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - FE: Quando quer controlar para caracter√≠sticas fixas de cada unidade
    - RE: Quando interesse √© em generalizar para popula√ß√£o maior
    - Usa Hausman para decidir (pr√≥xima se√ß√£o!)
    """)


def render_section_S6():
    """S6: Escolha do Modelo: Teste de Hausman"""
    st.header("üß™ Teste de Hausman: FE ou RE?")
    
    st.markdown("""
    O **teste de Hausman** ajuda a escolher entre Efeitos Fixos e Aleat√≥rios.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("L√≥gica do Teste")
        
        st.markdown("""
        **A pergunta-chave:**
        > "Os efeitos individuais est√£o correlacionados com as vari√°veis explicativas?"
        
        **Hip√≥teses:**
        - H‚ÇÄ: Corr(u_i, x_it) = 0 ‚Üí RE √© consistente E eficiente
        - H‚ÇÅ: Corr(u_i, x_it) ‚â† 0 ‚Üí RE √© inconsistente (usar FE)
        
        **Estat√≠stica:**
        $$H = (\\beta_{FE} - \\beta_{RE})' [Var(\\beta_{FE}) - Var(\\beta_{RE})]^{-1} (\\beta_{FE} - \\beta_{RE})$$
        
        **Decis√£o:**
        - H grande (p < 0.05): Rejeita H‚ÇÄ ‚Üí Use FE
        - H pequeno (p ‚â• 0.05): N√£o rejeita H‚ÇÄ ‚Üí Use RE
        """)
        
        st.subheader("Trade-off")
        
        st.markdown("""
        | Crit√©rio | FE | RE |
        |----------|-----|-----|
        | Consist√™ncia | Sempre ‚úì | S√≥ se H‚ÇÄ ‚úì |
        | Efici√™ncia | Menor | Maior |
        | Usa info between | N√£o | Sim |
        """)
    
    with col2:
        st.subheader("Simula√ß√£o Interativa")
        
        correlation = st.slider("Correla√ß√£o Œ±_i com x", 0.0, 0.8, 0.4, 0.1, key="corr_hausman")
        
        # Gerar dados com correla√ß√£o controlada
        np.random.seed(42)
        n_entities = 15
        n_periods = 10
        
        # Efeitos fixos
        alpha = np.random.normal(0, 2, n_entities)
        
        data = []
        for i in range(n_entities):
            for t in range(n_periods):
                # X correlacionado com alpha_i
                x = 5 + correlation * alpha[i] + np.random.normal(0, 1)
                epsilon = np.random.normal(0, 1)
                y = alpha[i] + 0.5 * x + epsilon
                
                data.append({
                    'entity_id': i,
                    'entity': f'E_{i}',
                    'period': t,
                    'x': x,
                    'y': y
                })
        
        df = pd.DataFrame(data)
        
        # Teste de Hausman
        hausman = hausman_test_simple(df)
        
        col_m1, col_m2 = st.columns(2)
        col_m1.metric("Estat√≠stica H", f"{hausman['H_stat']:.2f}")
        col_m2.metric("p-valor", f"{hausman['p_value']:.4f}")
        
        st.metric("Œ≤ (FE)", f"{hausman['beta_fe']:.3f}")
        st.metric("Œ≤ (RE)", f"{hausman['beta_re']:.3f}")
        
        if hausman['p_value'] < 0.05:
            st.error(f"üî¥ **Recomenda√ß√£o: Use EFEITOS FIXOS**\n\np < 0.05 ‚Üí Rejeita H‚ÇÄ ‚Üí RE inconsistente")
        else:
            st.success(f"üü¢ **Recomenda√ß√£o: Use EFEITOS ALEAT√ìRIOS**\n\np ‚â• 0.05 ‚Üí N√£o rejeita H‚ÇÄ ‚Üí RE √© prefer√≠vel")
    
    # Quiz
    st.subheader("üß™ Quiz")
    
    st.markdown("""
    Um pesquisador estima um modelo de painel para 50 empresas em 10 anos.
    O teste de Hausman d√° H = 15.3, p-valor = 0.001.
    """)
    
    resposta = st.radio(
        "Qual modelo deve usar?",
        ["Efeitos Aleat√≥rios (mais eficiente)",
         "Efeitos Fixos (mais consistente)",
         "Pooled OLS (mais simples)"],
        key="quiz_hausman"
    )
    
    if st.button("Ver resposta", key="btn_hausman"):
        if resposta == "Efeitos Fixos (mais consistente)":
            st.success("""
            ‚úÖ **Correto!**
            
            p = 0.001 < 0.05 ‚Üí Rejeita H‚ÇÄ
            
            H√° evid√™ncia de correla√ß√£o entre efeitos individuais e regressores.
            RE seria inconsistente. FE √© a escolha segura.
            """)
        else:
            st.error("Com p < 0.05, rejeitamos H‚ÇÄ. RE seria inconsistente. Use FE!")
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Sempre roda teste de Hausman antes de interpretar
    - Se p < 0.05: usa FE (seguro, mesmo que menos eficiente)
    - Se p ‚â• 0.05: pode usar RE (mais eficiente)
    """)


def render_section_S7():
    """S7: Estacionariedade e Longo Prazo em Painel"""
    st.header("üìà Estacionariedade e Cointegra√ß√£o em Painel")
    
    st.markdown("""
    Com pain√©is "macro" (muitos per√≠odos), precisamos considerar n√£o-estacionaridade.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Por que Importa?")
        
        st.markdown("""
        **Problemas de s√©ries n√£o-estacion√°rias:**
        - Regress√£o esp√∫ria (correla√ß√£o sem sentido)
        - Infer√™ncia inv√°lida
        - Estimativas inconsistentes
        
        **Em painel:**
        - Combina N s√©ries temporais
        - Mais poder para detectar raiz unit√°ria
        - Testes espec√≠ficos: LLC, IPS, Fisher
        """)
        
        st.subheader("Testes de Raiz Unit√°ria em Painel")
        
        st.markdown("""
        **LLC (Levin-Lin-Chu):**
        - Assume raiz unit√°ria comum
        - H‚ÇÄ: Todas as s√©ries t√™m RU
        - H‚ÇÅ: Todas estacion√°rias
        
        **IPS (Im-Pesaran-Shin):**
        - Permite heterogeneidade
        - H‚ÇÄ: Todas t√™m RU
        - H‚ÇÅ: Algumas estacion√°rias
        """)
    
    with col2:
        # Simular dados e testar
        df_credit = make_credit_case_data(n_countries=15, n_years=20, seed=42)
        
        # Teste simplificado
        ur_test = panel_unit_root_test_simple(df_credit, variable='log_gdp')
        coint_test = panel_cointegration_test_simple(df_credit)
        
        st.markdown("**Resultados dos Testes (Simulados):**")
        
        st.markdown("**Teste de Raiz Unit√°ria (tipo LLC):**")
        col_m1, col_m2 = st.columns(2)
        col_m1.metric("Estat√≠stica m√©dia", f"{ur_test['avg_stat']:.2f}")
        col_m2.metric("p-valor", f"{ur_test['p_value']:.4f}")
        
        st.markdown("**Teste de Cointegra√ß√£o em Painel:**")
        col_m3, col_m4 = st.columns(2)
        col_m3.metric("Estat√≠stica t", f"{coint_test['t_stat']:.2f}")
        col_m4.metric("Cr√≠tico 5%", f"{coint_test['critical_5']:.2f}")
        
        if coint_test['cointegrated']:
            st.success("‚úÖ Evid√™ncia de cointegra√ß√£o: PIB e Cr√©dito t√™m rela√ß√£o de longo prazo")
        else:
            st.warning("‚ö†Ô∏è Sem evid√™ncia forte de cointegra√ß√£o")
    
    with st.expander("üìñ Cointegra√ß√£o em Painel: Aplica√ß√µes"):
        st.markdown("""
        **Aplica√ß√µes em finan√ßas e macro:**
        
        1. **Crescimento e Desenvolvimento Financeiro:**
           - Cr√©dito/PIB e PIB per capita
           - Rela√ß√£o de longo prazo entre pa√≠ses
        
        2. **Paridade de Poder de Compra (PPP):**
           - C√¢mbio e pre√ßos relativos
           - Testar se PPP vale no longo prazo
        
        3. **Estrutura de Capital:**
           - Alavancagem e caracter√≠sticas da firma
           - Velocidade de ajuste ao target
        
        **VECM em Painel:**
        - Combina cointegra√ß√£o com ajuste de curto prazo
        - Permite estimar velocidade de converg√™ncia
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Verifica estacionaridade em pain√©is longos (T > 20)
    - Usa cointegra√ß√£o para rela√ß√µes de longo prazo
    - Considera VECM para din√¢mica de ajuste
    """)


def render_section_S8():
    """S8: Casos Pr√°ticos e Interpreta√ß√£o"""
    st.header("üíº Casos Pr√°ticos")
    
    tab1, tab2 = st.tabs(["üè¶ Caso 1: Competi√ß√£o Banc√°ria", "üìâ Caso 2: Crises e Cr√©dito"])
    
    with tab1:
        st.subheader("Caso: Determinantes da Rentabilidade Banc√°ria")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("""
            **Pergunta de pesquisa:**
            > "Quais fatores explicam a rentabilidade (ROE) dos bancos?"
            
            **Dados:**
            - 15 bancos, 10 anos
            - Vari√°vel dependente: ROE (%)
            - Regressores: Market Share, Cost/Income, Crescimento de Cr√©dito, NPL
            
            **Modelo:**
            $$ROE_{it} = \\alpha_i + \\beta_1 MS_{it} + \\beta_2 CI_{it} + \\beta_3 CG_{it} + \\beta_4 NPL_{it} + \\varepsilon_{it}$$
            """)
        
        with col2:
            df_bank = make_banking_case_data(n_banks=15, n_years=10, seed=42)
            
            # Preparar para estima√ß√£o
            df_bank['entity_id'] = df_bank['banco_id']
            df_bank['entity'] = df_bank['banco']
            df_bank['x'] = df_bank['market_share']  # Simplificado
            df_bank['y'] = df_bank['roe']
            
            # Estimar
            fe = fit_fe_simple(df_bank)
            re = fit_re_simple(df_bank)
            hausman = hausman_test_simple(df_bank)
            
            st.dataframe(df_bank.head(5)[['banco', 'ano', 'roe', 'market_share', 'cost_income']], 
                        use_container_width=True)
        
        st.subheader("Resultados da Estima√ß√£o")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**Efeitos Fixos:**")
            st.metric("Œ≤ (Market Share)", f"{fe['beta']:.3f}")
            st.metric("R¬≤ within", f"{fe['r_squared_within']:.3f}")
        
        with col2:
            st.markdown("**Efeitos Aleat√≥rios:**")
            st.metric("Œ≤ (Market Share)", f"{re['beta']:.3f}")
            st.metric("Œ∏ (peso within)", f"{re['theta']:.3f}")
        
        with col3:
            st.markdown("**Teste de Hausman:**")
            st.metric("H-stat", f"{hausman['H_stat']:.2f}")
            st.metric("p-valor", f"{hausman['p_value']:.4f}")
            st.markdown(f"**Recomenda√ß√£o:** {hausman['recommendation']}")
        
        with st.expander("üìñ Interpreta√ß√£o dos Resultados"):
            st.markdown(f"""
            **Leitura da tabela:**
            
            - Œ≤ = {fe['beta']:.3f}: Aumento de 1 p.p. em market share est√° associado 
              a varia√ß√£o de {fe['beta']:.2f} p.p. no ROE (controlando por efeitos fixos)
            
            - R¬≤ within = {fe['r_squared_within']:.3f}: Varia√ß√£o **dentro** de cada banco 
              explica {fe['r_squared_within']*100:.1f}% da varia√ß√£o do ROE
            
            - Teste de Hausman p = {hausman['p_value']:.4f}: 
              {'Rejeita H‚ÇÄ ‚Üí Use FE' if hausman['p_value'] < 0.05 else 'N√£o rejeita H‚ÇÄ ‚Üí RE √© v√°lido'}
            
            **Implica√ß√£o gerencial:**
            {"Ganhar market share est√° associado a maior rentabilidade, mesmo controlando para caracter√≠sticas fixas do banco." if fe['beta'] > 0 else "N√£o h√° evid√™ncia de que market share aumenta rentabilidade."}
            """)
    
    with tab2:
        st.subheader("Caso: Cr√©dito e Crescimento em Crises")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("""
            **Pergunta de pesquisa:**
            > "Qual a rela√ß√£o entre cr√©dito e crescimento econ√¥mico? 
            > Crises afetam essa rela√ß√£o?"
            
            **Dados:**
            - 20 pa√≠ses, 15 anos
            - Vari√°veis: log(PIB), log(Cr√©dito), Cr√©dito/PIB
            - Per√≠odo inclui crise (anos 5-6 para metade dos pa√≠ses)
            
            **An√°lise:**
            - Cointegra√ß√£o entre cr√©dito e PIB
            - Efeito diferencial em pa√≠ses com crise
            """)
        
        with col2:
            df_credit = make_credit_case_data(n_countries=20, n_years=15, seed=42)
            
            # Visualiza√ß√£o
            fig = px.line(df_credit, x='ano', y='credit_gdp_ratio', color='pais',
                         title="Cr√©dito/PIB por Pa√≠s ao Longo do Tempo")
            fig.update_layout(height=350, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
        
        # Compara√ß√£o antes/durante/depois da crise
        st.subheader("An√°lise: Impacto da Crise")
        
        # Identificar pa√≠ses com crise
        crisis_countries = df_credit[df_credit['pais_id'] < 10]['pais'].unique()
        
        df_credit['has_crisis'] = df_credit['pais'].isin(crisis_countries)
        df_credit['period'] = pd.cut(df_credit['ano'], 
                                     bins=[2004, 2009, 2011, 2020],
                                     labels=['Pr√©-Crise', 'Crise', 'P√≥s-Crise'])
        
        # M√©dia de crescimento por grupo
        summary = df_credit.groupby(['has_crisis', 'period'])['gdp_growth'].mean().reset_index()
        
        fig = px.bar(summary, x='period', y='gdp_growth', color='has_crisis',
                    barmode='group', title="Crescimento M√©dio por Per√≠odo",
                    labels={'gdp_growth': 'Crescimento (%)', 'period': 'Per√≠odo',
                           'has_crisis': 'Pa√≠s com Crise'})
        fig.update_layout(height=350)
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("""
        **Interpreta√ß√£o:**
        - Pa√≠ses com crise tiveram queda significativa no crescimento (anos 5-6)
        - Recupera√ß√£o parcial no per√≠odo p√≥s-crise
        - Painel permite comparar trajet√≥rias (diff-in-diff impl√≠cito)
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Interpreta coeficientes em termos econ√¥micos
    - Considera se efeito √© dentro ou entre entidades
    - Usa resultados para decis√µes de estrat√©gia e pol√≠tica
    """)


def render_section_S9():
    """S9: Resumo Executivo e Encerramento do Curso"""
    st.header("üìã Resumo Executivo")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### O que Aprendemos sobre Dados em Painel
        
        ‚úÖ **O que s√£o pain√©is:**
        - Mesmas entidades observadas ao longo do tempo
        - Combinam cross-section e s√©ries temporais
        - N √ó T observa√ß√µes = mais poder estat√≠stico
        
        ‚úÖ **Vantagens:**
        - Controlam heterogeneidade n√£o observada
        - Reduzem vi√©s de vari√°vel omitida
        - Capturam din√¢mica temporal
        
        ‚úÖ **Estrutura:**
        - Balanceado: todas obs presentes
        - N√£o balanceado: alguns missings (verificar padr√£o!)
        
        ‚úÖ **SUR:**
        - Equa√ß√µes com erros correlacionados
        - Ganho de efici√™ncia quando œÅ alto
        
        ‚úÖ **Efeitos Fixos vs Aleat√≥rios:**
        - FE: intercepto espec√≠fico por entidade (sempre consistente)
        - RE: efeito aleat√≥rio de popula√ß√£o (mais eficiente se v√°lido)
        - Hausman decide: p < 0.05 ‚Üí FE
        
        ‚úÖ **Longo prazo:**
        - Testar raiz unit√°ria em pain√©is longos
        - Cointegra√ß√£o para rela√ß√µes de equil√≠brio
        
        ‚úÖ **Aplica√ß√µes:**
        - Competi√ß√£o e rentabilidade banc√°ria
        - Cr√©dito e crescimento
        - Pol√≠ticas e seus efeitos
        """)
    
    with col2:
        st.markdown("### üí° Mensagem-Chave")
        
        st.info("""
        **"Pain√©is transformam dados em hist√≥rias de decis√£o"**
        
        Ao observar as mesmas unidades ao longo do tempo:
        - Controlamos o que n√£o muda
        - Isolamos o que muda
        - Estimamos efeitos causais com mais confian√ßa
        """)
        
        st.markdown("### üß™ Quiz Final")
        
        resposta = st.radio(
            "Qual a principal vantagem de FE sobre Pooled OLS?",
            ["Mais observa√ß√µes",
             "Controla heterogeneidade n√£o observada constante",
             "Estimativas mais eficientes"],
            key="quiz_final"
        )
        
        if st.button("Ver resposta", key="btn_final"):
            if resposta == "Controla heterogeneidade n√£o observada constante":
                st.success("""
                ‚úÖ **Correto!**
                
                FE adiciona um intercepto para cada entidade, 
                absorvendo tudo que √© constante no tempo.
                
                Isso elimina vi√©s de vari√°veis omitidas 
                que s√£o fixas por entidade.
                """)
            else:
                st.error("FE controla para caracter√≠sticas fixas de cada entidade que poderiam viesar OLS.")
    
    st.markdown("---")
    
    st.subheader("üéì Encerramento do Curso")
    
    st.markdown("""
    ### Integra√ß√£o dos M√≥dulos
    
    Este curso cobriu a jornada completa da econometria aplicada:
    """)
    
    modules = pd.DataFrame({
        'M√≥dulo': ['1-2', '3-4', '5', '6', '7', '8', '9', '10'],
        'Tema': ['Fundamentos e CLRM', 'Diagn√≥stico e Corre√ß√µes', 'Causalidade',
                'S√©ries Univariadas', 'Modelos Multivariados', 'Cointegra√ß√£o',
                'Volatilidade', 'Dados em Painel'],
        'Aplica√ß√£o': ['Base te√≥rica', 'Valida√ß√£o de modelos', 'Decis√µes causais',
                     'Previs√£o', 'Sistemas e VAR', 'Longo prazo', 'Risco', 'Compara√ß√µes']
    })
    st.dataframe(modules, use_container_width=True, hide_index=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **üîß Ferramentas:**
        - OLS e extens√µes
        - Diagn√≥sticos
        - IV/2SLS
        - ARIMA, VAR, VECM
        - GARCH, DCC
        - FE, RE, Hausman
        """)
    
    with col2:
        st.markdown("""
        **üìä Dados:**
        - Cross-section
        - S√©ries temporais
        - Pain√©is
        - Balanceados/n√£o
        """)
    
    with col3:
        st.markdown("""
        **üíº Decis√µes:**
        - Previs√£o
        - Causalidade
        - Risco
        - Pol√≠tica
        - Estrat√©gia
        """)
    
    st.success("""
    üéì **Parab√©ns!** Voc√™ completou o Laborat√≥rio de Econometria.
    
    Agora voc√™ tem as ferramentas para:
    - Analisar dados com rigor metodol√≥gico
    - Escolher o modelo adequado para cada situa√ß√£o
    - Interpretar resultados para tomada de decis√£o
    - Comunicar achados com confian√ßa
    
    **Continue praticando com dados reais!**
    """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com tudo isso?**
    - Aplica a ferramenta certa para cada problema
    - Interpreta resultados considerando limita√ß√µes
    - Comunica incerteza junto com conclus√µes
    - Usa evid√™ncia para melhorar decis√µes
    """)


# =============================================================================
# FUN√á√ÉO PRINCIPAL DE RENDERIZA√á√ÉO
# =============================================================================

def render():
    """Fun√ß√£o principal que renderiza o m√≥dulo completo."""
    
    # T√≠tulo e objetivos
    st.title("üìä M√≥dulo 10: Dados em Painel")
    st.markdown("**Laborat√≥rio de Econometria** | FE, RE, Hausman e Aplica√ß√µes")
    
    with st.expander("üéØ Objetivos do M√≥dulo", expanded=False):
        st.markdown("""
        - Explicar o que s√£o **dados em painel** e suas vantagens
        - Mostrar diferen√ßa entre **balanceado** e **n√£o balanceado**
        - Introduzir **SUR** para erros correlacionados
        - Diferenciar **Efeitos Fixos** e **Aleat√≥rios**
        - Ensinar o **Teste de Hausman** para escolha do modelo
        - Apresentar **estacionariedade** e **cointegra√ß√£o** em painel
        - Aplicar em **casos pr√°ticos** do setor banc√°rio
        """)
    
    # Sidebar: navega√ß√£o
    st.sidebar.title("üìë Navega√ß√£o")
    
    secoes = {
        "S1": "üìä Introdu√ß√£o",
        "S2": "üí™ Vantagens",
        "S3": "üìã Balanceado vs N√£o",
        "S4": "üîó SUR",
        "S5": "‚öñÔ∏è FE vs RE",
        "S6": "üß™ Hausman",
        "S7": "üìà Longo Prazo",
        "S8": "üíº Casos Pr√°ticos",
        "S9": "üìã Resumo"
    }
    
    secao_selecionada = st.sidebar.radio(
        "Selecione a se√ß√£o:",
        list(secoes.keys()),
        format_func=lambda x: secoes[x]
    )
    
    st.sidebar.markdown("---")
    st.sidebar.success("""
    üéì **√öltimo M√≥dulo!**
    
    Pain√©is combinam o melhor de 
    cross-section e s√©ries temporais.
    """)
    
    # Renderizar se√ß√£o selecionada
    if secao_selecionada == "S1":
        render_section_S1()
    elif secao_selecionada == "S2":
        render_section_S2()
    elif secao_selecionada == "S3":
        render_section_S3()
    elif secao_selecionada == "S4":
        render_section_S4()
    elif secao_selecionada == "S5":
        render_section_S5()
    elif secao_selecionada == "S6":
        render_section_S6()
    elif secao_selecionada == "S7":
        render_section_S7()
    elif secao_selecionada == "S8":
        render_section_S8()
    elif secao_selecionada == "S9":
        render_section_S9()


# =============================================================================
# EXECU√á√ÉO STANDALONE (para testes)
# =============================================================================

if __name__ == "__main__":
    try:
        st.set_page_config(
            page_title="M√≥dulo 10: Dados em Painel",
            page_icon="üìä",
            layout="wide"
        )
    except st.errors.StreamlitAPIException:
        pass
    render()