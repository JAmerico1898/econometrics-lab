"""
Laborat√≥rio de Econometria - Module 2: Classical Linear Regression (CLRM)
Aplicativo educacional interativo para regress√£o linear aplicada a neg√≥cios.
P√∫blico-alvo: alunos de MBA com perfis quantitativos heterog√™neos.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# =============================================================================
# FUN√á√ïES AUXILIARES PARA GERA√á√ÉO DE DADOS E C√ÅLCULOS
# =============================================================================

@st.cache_data
def make_regression_data(n: int = 100, alpha: float = 10.0, beta: float = 2.0, 
                         sigma: float = 5.0, seed: int = 42) -> pd.DataFrame:
    """Gera dados sint√©ticos para regress√£o simples."""
    np.random.seed(seed)
    x = np.random.uniform(10, 50, n)
    u = np.random.normal(0, sigma, n)
    y = alpha + beta * x + u
    return pd.DataFrame({'x': x, 'y': y, 'u': u})


def fit_ols_closed_form(x: np.ndarray, y: np.ndarray) -> dict:
    """Calcula OLS via f√≥rmula fechada (sem statsmodels)."""
    n = len(x)
    x_mean = np.mean(x)
    y_mean = np.mean(y)
    
    # Coeficientes
    beta_hat = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean)**2)
    alpha_hat = y_mean - beta_hat * x_mean
    
    # Valores ajustados e res√≠duos
    y_hat = alpha_hat + beta_hat * x
    residuals = y - y_hat
    
    # Soma dos quadrados
    SSE = np.sum(residuals**2)  # Sum of Squared Errors
    SST = np.sum((y - y_mean)**2)  # Total Sum of Squares
    SSR = SST - SSE  # Regression Sum of Squares
    
    # R¬≤
    r_squared = 1 - (SSE / SST) if SST > 0 else 0
    
    # Erro padr√£o dos res√≠duos
    s2 = SSE / (n - 2)  # Vari√¢ncia dos res√≠duos
    se_residuals = np.sqrt(s2)
    
    # Erros padr√£o dos coeficientes
    se_beta = np.sqrt(s2 / np.sum((x - x_mean)**2))
    se_alpha = np.sqrt(s2 * (1/n + x_mean**2 / np.sum((x - x_mean)**2)))
    
    # Estat√≠sticas t
    t_beta = beta_hat / se_beta
    t_alpha = alpha_hat / se_alpha
    
    # P-valores (aproxima√ß√£o usando distribui√ß√£o normal para n grande)
    from scipy import stats
    p_beta = 2 * (1 - stats.t.cdf(abs(t_beta), n - 2))
    p_alpha = 2 * (1 - stats.t.cdf(abs(t_alpha), n - 2))
    
    # Intervalos de confian√ßa (95%)
    t_crit = stats.t.ppf(0.975, n - 2)
    ci_beta = (beta_hat - t_crit * se_beta, beta_hat + t_crit * se_beta)
    ci_alpha = (alpha_hat - t_crit * se_alpha, alpha_hat + t_crit * se_alpha)
    
    return {
        'alpha': alpha_hat,
        'beta': beta_hat,
        'y_hat': y_hat,
        'residuals': residuals,
        'SSE': SSE,
        'SST': SST,
        'SSR': SSR,
        'r_squared': r_squared,
        'se_residuals': se_residuals,
        'se_alpha': se_alpha,
        'se_beta': se_beta,
        't_alpha': t_alpha,
        't_beta': t_beta,
        'p_alpha': p_alpha,
        'p_beta': p_beta,
        'ci_alpha': ci_alpha,
        'ci_beta': ci_beta,
        'n': n
    }


@st.cache_data
def simulate_capm_data(n: int = 60, beta_true: float = 1.2, alpha_true: float = 0.0,
                       sigma: float = 2.0, rf: float = 0.5, seed: int = 42) -> pd.DataFrame:
    """Simula dados de retorno de fundo vs mercado (CAPM)."""
    np.random.seed(seed)
    # Retorno do mercado (em % mensal)
    rm = np.random.normal(1.0, 4.0, n)  # M√©dia 1%, vol 4% ao m√™s
    # Pr√™mio de risco do mercado
    rm_rf = rm - rf
    # Retorno do fundo
    rf_fund = rf + alpha_true + beta_true * rm_rf + np.random.normal(0, sigma, n)
    return pd.DataFrame({
        'Retorno_Mercado': rm,
        'Retorno_Fundo': rf_fund,
        'Premio_Mercado': rm_rf,
        'Excesso_Fundo': rf_fund - rf
    })


@st.cache_data
def simulate_jensen_alpha(n: int = 60, alpha_true: float = 0.5, beta_true: float = 1.0,
                          sigma: float = 1.5, seed: int = 42) -> pd.DataFrame:
    """Simula dados para an√°lise de Alfa de Jensen."""
    np.random.seed(seed)
    rf = 0.4  # Taxa livre de risco mensal
    rm = np.random.normal(1.2, 4.0, n)
    rm_rf = rm - rf
    # Excesso de retorno do fundo
    ri_rf = alpha_true + beta_true * rm_rf + np.random.normal(0, sigma, n)
    return pd.DataFrame({
        'Excesso_Mercado': rm_rf,
        'Excesso_Fundo': ri_rf,
        'Retorno_Mercado': rm,
        'Retorno_Fundo': ri_rf + rf
    })


def make_endogenous_data(n: int = 100, alpha: float = 10.0, beta_true: float = 2.0,
                         sigma: float = 5.0, corr_ux: float = 0.0, seed: int = 42) -> pd.DataFrame:
    """Gera dados com poss√≠vel viola√ß√£o de exogeneidade (correla√ß√£o entre u e x)."""
    np.random.seed(seed)
    
    # Vari√°vel omitida z que afeta tanto x quanto y
    z = np.random.normal(0, 1, n)
    
    # x √© parcialmente determinado por z
    x = 30 + 5 * corr_ux * z + np.random.normal(0, 5, n)
    
    # Erro u tamb√©m √© afetado por z (criando endogeneidade)
    u = sigma * corr_ux * z + np.random.normal(0, sigma * (1 - abs(corr_ux)), n)
    
    # y depende de x e u
    y = alpha + beta_true * x + u
    
    return pd.DataFrame({'x': x, 'y': y, 'u': u, 'z': z})


# =============================================================================
# FUN√á√ïES DE RENDERIZA√á√ÉO POR SE√á√ÉO
# =============================================================================

def render_section_S1():
    """S1: Introdu√ß√£o e Motiva√ß√£o de Neg√≥cios"""
    st.header("üìà Introdu√ß√£o: Por que Regress√£o?")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        A **regress√£o** √© a ferramenta mais usada em an√°lise quantitativa de neg√≥cios.
        Ela responde √† pergunta central: *"Qual o efeito de X sobre Y?"*
        
        Diferente da correla√ß√£o (que mede associa√ß√£o), a regress√£o **modela a depend√™ncia**
        de uma vari√°vel (Y) em rela√ß√£o a outra (X).
        """)
        
        caso = st.selectbox(
            "Selecione um caso de neg√≥cio:",
            ["Marketing ‚Üí Vendas", "Pre√ßo ‚Üí Demanda", 
             "Taxa de Juros ‚Üí Inadimpl√™ncia", "Mercado ‚Üí Retorno do Fundo"]
        )
        
        casos_config = {
            "Marketing ‚Üí Vendas": {"x_label": "Investimento em Marketing (R$ mil)", 
                                   "y_label": "Vendas (unidades)", "alpha": 100, "beta": 5, "sigma": 50},
            "Pre√ßo ‚Üí Demanda": {"x_label": "Pre√ßo (R$)", 
                                "y_label": "Demanda (unidades)", "alpha": 500, "beta": -8, "sigma": 30},
            "Taxa de Juros ‚Üí Inadimpl√™ncia": {"x_label": "Taxa de Juros (%)", 
                                               "y_label": "Taxa de Inadimpl√™ncia (%)", "alpha": 2, "beta": 0.5, "sigma": 1},
            "Mercado ‚Üí Retorno do Fundo": {"x_label": "Retorno do Mercado (%)", 
                                           "y_label": "Retorno do Fundo (%)", "alpha": 0.5, "beta": 1.2, "sigma": 2}
        }
        
        config = casos_config[caso]
        
        st.info(f"""
        **Pergunta de neg√≥cio:** Se aumentarmos {config['x_label'].split('(')[0].strip().lower()}, 
        qual o impacto esperado em {config['y_label'].split('(')[0].strip().lower()}?
        """)
    
    with col2:
        # Gerar dados do caso selecionado
        np.random.seed(42)
        n = 50
        x = np.random.uniform(10, 50, n)
        y = config['alpha'] + config['beta'] * x + np.random.normal(0, config['sigma'], n)
        
        df = pd.DataFrame({'x': x, 'y': y})
        corr = np.corrcoef(x, y)[0, 1]
        
        fig = px.scatter(df, x='x', y='y', 
                        labels={'x': config['x_label'], 'y': config['y_label']},
                        title="Nuvem de Dados: Visualize Antes de Modelar")
        fig.update_traces(marker=dict(size=10, opacity=0.7))
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.metric("Correla√ß√£o", f"{corr:.2f}")
    
    with st.expander("üìä Regress√£o vs Correla√ß√£o: Qual a Diferen√ßa?"):
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown("""
            **Correla√ß√£o:**
            - Mede associa√ß√£o sim√©trica entre X e Y
            - N√£o distingue causa de efeito
            - Varia de -1 a +1
            - Pergunta: *"X e Y andam juntos?"*
            """)
        with col_b:
            st.markdown("""
            **Regress√£o:**
            - Modela Y como fun√ß√£o de X (assim√©trica)
            - Y √© vari√°vel dependente (aleat√≥ria)
            - X √© vari√°vel explicativa (pode ser fixa)
            - Pergunta: *"Quanto Y muda se X variar?"*
            """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa regress√£o para **quantificar** o efeito de decis√µes (investimento, pre√ßo, etc.)
    - Visualiza os dados antes de confiar em qualquer modelo
    """)


def render_section_S2():
    """S2: O Modelo de Regress√£o Simples"""
    st.header("üìê O Modelo de Regress√£o Simples")
    
    st.markdown("""
    O modelo b√°sico de regress√£o √©:
    
    $$y = \\alpha + \\beta x + u$$
    
    Em linguagem de neg√≥cios:
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        | Componente | Significado | Exemplo |
        |------------|-------------|---------|
        | **y** | Vari√°vel objetivo (o que queremos explicar/prever) | Vendas, Retorno, Demanda |
        | **x** | Driver / vari√°vel explicativa | Marketing, Pre√ßo, Mercado |
        | **Œ± (alfa)** | Intercepto (valor base de y quando x=0) | Vendas "org√¢nicas" |
        | **Œ≤ (beta)** | Efeito marginal de x sobre y | Impacto de +1 em marketing |
        | **u** | Termo de erro (tudo que n√£o observamos) | Fatores n√£o modelados |
        """)
        
        st.subheader("O que √© o termo de erro (u)?")
        
        erro_tipo = st.radio(
            "O erro captura:",
            ["Vari√°veis omitidas", "Erro de medi√ß√£o", "Aleatoriedade comportamental"],
            horizontal=True
        )
        
        erro_explicacao = {
            "Vari√°veis omitidas": "Fatores que afetam Y mas n√£o est√£o no modelo (ex.: qualidade do produto, sazonalidade).",
            "Erro de medi√ß√£o": "Imprecis√£o nos dados coletados (ex.: vendas estimadas, n√£o exatas).",
            "Aleatoriedade comportamental": "Varia√ß√£o natural no comportamento de consumidores ou mercados."
        }
        
        st.info(f"üí° **{erro_tipo}:** {erro_explicacao[erro_tipo]}")
    
    with col2:
        st.subheader("Gerador de Dados Interativo")
        
        alpha = st.slider("Œ± (intercepto)", -20.0, 50.0, 10.0, 1.0)
        beta = st.slider("Œ≤ (efeito de x)", -5.0, 5.0, 2.0, 0.1)
        sigma = st.slider("œÉ (n√≠vel de ru√≠do)", 1.0, 30.0, 10.0, 1.0)
        n = st.slider("n (tamanho da amostra)", 20, 200, 50, 10)
        
        df = make_regression_data(n=n, alpha=alpha, beta=beta, sigma=sigma)
        
        fig = px.scatter(df, x='x', y='y', opacity=0.7,
                        title=f"y = {alpha:.1f} + {beta:.1f}x + erro")
        
        # Adicionar reta verdadeira
        x_line = np.array([df['x'].min(), df['x'].max()])
        y_line = alpha + beta * x_line
        fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines',
                                line=dict(color='red', dash='dash'),
                                name='Rela√ß√£o Verdadeira'))
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with st.expander("üìñ Nota T√©cnica: Por que 'erro' e n√£o 'res√≠duo'?"):
        st.markdown("""
        - **Erro (u):** √â o termo te√≥rico, n√£o observ√°vel. Representa tudo que afeta Y al√©m de X.
        - **Res√≠duo (√ª):** √â a estimativa do erro, calculada ap√≥s ajustar a regress√£o: √ª = y - ≈∑.
        
        Na pr√°tica, trabalhamos com res√≠duos porque o erro verdadeiro √© desconhecido.
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Entende que o modelo √© uma **simplifica√ß√£o** ‚Äî o erro sempre existe
    - Questiona: "Quais vari√°veis importantes podem estar no termo de erro?"
    """)


def render_section_S3():
    """S3: A Reta de Melhor Ajuste (OLS) ‚Äî Intui√ß√£o"""
    st.header("üìè OLS: A Reta de Melhor Ajuste")
    
    st.markdown("""
    **OLS (Ordinary Least Squares)** encontra a reta que **minimiza a soma dos res√≠duos ao quadrado**.
    
    Por que ao quadrado? Para penalizar erros grandes e evitar que erros positivos cancelem negativos.
    """)
    
    tab1, tab2, tab3 = st.tabs(["üìä Visualiza√ß√£o", "üéÆ Experimento Manual", "üìà Compara√ß√£o"])
    
    # Dados comuns
    np.random.seed(42)
    df = make_regression_data(n=50, alpha=10, beta=2, sigma=8)
    ols = fit_ols_closed_form(df['x'].values, df['y'].values)
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            mostrar_reta = st.checkbox("Mostrar reta ajustada", value=True)
            mostrar_residuos = st.checkbox("Mostrar res√≠duos", value=False)
            
            st.markdown("""
            **O que s√£o res√≠duos?**
            
            Res√≠duos s√£o as **dist√¢ncias verticais** entre cada ponto e a reta.
            OLS encontra a reta que minimiza a soma dessas dist√¢ncias ao quadrado.
            """)
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("SSE (Soma Quad. Res√≠duos)", f"{ols['SSE']:.1f}")
            col_m2.metric("R¬≤", f"{ols['r_squared']:.3f}")
        
        with col2:
            fig = go.Figure()
            
            # Pontos
            fig.add_trace(go.Scatter(x=df['x'], y=df['y'], mode='markers',
                                    marker=dict(size=10, color='#636EFA', opacity=0.7),
                                    name='Dados'))
            
            if mostrar_reta:
                x_line = np.array([df['x'].min(), df['x'].max()])
                y_line = ols['alpha'] + ols['beta'] * x_line
                fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines',
                                        line=dict(color='red', width=2),
                                        name=f"OLS: y = {ols['alpha']:.1f} + {ols['beta']:.2f}x"))
            
            if mostrar_residuos:
                for i in range(len(df)):
                    fig.add_trace(go.Scatter(
                        x=[df['x'].iloc[i], df['x'].iloc[i]],
                        y=[df['y'].iloc[i], ols['y_hat'][i]],
                        mode='lines',
                        line=dict(color='gray', width=1, dash='dot'),
                        showlegend=False
                    ))
            
            fig.update_layout(
                title="Regress√£o OLS",
                xaxis_title="X",
                yaxis_title="Y",
                height=450
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("üéÆ Tente Ajustar sua Pr√≥pria Reta!")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("**Sua tentativa:**")
            alpha_manual = st.slider("Seu Œ± (intercepto)", -20.0, 50.0, 5.0, 0.5, key="alpha_manual")
            beta_manual = st.slider("Seu Œ≤ (inclina√ß√£o)", -1.0, 5.0, 1.5, 0.1, key="beta_manual")
            
            # Calcular SSE manual
            y_hat_manual = alpha_manual + beta_manual * df['x'].values
            sse_manual = np.sum((df['y'].values - y_hat_manual)**2)
            
            st.markdown("---")
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("Seu SSE", f"{sse_manual:.1f}")
            col_m2.metric("SSE do OLS", f"{ols['SSE']:.1f}")
            
            diff = sse_manual - ols['SSE']
            if diff < 1:
                st.success("üéØ Excelente! Voc√™ est√° muito pr√≥ximo do OLS!")
            elif diff < 100:
                st.info("üëç Bom! Mas o OLS ainda √© melhor.")
            else:
                st.warning(f"üìà Seu SSE est√° {diff:.0f} acima do OLS. Continue ajustando!")
        
        with col2:
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(x=df['x'], y=df['y'], mode='markers',
                                    marker=dict(size=10, color='#636EFA', opacity=0.7),
                                    name='Dados'))
            
            x_line = np.array([df['x'].min(), df['x'].max()])
            
            # Reta manual
            y_manual = alpha_manual + beta_manual * x_line
            fig.add_trace(go.Scatter(x=x_line, y=y_manual, mode='lines',
                                    line=dict(color='orange', width=2),
                                    name=f"Sua reta: y = {alpha_manual:.1f} + {beta_manual:.2f}x"))
            
            # Reta OLS
            y_ols = ols['alpha'] + ols['beta'] * x_line
            fig.add_trace(go.Scatter(x=x_line, y=y_ols, mode='lines',
                                    line=dict(color='red', width=2, dash='dash'),
                                    name=f"OLS: y = {ols['alpha']:.1f} + {ols['beta']:.2f}x"))
            
            fig.update_layout(title="Sua Reta vs OLS", height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("üìä Por que OLS √© o Melhor?")
        
        # Simular v√°rias retas e mostrar SSE
        alphas = np.linspace(ols['alpha'] - 15, ols['alpha'] + 15, 50)
        betas = np.linspace(ols['beta'] - 1, ols['beta'] + 1, 50)
        
        sse_surface = np.zeros((len(alphas), len(betas)))
        for i, a in enumerate(alphas):
            for j, b in enumerate(betas):
                y_hat = a + b * df['x'].values
                sse_surface[i, j] = np.sum((df['y'].values - y_hat)**2)
        
        fig = go.Figure(data=go.Contour(
            x=betas, y=alphas, z=sse_surface,
            colorscale='Viridis',
            contours=dict(showlabels=True)
        ))
        
        # Marcar o ponto √≥timo
        fig.add_trace(go.Scatter(
            x=[ols['beta']], y=[ols['alpha']],
            mode='markers',
            marker=dict(size=15, color='red', symbol='x'),
            name='OLS (m√≠nimo)'
        ))
        
        fig.update_layout(
            title="Superf√≠cie de SSE: OLS est√° no Vale M√≠nimo",
            xaxis_title="Œ≤",
            yaxis_title="Œ±",
            height=450
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("üí° O ponto vermelho marca onde o SSE √© m√≠nimo ‚Äî exatamente os coeficientes OLS!")
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Confia que OLS d√° a "melhor" reta no sentido de menor erro total
    - Entende que R¬≤ mede quanto da varia√ß√£o de Y √© explicada por X
    """)


def render_section_S4():
    """S4: Interpreta√ß√£o de Resultados para Tomada de Decis√£o"""
    st.header("üíº Interpreta√ß√£o para Decis√£o")
    
    st.markdown("""
    O valor de uma regress√£o est√° na **interpreta√ß√£o dos coeficientes** para a√ß√£o gerencial.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Interpretando Œ≤ (efeito marginal)")
        
        st.markdown("""
        **Œ≤** responde: *"Se X aumentar em 1 unidade, quanto Y muda em m√©dia?"*
        
        Exemplos:
        - Œ≤ = 5 em Marketing‚ÜíVendas: +R$1 mil em marketing ‚Üí +5 vendas
        - Œ≤ = -8 em Pre√ßo‚ÜíDemanda: +R$1 no pre√ßo ‚Üí -8 unidades vendidas
        - Œ≤ = 1.2 em CAPM: +1% no mercado ‚Üí +1.2% no fundo (beta > 1 = mais vol√°til)
        """)
        
        st.subheader("Interpretando Œ± (intercepto)")
        
        st.warning("""
        ‚ö†Ô∏è **Cuidado com Œ±!** Ele representa Y quando X=0, mas isso pode n√£o fazer sentido.
        
        - Marketing = 0: Faz sentido (vendas sem propaganda)
        - Pre√ßo = 0: N√£o faz sentido (produto gr√°tis?)
        - Idade = 0: N√£o faz sentido em muitos contextos
        """)
    
    with col2:
        st.subheader("üìä Exemplo: CAPM")
        
        st.markdown("""
        O **CAPM** (Capital Asset Pricing Model) usa regress√£o para medir risco:
        
        $$R_i - R_f = \\alpha + \\beta (R_m - R_f) + \\epsilon$$
        
        Onde:
        - Œ≤ = risco sistem√°tico (sensibilidade ao mercado)
        - Œ± = retorno anormal (alfa de Jensen)
        """)
        
        beta_capm = st.slider("Beta do fundo", 0.5, 2.0, 1.2, 0.1, key="beta_capm")
        alpha_capm = st.slider("Alfa (% ao m√™s)", -1.0, 1.0, 0.2, 0.1, key="alpha_capm")
        
        df_capm = simulate_capm_data(n=60, beta_true=beta_capm, alpha_true=alpha_capm, sigma=2.0)
        ols_capm = fit_ols_closed_form(df_capm['Premio_Mercado'].values, 
                                       df_capm['Excesso_Fundo'].values)
        
        fig = px.scatter(df_capm, x='Premio_Mercado', y='Excesso_Fundo',
                        labels={'Premio_Mercado': 'Pr√™mio de Risco do Mercado (%)',
                               'Excesso_Fundo': 'Excesso de Retorno do Fundo (%)'},
                        title="CAPM: Fundo vs Mercado")
        
        x_line = np.array([df_capm['Premio_Mercado'].min(), df_capm['Premio_Mercado'].max()])
        y_line = ols_capm['alpha'] + ols_capm['beta'] * x_line
        fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines',
                                line=dict(color='red'),
                                name=f"Œ≤={ols_capm['beta']:.2f}, Œ±={ols_capm['alpha']:.2f}"))
        fig.update_layout(height=350)
        st.plotly_chart(fig, use_container_width=True)
        
        col_m1, col_m2 = st.columns(2)
        col_m1.metric("Beta Estimado", f"{ols_capm['beta']:.2f}", 
                     help="Œ≤ > 1: mais vol√°til que o mercado")
        col_m2.metric("Alfa Estimado", f"{ols_capm['alpha']:.2f}%",
                     help="Œ± > 0: retorno acima do esperado pelo risco")
    
    with st.expander("üí° Card: Implica√ß√£o Gerencial"):
        st.markdown("""
        ### Como traduzir coeficientes em a√ß√£o?
        
        | Contexto | Coeficiente | A√ß√£o Gerencial |
        |----------|-------------|----------------|
        | Marketing‚ÜíVendas | Œ≤ = 5 | ROI: cada R$1 gera 5 vendas. Vale investir se margem > custo |
        | Pre√ßo‚ÜíDemanda | Œ≤ = -8 | Elasticidade: subir pre√ßo reduz volume. Otimizar ponto |
        | CAPM | Œ≤ = 1.3 | Fundo amplifica mercado. Bom em alta, ruim em queda |
        | Jensen | Œ± = 0.5% | Gestor gera valor? 0.5%/m√™s = 6%/ano acima do benchmark |
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Traduz Œ≤ em impacto financeiro: "Se investirmos X, o retorno esperado √© Y"
    - Questiona se Œ±=0 faz sentido no contexto antes de interpret√°-lo
    """)


def render_section_S5():
    """S5: Propriedades e Suposi√ß√µes Cr√≠ticas (o 'pulo do gato')"""
    st.header("üéØ Suposi√ß√µes Cr√≠ticas: Quando Confiar no OLS?")
    
    st.markdown("""
    OLS √© **BLUE** (Best Linear Unbiased Estimator) sob certas condi√ß√µes.
    Em linguagem gerencial: *"a melhor estimativa linear, que acerta na m√©dia"*.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("O que significa BLUE?")
        
        st.markdown("""
        - **Unbiased (N√£o-viesado):** Na m√©dia, OLS acerta o valor verdadeiro de Œ≤
        - **Efficient (Eficiente):** Entre estimadores n√£o-viesados, OLS tem menor vari√¢ncia
        
        **Mas isso s√≥ vale se as suposi√ß√µes forem verdadeiras!**
        """)
        
        st.subheader("Suposi√ß√µes Cr√≠ticas para Decis√£o")
        
        st.markdown("""
        1. **Exogeneidade:** E(u|x) = 0 ‚Äî o erro n√£o √© correlacionado com x
        2. **Independ√™ncia:** Os erros n√£o s√£o correlacionados entre si
        3. **Homocedasticidade:** Vari√¢ncia do erro √© constante
        
        A mais importante para decis√£o √© a **exogeneidade**. Se violada, Œ≤ √© viesado!
        """)
    
    with col2:
        st.subheader("üî¨ Simula√ß√£o: Violando Exogeneidade")
        
        st.markdown("""
        O que acontece quando h√° uma **vari√°vel omitida** que afeta tanto X quanto Y?
        """)
        
        corr_ux = st.slider("Correla√ß√£o entre erro (u) e x", -0.9, 0.9, 0.0, 0.1,
                           help="0 = ex√≥geno (correto); ‚â†0 = end√≥geno (vi√©s)")
        
        beta_true = 2.0
        df_endo = make_endogenous_data(n=200, beta_true=beta_true, corr_ux=corr_ux, sigma=5.0)
        ols_endo = fit_ols_closed_form(df_endo['x'].values, df_endo['y'].values)
        
        vies = ols_endo['beta'] - beta_true
        
        col_m1, col_m2, col_m3 = st.columns(3)
        col_m1.metric("Œ≤ Verdadeiro", f"{beta_true:.2f}")
        col_m2.metric("Œ≤ Estimado (OLS)", f"{ols_endo['beta']:.2f}")
        col_m3.metric("Vi√©s", f"{vies:+.2f}", 
                     delta_color="inverse" if abs(vies) > 0.1 else "off")
        
        if abs(corr_ux) > 0.3:
            st.error(f"üö® Vi√©s significativo! OLS superestima/subestima o efeito real.")
        elif abs(corr_ux) > 0.1:
            st.warning("‚ö†Ô∏è Vi√©s moderado. Resultados devem ser interpretados com cautela.")
        else:
            st.success("‚úÖ Exogeneidade aproximadamente v√°lida. OLS √© confi√°vel.")
        
        fig = px.scatter(df_endo, x='x', y='y', opacity=0.5,
                        title=f"Exogeneidade: corr(u,x) = {corr_ux}")
        
        x_line = np.array([df_endo['x'].min(), df_endo['x'].max()])
        # Reta verdadeira
        fig.add_trace(go.Scatter(x=x_line, y=10 + beta_true * x_line, mode='lines',
                                line=dict(color='green', dash='dash'),
                                name=f'Verdadeiro: Œ≤={beta_true}'))
        # Reta OLS
        fig.add_trace(go.Scatter(x=x_line, y=ols_endo['alpha'] + ols_endo['beta'] * x_line,
                                mode='lines', line=dict(color='red'),
                                name=f'OLS: Œ≤={ols_endo["beta"]:.2f}'))
        fig.update_layout(height=350)
        st.plotly_chart(fig, use_container_width=True)
    
    with st.expander("üìñ Nota T√©cnica: Por que endogeneidade causa vi√©s?"):
        st.markdown("""
        Quando uma vari√°vel omitida (z) afeta tanto x quanto y:
        
        1. O erro u "absorve" o efeito de z
        2. Como z tamb√©m afeta x, temos correla√ß√£o entre u e x
        3. OLS "confunde" o efeito de z com o efeito de x
        4. Resultado: Œ≤ estimado ‚â† Œ≤ verdadeiro
        
        **Exemplo:** Efeito de educa√ß√£o sobre sal√°rio. Se "habilidade" afeta ambos 
        (pessoas habilidosas estudam mais E ganham mais), OLS superestima o efeito da educa√ß√£o.
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Pergunta: "H√° vari√°veis omitidas que afetam tanto X quanto Y?"
    - Se sim, busca dados adicionais ou m√©todos alternativos (ex.: experimentos, vari√°veis instrumentais)
    """)


def render_section_S6():
    """S6: Infer√™ncia Estat√≠stica: Podemos Confiar no Resultado?"""
    st.header("üìä Infer√™ncia: Podemos Confiar?")
    
    st.markdown("""
    Mesmo que OLS seja n√£o-viesado, a **estimativa tem incerteza**.
    Infer√™ncia estat√≠stica quantifica essa incerteza para decis√µes mais seguras.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    # Gerar dados para exemplo
    np.random.seed(42)
    df = make_regression_data(n=50, alpha=10, beta=2, sigma=10)
    ols = fit_ols_closed_form(df['x'].values, df['y'].values)
    
    with col1:
        st.subheader("Erro Padr√£o: Precis√£o da Estimativa")
        
        st.markdown("""
        O **erro padr√£o (SE)** mede a incerteza do coeficiente estimado.
        
        - SE menor ‚Üí estimativa mais precisa
        - SE maior ‚Üí mais incerteza
        
        SE depende de:
        - Vari√¢ncia dos erros (mais ru√≠do ‚Üí mais incerteza)
        - Tamanho da amostra (mais dados ‚Üí mais precis√£o)
        - Varia√ß√£o em X (mais spread em X ‚Üí mais precis√£o)
        """)
        
        st.metric("Erro Padr√£o de Œ≤", f"{ols['se_beta']:.3f}")
        
        st.subheader("Teste t: Œ≤ √© Significativo?")
        
        st.markdown("""
        **Hip√≥teses:**
        - H‚ÇÄ: Œ≤ = 0 (X n√£o afeta Y)
        - H‚ÇÅ: Œ≤ ‚â† 0 (X afeta Y)
        
        **Estat√≠stica t** = Œ≤ÃÇ / SE(Œ≤ÃÇ)
        """)
        
        col_m1, col_m2 = st.columns(2)
        col_m1.metric("Estat√≠stica t", f"{ols['t_beta']:.2f}")
        col_m2.metric("p-valor", f"{ols['p_beta']:.4f}")
        
        if ols['p_beta'] < 0.01:
            st.success("‚úÖ Altamente significativo (p < 0.01)")
        elif ols['p_beta'] < 0.05:
            st.success("‚úÖ Significativo (p < 0.05)")
        elif ols['p_beta'] < 0.10:
            st.warning("‚ö†Ô∏è Marginalmente significativo (p < 0.10)")
        else:
            st.error("‚ùå N√£o significativo (p ‚â• 0.10)")
    
    with col2:
        st.subheader("Intervalo de Confian√ßa: Margem de Seguran√ßa")
        
        st.markdown("""
        O **IC 95%** indica a faixa onde Œ≤ provavelmente est√°.
        
        Se o IC n√£o cont√©m zero, Œ≤ √© significativo a 5%.
        """)
        
        st.metric("IC 95% para Œ≤", f"[{ols['ci_beta'][0]:.2f}, {ols['ci_beta'][1]:.2f}]")
        
        # Visualiza√ß√£o do IC
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=[ols['ci_beta'][0], ols['ci_beta'][1]],
            y=[1, 1],
            mode='lines',
            line=dict(color='blue', width=8),
            name='IC 95%'
        ))
        
        fig.add_trace(go.Scatter(
            x=[ols['beta']],
            y=[1],
            mode='markers',
            marker=dict(size=15, color='red'),
            name=f"Œ≤ = {ols['beta']:.2f}"
        ))
        
        fig.add_vline(x=0, line_dash="dash", line_color="gray")
        
        fig.update_layout(
            title="Intervalo de Confian√ßa de Œ≤",
            xaxis_title="Valor de Œ≤",
            yaxis=dict(visible=False),
            height=200,
            showlegend=True
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("Erros de Decis√£o")
        
        st.markdown("""
        | Erro | Descri√ß√£o | Risco de Neg√≥cio |
        |------|-----------|------------------|
        | **Tipo I** | Rejeitar H‚ÇÄ quando √© verdadeira | Investir em X que n√£o funciona |
        | **Tipo II** | N√£o rejeitar H‚ÇÄ quando √© falsa | Ignorar X que funciona |
        """)
    
    st.markdown("---")
    
    st.subheader("üß™ Quiz: Decis√£o sob Incerteza")
    
    st.markdown("""
    **Cen√°rio:** Voc√™ est√° avaliando se uma campanha de marketing (X) afeta vendas (Y).
    O p-valor do coeficiente √© **0.08** e o custo de implementar a campanha √© alto.
    """)
    
    resposta = st.radio(
        "O que voc√™ faz?",
        ["Implementar a campanha (Œ≤ √© significativo)",
         "N√£o implementar (p > 0.05, n√£o √© significativo)",
         "Coletar mais dados antes de decidir",
         "Depende do custo do erro Tipo I vs Tipo II"],
        key="quiz_s6"
    )
    
    if st.button("Ver feedback", key="feedback_s6"):
        if resposta == "Depende do custo do erro Tipo I vs Tipo II":
            st.success("""
            ‚úÖ **Correto!** A decis√£o depende do contexto:
            
            - Se o custo de implementar sem efeito (Tipo I) √© muito alto ‚Üí seja conservador
            - Se o custo de perder uma oportunidade real (Tipo II) √© alto ‚Üí aceite p=0.08
            
            N√£o existe resposta universal. O limiar de 5% √© conven√ß√£o, n√£o lei.
            """)
        elif resposta == "Coletar mais dados antes de decidir":
            st.info("""
            üëç **Parcialmente correto!** Mais dados reduzem incerteza, mas:
            
            - Tem custo (tempo, dinheiro)
            - √Äs vezes n√£o √© vi√°vel
            
            A melhor resposta considera o trade-off de erros Tipo I e II.
            """)
        else:
            st.warning("""
            ‚ö†Ô∏è **Incompleto.** O limiar de 5% √© arbitr√°rio. A decis√£o √≥tima depende de:
            
            - Custo de implementar algo que n√£o funciona (Tipo I)
            - Custo de n√£o implementar algo que funciona (Tipo II)
            
            Com p=0.08, a evid√™ncia √© "marginalmente significativa" ‚Äî o contexto importa!
            """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - N√£o decide apenas pelo p-valor; considera o custo dos erros
    - Usa IC para comunicar incerteza: "O efeito est√° entre X e Y com 95% de confian√ßa"
    """)


def render_section_S7():
    """S7: Casos Reais e Aplica√ß√µes em Finan√ßas"""
    st.header("üí∞ Aplica√ß√µes em Finan√ßas")
    
    tab1, tab2 = st.tabs(["üìä Alfa de Jensen", "üîç Discuss√£o: Anomalias"])
    
    with tab1:
        st.subheader("Alfa de Jensen: O Gestor Gera Valor?")
        
        st.markdown("""
        O **Alfa de Jensen** mede o retorno excedente de um fundo ajustado pelo risco:
        
        $$R_i - R_f = \\alpha + \\beta (R_m - R_f) + \\epsilon$$
        
        - **Œ± > 0:** Gestor gera retorno acima do esperado pelo risco (skill?)
        - **Œ± = 0:** Retorno compat√≠vel com o risco assumido
        - **Œ± < 0:** Gestor destr√≥i valor (ou cobra taxas altas)
        """)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("**Configure o fundo:**")
            alpha_jensen = st.slider("Alfa verdadeiro (% ao m√™s)", -1.0, 2.0, 0.5, 0.1, key="alpha_jensen")
            beta_jensen = st.slider("Beta verdadeiro", 0.5, 1.5, 1.0, 0.1, key="beta_jensen")
            sigma_jensen = st.slider("Volatilidade idiossincr√°tica (%)", 0.5, 4.0, 1.5, 0.25, key="sigma_jensen")
            n_meses = st.slider("Meses de hist√≥rico", 24, 120, 60, 12, key="n_meses")
        
        df_jensen = simulate_jensen_alpha(n=n_meses, alpha_true=alpha_jensen, 
                                          beta_true=beta_jensen, sigma=sigma_jensen)
        ols_jensen = fit_ols_closed_form(df_jensen['Excesso_Mercado'].values,
                                         df_jensen['Excesso_Fundo'].values)
        
        with col2:
            col_m1, col_m2, col_m3 = st.columns(3)
            col_m1.metric("Œ± Estimado", f"{ols_jensen['alpha']:.2f}%",
                         delta=f"{ols_jensen['alpha'] - alpha_jensen:+.2f}% vs real")
            col_m2.metric("p-valor (Œ±)", f"{ols_jensen['p_alpha']:.3f}")
            col_m3.metric("Œ≤ Estimado", f"{ols_jensen['beta']:.2f}")
            
            # Interpreta√ß√£o
            if ols_jensen['p_alpha'] < 0.05 and ols_jensen['alpha'] > 0:
                st.success("‚úÖ Alfa positivo e significativo: evid√™ncia de skill!")
            elif ols_jensen['alpha'] > 0 and ols_jensen['p_alpha'] >= 0.05:
                st.warning("‚ö†Ô∏è Alfa positivo mas n√£o significativo: pode ser sorte")
            elif ols_jensen['alpha'] <= 0:
                st.error("‚ùå Alfa zero ou negativo: sem evid√™ncia de gera√ß√£o de valor")
        
        fig = px.scatter(df_jensen, x='Excesso_Mercado', y='Excesso_Fundo',
                        labels={'Excesso_Mercado': 'Excesso de Retorno do Mercado (%)',
                               'Excesso_Fundo': 'Excesso de Retorno do Fundo (%)'},
                        title="An√°lise de Alfa de Jensen")
        
        x_line = np.array([df_jensen['Excesso_Mercado'].min(), df_jensen['Excesso_Mercado'].max()])
        fig.add_trace(go.Scatter(x=x_line, y=ols_jensen['alpha'] + ols_jensen['beta'] * x_line,
                                mode='lines', line=dict(color='red'),
                                name=f"Œ±={ols_jensen['alpha']:.2f}%, Œ≤={ols_jensen['beta']:.2f}"))
        # Linha de mercado (alfa = 0)
        fig.add_trace(go.Scatter(x=x_line, y=ols_jensen['beta'] * x_line,
                                mode='lines', line=dict(color='gray', dash='dash'),
                                name="Œ±=0 (benchmark)"))
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        with st.expander("üíº Implica√ß√£o: O que muda na avalia√ß√£o do gestor?"):
            st.markdown(f"""
            **Resultados da an√°lise:**
            - Alfa estimado: {ols_jensen['alpha']:.2f}% ao m√™s ({ols_jensen['alpha']*12:.1f}% ao ano)
            - IC 95%: [{ols_jensen['ci_alpha'][0]:.2f}%, {ols_jensen['ci_alpha'][1]:.2f}%]
            
            **Decis√£o de aloca√ß√£o:**
            - Se Œ± > 0 e significativo: considerar aumentar aloca√ß√£o
            - Se Œ± ‚âà 0: avaliar se a taxa de administra√ß√£o justifica
            - Se Œ± < 0: questionar a perman√™ncia no fundo
            
            **Cuidados:**
            - Alfa passado n√£o garante alfa futuro
            - Per√≠odos curtos t√™m alta incerteza
            - Considerar custos de transa√ß√£o e taxas
            """)
    
    with tab2:
        st.subheader("üîç Provoca√ß√£o: Anomalias de Mercado")
        
        st.markdown("""
        Se mercados s√£o eficientes, **n√£o deveria haver alfa consistente**. 
        Mas a literatura documenta v√°rias "anomalias":
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **Anomalias Cl√°ssicas:**
            
            - **Efeito Momentum:** Ativos que subiram continuam subindo no curto prazo
            - **Efeito Valor:** A√ß√µes "baratas" (P/L baixo) superam "caras"
            - **Efeito Tamanho:** Small caps historicamente superam large caps
            - **Sobre-rea√ß√£o:** Mercado exagera em not√≠cias, depois corrige
            """)
        
        with col2:
            st.markdown("""
            **Interpreta√ß√µes:**
            
            1. **Risco:** Anomalias s√£o pr√™mios por riscos n√£o capturados pelo CAPM
            2. **Comportamento:** Vieses cognitivos dos investidores
            3. **Data mining:** Padr√µes esp√∫rios encontrados no passado
            4. **Limites √† arbitragem:** Custos impedem explora√ß√£o
            """)
        
        st.info("""
        üí° **Conex√£o com regress√£o:** Anomalias s√£o detectadas via regress√£o ‚Äî se Œ± ‚â† 0 
        sistematicamente para certas estrat√©gias, h√° "retorno anormal". A quest√£o √©: 
        √© skill, risco ou ilus√£o estat√≠stica?
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa alfa de Jensen para avaliar gestores ativos vs passivos
    - Questiona: "O alfa √© estatisticamente significativo? Persiste no tempo?"
    """)


def render_section_S8():
    """S8: Resumo Executivo e Ponte para o Pr√≥ximo M√≥dulo"""
    st.header("üìã Resumo Executivo")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### O que Aprendemos sobre Regress√£o Linear
        
        ‚úÖ **O que regress√£o faz:**
        - Quantifica a rela√ß√£o entre vari√°veis (efeito de X sobre Y)
        - Fornece estimativas pontuais (Œ≤) e medidas de incerteza (SE, IC)
        - Permite previs√£o: dado X, qual o Y esperado?
        
        ‚ùå **O que regress√£o N√ÉO faz:**
        - N√£o prova causalidade automaticamente (correla√ß√£o ‚â† causa√ß√£o)
        - N√£o funciona bem com suposi√ß√µes violadas (endogeneidade ‚Üí vi√©s)
        - N√£o substitui entendimento do neg√≥cio
        
        üìñ **Como interpretar:**
        - Œ≤ = efeito marginal: +1 em X ‚Üí +Œ≤ em Y (em m√©dia)
        - Œ± = intercepto (cuidado com interpreta√ß√£o quando X=0 n√£o faz sentido)
        - R¬≤ = % da varia√ß√£o de Y explicada por X
        
        üéØ **Quando confiar:**
        - Exogeneidade v√°lida (erro n√£o correlacionado com X)
        - Amostra representativa e suficientemente grande
        - p-valor e IC indicam signific√¢ncia estat√≠stica
        
        ‚ö†Ô∏è **Riscos comuns:**
        - Vari√°veis omitidas que causam vi√©s
        - Confundir signific√¢ncia estat√≠stica com relev√¢ncia pr√°tica
        - Extrapolar al√©m do range dos dados
        """)
    
    with col2:
        st.markdown("### M√©tricas-Chave")
        
        # Exemplo com dados
        df = make_regression_data(n=100, alpha=10, beta=2, sigma=8)
        ols = fit_ols_closed_form(df['x'].values, df['y'].values)
        
        st.metric("Œ± (intercepto)", f"{ols['alpha']:.2f}")
        st.metric("Œ≤ (efeito)", f"{ols['beta']:.2f}")
        st.metric("R¬≤", f"{ols['r_squared']:.1%}")
        st.metric("SE(Œ≤)", f"{ols['se_beta']:.3f}")
        st.metric("p-valor(Œ≤)", f"{ols['p_beta']:.4f}")
    
    st.markdown("---")
    
    st.subheader("üîú Pr√≥ximo M√≥dulo: Extens√µes e Diagn√≥sticos")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **Regress√£o M√∫ltipla:**
        - M√∫ltiplos X's no mesmo modelo
        - Controle de vari√°veis confundidoras
        - Interpreta√ß√£o ceteris paribus
        """)
    
    with col2:
        st.markdown("""
        **Diagn√≥sticos:**
        - Testes de heterocedasticidade
        - Detec√ß√£o de multicolinearidade
        - An√°lise de res√≠duos
        """)
    
    with col3:
        st.markdown("""
        **Extens√µes:**
        - Vari√°veis dummy (categ√≥ricas)
        - Transforma√ß√µes (log, quadr√°tico)
        - Intera√ß√µes entre vari√°veis
        """)
    
    st.success("""
    üéì **Mensagem final:** Regress√£o √© ferramenta poderosa, mas requer julgamento cr√≠tico.
    Entenda as suposi√ß√µes, questione a exogeneidade, e sempre conecte os n√∫meros √† decis√£o de neg√≥cio.
    """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa regress√£o como ponto de partida para an√°lise quantitativa
    - Exige robustez: "Os resultados mudam se incluirmos outras vari√°veis?"
    """)


# =============================================================================
# FUN√á√ÉO PRINCIPAL DE RENDERIZA√á√ÉO
# =============================================================================

def render():
    """Fun√ß√£o principal que renderiza o m√≥dulo completo."""
    
    # T√≠tulo e objetivos
    st.title("üìà M√≥dulo 2: Regress√£o Linear Cl√°ssica (CLRM)")
    st.markdown("**Laborat√≥rio de Econometria** | Modelando Rela√ß√µes para Decis√£o")
    
    with st.expander("üéØ Objetivos do M√≥dulo", expanded=False):
        st.markdown("""
        - Apresentar regress√£o como ferramenta para modelar rela√ß√µes e apoiar decis√µes
        - Ensinar a **leitura gerencial** de uma regress√£o: coeficientes, res√≠duos, R¬≤
        - Introduzir OLS como "reta de melhor ajuste" via minimiza√ß√£o de res√≠duos
        - Explicar **infer√™ncia estat√≠stica**: erro padr√£o, teste t, p-valor, intervalos de confian√ßa
        - Conectar a aplica√ß√µes em finan√ßas: CAPM, Alfa de Jensen
        """)
    
    # Sidebar: navega√ß√£o
    st.sidebar.title("üìë Navega√ß√£o")
    
    secoes = {
        "S1": "üìà Introdu√ß√£o e Motiva√ß√£o",
        "S2": "üìê Modelo de Regress√£o Simples",
        "S3": "üìè OLS: Reta de Melhor Ajuste",
        "S4": "üíº Interpreta√ß√£o para Decis√£o",
        "S5": "üéØ Suposi√ß√µes Cr√≠ticas",
        "S6": "üìä Infer√™ncia Estat√≠stica",
        "S7": "üí∞ Aplica√ß√µes em Finan√ßas",
        "S8": "üìã Resumo e Pr√≥ximos Passos"
    }
    
    secao_selecionada = st.sidebar.radio(
        "Selecione a se√ß√£o:",
        list(secoes.keys()),
        format_func=lambda x: secoes[x]
    )
    
    st.sidebar.markdown("---")
    st.sidebar.info("""
    üí° **Dica:** Use os controles interativos 
    para experimentar com diferentes par√¢metros.
    """)
    
    # Renderizar se√ß√£o selecionada
    if secao_selecionada == "S1":
        render_section_S1()
    elif secao_selecionada == "S2":
        render_section_S2()
    elif secao_selecionada == "S3":
        render_section_S3()
    elif secao_selecionada == "S4":
        render_section_S4()
    elif secao_selecionada == "S5":
        render_section_S5()
    elif secao_selecionada == "S6":
        render_section_S6()
    elif secao_selecionada == "S7":
        render_section_S7()
    elif secao_selecionada == "S8":
        render_section_S8()


# =============================================================================
# EXECU√á√ÉO STANDALONE (para testes)
# =============================================================================

if __name__ == "__main__":
    # Configura√ß√£o da p√°gina (apenas quando executado diretamente)
    try:
        st.set_page_config(
            page_title="M√≥dulo 2: Regress√£o Linear (CLRM)",
            page_icon="üìà",
            layout="wide"
        )
    except st.errors.StreamlitAPIException:
        pass
    render()