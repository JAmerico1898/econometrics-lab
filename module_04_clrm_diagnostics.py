"""
Laborat√≥rio de Econometria - Module 4: Assumptions and Diagnostic Tests of CLRM
Aplicativo educacional interativo para diagn√≥sticos do modelo de regress√£o linear.
P√∫blico-alvo: alunos de MBA com perfis quantitativos heterog√™neos.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy import stats

# =============================================================================
# FUN√á√ïES AUXILIARES PARA GERA√á√ÉO DE DADOS
# =============================================================================

@st.cache_data
def make_hetero_data(n: int = 200, hetero_intensity: float = 0.0, seed: int = 42) -> pd.DataFrame:
    """Gera dados com heterocedasticidade controlada."""
    np.random.seed(seed)
    x = np.random.uniform(10, 100, n)
    
    # Erro com vari√¢ncia que cresce com x
    if hetero_intensity > 0:
        sigma = 2 + hetero_intensity * x / 10
    else:
        sigma = np.full(n, 5.0)
    
    erro = np.random.normal(0, 1, n) * sigma
    y = 10 + 0.5 * x + erro
    
    return pd.DataFrame({'x': x, 'y': y, 'sigma': sigma})


@st.cache_data
def make_autocorr_ts_data(n: int = 100, rho: float = 0.0, seed: int = 42) -> pd.DataFrame:
    """Gera s√©rie temporal com erro AR(1) controlado."""
    np.random.seed(seed)
    
    # Tend√™ncia temporal
    t = np.arange(1, n + 1)
    x = t + np.random.normal(0, 5, n)
    
    # Erro AR(1): u_t = rho * u_{t-1} + e_t
    e = np.random.normal(0, 2, n)
    u = np.zeros(n)
    u[0] = e[0]
    for i in range(1, n):
        u[i] = rho * u[i-1] + e[i]
    
    y = 5 + 0.3 * x + u
    
    return pd.DataFrame({'t': t, 'x': x, 'y': y, 'u': u})


@st.cache_data
def make_collinear_data(n: int = 200, corr: float = 0.0, seed: int = 42) -> pd.DataFrame:
    """Gera dados com multicolinearidade controlada."""
    np.random.seed(seed)
    
    # x1 √© independente
    x1 = np.random.normal(50, 10, n)
    
    # x2 √© correlacionado com x1
    noise = np.random.normal(0, 10 * np.sqrt(1 - corr**2), n) if abs(corr) < 1 else np.zeros(n)
    x2 = corr * (x1 - 50) + 50 + noise
    
    # y depende de ambos
    erro = np.random.normal(0, 5, n)
    y = 10 + 2 * x1 + 3 * x2 + erro
    
    return pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})


@st.cache_data
def make_nonnormal_data(n: int = 200, outlier_pct: float = 0.0, seed: int = 42) -> pd.DataFrame:
    """Gera dados com poss√≠veis outliers/eventos extremos."""
    np.random.seed(seed)
    
    x = np.random.uniform(10, 90, n)
    erro = np.random.normal(0, 5, n)
    
    # Adicionar outliers
    n_outliers = int(n * outlier_pct / 100)
    if n_outliers > 0:
        outlier_idx = np.random.choice(n, n_outliers, replace=False)
        erro[outlier_idx] = np.random.choice([-1, 1], n_outliers) * np.random.uniform(20, 40, n_outliers)
    
    y = 15 + 0.8 * x + erro
    
    return pd.DataFrame({'x': x, 'y': y})


@st.cache_data
def make_structural_break_data(n: int = 100, break_point: int = 50, 
                                has_break: bool = False, seed: int = 42) -> pd.DataFrame:
    """Gera dados com poss√≠vel quebra estrutural."""
    np.random.seed(seed)
    
    t = np.arange(1, n + 1)
    x = np.random.uniform(10, 50, n)
    erro = np.random.normal(0, 3, n)
    
    if has_break:
        # Antes da quebra
        y1 = 10 + 1.0 * x[:break_point] + erro[:break_point]
        # Depois da quebra (coeficientes mudam)
        y2 = 25 + 0.3 * x[break_point:] + erro[break_point:]
        y = np.concatenate([y1, y2])
    else:
        y = 10 + 1.0 * x + erro
    
    regime = np.array(['Antes'] * break_point + ['Depois'] * (n - break_point))
    
    return pd.DataFrame({'t': t, 'x': x, 'y': y, 'regime': regime})


@st.cache_data
def make_ratings_case_data(n: int = 50, seed: int = 42) -> pd.DataFrame:
    """Gera dados sint√©ticos de ratings soberanos."""
    np.random.seed(seed)
    
    # Vari√°veis macroecon√¥micas
    pib_crescimento = np.random.normal(2.5, 2.0, n)
    inflacao = np.abs(np.random.normal(4, 3, n))
    divida_pib = np.random.uniform(30, 120, n)
    reservas_pib = np.random.uniform(5, 40, n)
    
    # Rating (escala num√©rica, com ru√≠do)
    rating_score = (50 
                   + 3 * pib_crescimento 
                   - 2 * inflacao 
                   - 0.3 * divida_pib 
                   + 0.5 * reservas_pib
                   + np.random.normal(0, 5, n))
    
    # Adicionar heterocedasticidade e autocorrela√ß√£o leves
    rating_score = np.clip(rating_score, 0, 100)
    
    return pd.DataFrame({
        'Rating': rating_score,
        'PIB_Crescimento': pib_crescimento,
        'Inflacao': inflacao,
        'Divida_PIB': divida_pib,
        'Reservas_PIB': reservas_pib
    })


# =============================================================================
# FUN√á√ïES AUXILIARES PARA C√ÅLCULOS E TESTES
# =============================================================================

def fit_ols_closed_form(X: np.ndarray, y: np.ndarray) -> dict:
    """Calcula OLS via f√≥rmula matricial."""
    n, k = X.shape
    
    # Adicionar constante se n√£o existir
    if not np.allclose(X[:, 0], 1):
        X = np.column_stack([np.ones(n), X])
        k = X.shape[1]
    
    XtX = X.T @ X
    XtX_inv = np.linalg.inv(XtX)
    beta_hat = XtX_inv @ X.T @ y
    
    y_hat = X @ beta_hat
    residuals = y - y_hat
    
    SSE = np.sum(residuals**2)
    SST = np.sum((y - np.mean(y))**2)
    
    r_squared = 1 - SSE / SST
    r_squared_adj = 1 - (SSE / (n - k)) / (SST / (n - 1))
    
    s2 = SSE / (n - k)
    var_beta = s2 * np.diag(XtX_inv)
    se_beta = np.sqrt(var_beta)
    
    t_stats = beta_hat / se_beta
    p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k))
    
    return {
        'beta': beta_hat,
        'se': se_beta,
        't_stats': t_stats,
        'p_values': p_values,
        'y_hat': y_hat,
        'residuals': residuals,
        'SSE': SSE,
        'SST': SST,
        'r_squared': r_squared,
        'r_squared_adj': r_squared_adj,
        's2': s2,
        'n': n,
        'k': k,
        'X': X,
        'XtX_inv': XtX_inv
    }


def white_test(X: np.ndarray, residuals: np.ndarray) -> dict:
    """Teste de White para heterocedasticidade."""
    n = len(residuals)
    u2 = residuals**2
    
    # Regress√£o auxiliar: u¬≤ ~ X, X¬≤, X*X (cross products)
    # Simplificado: u¬≤ ~ constante, x, x¬≤
    if X.shape[1] >= 2:
        x = X[:, 1]  # Primeira vari√°vel explicativa (sem constante)
    else:
        x = X[:, 0]
    
    Z = np.column_stack([np.ones(n), x, x**2])
    
    # OLS da regress√£o auxiliar
    ZtZ_inv = np.linalg.inv(Z.T @ Z)
    gamma = ZtZ_inv @ Z.T @ u2
    u2_hat = Z @ gamma
    
    # R¬≤ da regress√£o auxiliar
    SSR_aux = np.sum((u2_hat - np.mean(u2))**2)
    SST_aux = np.sum((u2 - np.mean(u2))**2)
    r2_aux = SSR_aux / SST_aux if SST_aux > 0 else 0
    
    # Estat√≠stica LM = n * R¬≤
    lm_stat = n * r2_aux
    df = Z.shape[1] - 1  # Graus de liberdade
    p_value = 1 - stats.chi2.cdf(lm_stat, df)
    
    return {
        'lm_stat': lm_stat,
        'p_value': p_value,
        'df': df,
        'r2_aux': r2_aux
    }


def durbin_watson(residuals: np.ndarray) -> float:
    """Calcula a estat√≠stica de Durbin-Watson."""
    diff = np.diff(residuals)
    dw = np.sum(diff**2) / np.sum(residuals**2)
    return dw


def breusch_godfrey(residuals: np.ndarray, X: np.ndarray, lags: int = 1) -> dict:
    """Teste de Breusch-Godfrey para autocorrela√ß√£o."""
    n = len(residuals)
    
    # Criar lags dos res√≠duos
    Z = X.copy()
    for lag in range(1, lags + 1):
        lagged_res = np.zeros(n)
        lagged_res[lag:] = residuals[:-lag]
        Z = np.column_stack([Z, lagged_res])
    
    # Regress√£o auxiliar: u ~ X, u_{t-1}, ..., u_{t-p}
    ZtZ_inv = np.linalg.inv(Z.T @ Z)
    gamma = ZtZ_inv @ Z.T @ residuals
    u_hat = Z @ gamma
    
    # R¬≤ da regress√£o auxiliar
    SSR_aux = np.sum(u_hat**2)
    SST_aux = np.sum(residuals**2)
    r2_aux = SSR_aux / SST_aux if SST_aux > 0 else 0
    
    # Estat√≠stica LM = n * R¬≤
    lm_stat = n * r2_aux
    p_value = 1 - stats.chi2.cdf(lm_stat, lags)
    
    return {
        'lm_stat': lm_stat,
        'p_value': p_value,
        'lags': lags,
        'r2_aux': r2_aux
    }


def robust_se(X: np.ndarray, residuals: np.ndarray, XtX_inv: np.ndarray) -> np.ndarray:
    """Calcula erros padr√£o robustos (HC0 - White)."""
    n, k = X.shape
    
    # Matriz de covari√¢ncia robusta: (X'X)^{-1} X' diag(u¬≤) X (X'X)^{-1}
    u2 = residuals**2
    meat = X.T @ np.diag(u2) @ X
    var_robust = XtX_inv @ meat @ XtX_inv
    
    return np.sqrt(np.diag(var_robust))


def newey_west_se(X: np.ndarray, residuals: np.ndarray, XtX_inv: np.ndarray, 
                  max_lag: int = None) -> np.ndarray:
    """Calcula erros padr√£o Newey-West (HAC)."""
    n, k = X.shape
    
    if max_lag is None:
        max_lag = int(np.floor(4 * (n / 100) ** (2/9)))
    
    # Come√ßar com matriz HC0
    u = residuals
    S = np.zeros((k, k))
    
    for t in range(n):
        S += u[t]**2 * np.outer(X[t], X[t])
    
    # Adicionar termos de autocovari√¢ncia
    for lag in range(1, max_lag + 1):
        weight = 1 - lag / (max_lag + 1)  # Bartlett kernel
        for t in range(lag, n):
            cross = u[t] * u[t - lag] * (np.outer(X[t], X[t - lag]) + np.outer(X[t - lag], X[t]))
            S += weight * cross
    
    var_nw = XtX_inv @ S @ XtX_inv
    return np.sqrt(np.diag(var_nw))


def compute_vif(X: np.ndarray) -> np.ndarray:
    """Calcula VIF para cada vari√°vel (excluindo constante)."""
    n, k = X.shape
    
    # Identificar se primeira coluna √© constante
    start_idx = 1 if np.allclose(X[:, 0], 1) else 0
    
    vifs = []
    for j in range(start_idx, k):
        # Regress√£o de X_j contra as outras vari√°veis
        mask = [i for i in range(k) if i != j]
        X_others = X[:, mask]
        x_j = X[:, j]
        
        # OLS
        XtX_inv = np.linalg.inv(X_others.T @ X_others)
        beta = XtX_inv @ X_others.T @ x_j
        x_hat = X_others @ beta
        
        # R¬≤ e VIF
        ss_res = np.sum((x_j - x_hat)**2)
        ss_tot = np.sum((x_j - np.mean(x_j))**2)
        r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0
        
        vif = 1 / (1 - r2) if r2 < 1 else np.inf
        vifs.append(vif)
    
    return np.array(vifs)


def jarque_bera(residuals: np.ndarray) -> dict:
    """Teste de Jarque-Bera para normalidade."""
    n = len(residuals)
    
    # Padronizar res√≠duos
    u = residuals - np.mean(residuals)
    s = np.std(residuals, ddof=1)
    u_std = u / s
    
    # Skewness e Kurtosis
    skew = np.mean(u_std**3)
    kurt = np.mean(u_std**4)
    
    # Estat√≠stica JB
    jb_stat = n * (skew**2 / 6 + (kurt - 3)**2 / 24)
    p_value = 1 - stats.chi2.cdf(jb_stat, 2)
    
    return {
        'jb_stat': jb_stat,
        'p_value': p_value,
        'skewness': skew,
        'kurtosis': kurt
    }


def ramsey_reset(y: np.ndarray, X: np.ndarray, residuals: np.ndarray, 
                 y_hat: np.ndarray, powers: int = 2) -> dict:
    """Teste RESET de Ramsey para forma funcional."""
    n = len(y)
    
    # Adicionar pot√™ncias de y_hat ao modelo
    Z = X.copy()
    for p in range(2, powers + 2):
        Z = np.column_stack([Z, y_hat**p])
    
    # Modelo expandido
    ols_expanded = fit_ols_closed_form(Z, y)
    
    # Teste F para os termos adicionais
    k_original = X.shape[1]
    k_expanded = Z.shape[1]
    q = k_expanded - k_original
    
    sse_restricted = np.sum(residuals**2)
    sse_unrestricted = ols_expanded['SSE']
    
    f_stat = ((sse_restricted - sse_unrestricted) / q) / (sse_unrestricted / (n - k_expanded))
    p_value = 1 - stats.f.cdf(f_stat, q, n - k_expanded)
    
    return {
        'f_stat': f_stat,
        'p_value': p_value,
        'df1': q,
        'df2': n - k_expanded
    }


def chow_test(y: np.ndarray, X: np.ndarray, break_point: int) -> dict:
    """Teste de Chow para quebra estrutural."""
    n, k = X.shape
    
    # Modelo pooled (todo o per√≠odo)
    ols_pooled = fit_ols_closed_form(X, y)
    sse_pooled = ols_pooled['SSE']
    
    # Modelo antes da quebra
    ols_before = fit_ols_closed_form(X[:break_point], y[:break_point])
    sse_before = ols_before['SSE']
    
    # Modelo depois da quebra
    ols_after = fit_ols_closed_form(X[break_point:], y[break_point:])
    sse_after = ols_after['SSE']
    
    # Estat√≠stica F de Chow
    sse_unrestricted = sse_before + sse_after
    
    f_stat = ((sse_pooled - sse_unrestricted) / k) / (sse_unrestricted / (n - 2 * k))
    p_value = 1 - stats.f.cdf(f_stat, k, n - 2 * k)
    
    return {
        'f_stat': f_stat,
        'p_value': p_value,
        'sse_pooled': sse_pooled,
        'sse_before': sse_before,
        'sse_after': sse_after,
        'df1': k,
        'df2': n - 2 * k
    }


# =============================================================================
# FUN√á√ïES DE RENDERIZA√á√ÉO POR SE√á√ÉO
# =============================================================================

def render_section_S1():
    """S1: Por que as suposi√ß√µes importam? (BLUE e risco decis√≥rio)"""
    st.header("üéØ Por que as Suposi√ß√µes Importam?")
    
    st.markdown("""
    O OLS √© **BLUE** (Best Linear Unbiased Estimator) *somente se* certas suposi√ß√µes forem v√°lidas.
    Quando falham, os coeficientes podem estar ok, mas **erros padr√£o e testes enganam**.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("As 5 Suposi√ß√µes Cl√°ssicas")
        
        suposicoes = [
            ("1Ô∏è‚É£ Linearidade", "Y √© fun√ß√£o linear de X mais erro", 
             "Coeficientes n√£o capturam a rela√ß√£o verdadeira"),
            ("2Ô∏è‚É£ Exogeneidade", "E(u|X) = 0 ‚Äî erro n√£o correlacionado com X",
             "Coeficientes viesados e inconsistentes"),
            ("3Ô∏è‚É£ Homocedasticidade", "Var(u|X) = œÉ¬≤ constante",
             "Erros padr√£o incorretos ‚Üí testes inv√°lidos"),
            ("4Ô∏è‚É£ N√£o-autocorrela√ß√£o", "Cov(u·µ¢, u‚±º) = 0 para i ‚â† j",
             "Erros padr√£o subestimados ‚Üí falsa precis√£o"),
            ("5Ô∏è‚É£ Normalidade", "u ~ N(0, œÉ¬≤)",
             "Infer√™ncia em amostras pequenas comprometida")
        ]
        
        for titulo, descricao, consequencia in suposicoes:
            with st.expander(titulo):
                st.markdown(f"**O que diz:** {descricao}")
                st.markdown(f"**Se falhar:** {consequencia}")
    
    with col2:
        st.subheader("Resumo Visual: Impacto das Viola√ß√µes")
        
        # Criar tabela resumo
        impact_data = {
            'Viola√ß√£o': ['Heterocedasticidade', 'Autocorrela√ß√£o', 'Multicolinearidade', 
                        'N√£o-normalidade', 'Forma funcional errada'],
            'Œ≤ viesado?': ['N√£o', 'N√£o', 'N√£o', 'N√£o', 'Sim'],
            'SE incorreto?': ['Sim ‚ö†Ô∏è', 'Sim ‚ö†Ô∏è', 'Inflado ‚ö†Ô∏è', 'N√£o*', 'Sim'],
            'Testes inv√°lidos?': ['Sim ‚ö†Ô∏è', 'Sim ‚ö†Ô∏è', 'Parcial', 'Em amostras pequenas', 'Sim ‚ö†Ô∏è']
        }
        st.dataframe(pd.DataFrame(impact_data), use_container_width=True, hide_index=True)
        
        st.caption("*Em amostras grandes, normalidade √© menos cr√≠tica (Teorema Central do Limite)")
        
        st.warning("""
        ‚ö†Ô∏è **Risco decis√≥rio:** Voc√™ pode concluir que uma vari√°vel √© significativa 
        quando n√£o √© (falso positivo), ou ter excesso de confian√ßa na precis√£o do modelo.
        """)
    
    st.markdown("---")
    
    st.subheader("üìã Mini-Checklist: Quando Desconfiar do Modelo?")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        - [ ] Res√≠duos mostram padr√£o sistem√°tico (funil, curva)?
        - [ ] Dados s√£o s√©ries temporais (risco de autocorrela√ß√£o)?
        - [ ] Vari√°veis explicativas s√£o muito correlacionadas?
        """)
    
    with col2:
        st.markdown("""
        - [ ] H√° outliers ou eventos extremos nos dados?
        - [ ] O modelo foi estimado em per√≠odo diferente do usado?
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Nunca confia cegamente em p-valores sem verificar diagn√≥sticos
    - Exige robustez: "Os resultados mudam com erros padr√£o robustos?"
    """)


def render_section_S2():
    """S2: Heterocedasticidade (incerteza n√£o constante)"""
    st.header("üìä Heterocedasticidade: Vari√¢ncia N√£o Constante")
    
    st.markdown("""
    **Heterocedasticidade** ocorre quando a vari√¢ncia do erro muda com X.
    Exemplo: gastos mais altos t√™m maior variabilidade que gastos baixos.
    """)
    
    tab1, tab2, tab3 = st.tabs(["üìà Visual", "üß™ Teste de White", "üõ°Ô∏è Erros Robustos"])
    
    with tab1:
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("Controles")
            hetero_intensity = st.slider("Intensidade da heterocedasticidade", 
                                        0.0, 2.0, 0.0, 0.1,
                                        help="0 = homocedasticidade; >0 = vari√¢ncia cresce com x")
            
            st.markdown("""
            **O que observar:**
            - Com intensidade = 0: res√≠duos t√™m dispers√£o constante
            - Com intensidade > 0: forma de "funil" (dispers√£o cresce)
            """)
        
        with col2:
            df = make_hetero_data(n=200, hetero_intensity=hetero_intensity)
            X = np.column_stack([np.ones(len(df)), df['x'].values])
            ols = fit_ols_closed_form(X, df['y'].values)
            
            # Gr√°fico de res√≠duos vs x
            fig = px.scatter(x=df['x'], y=ols['residuals'],
                            labels={'x': 'X', 'y': 'Res√≠duos'},
                            title="Res√≠duos vs X (detecte o padr√£o funil)")
            fig.add_hline(y=0, line_dash="dash", line_color="red")
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            if hetero_intensity > 0.5:
                st.error("üîç Padr√£o de funil vis√≠vel ‚Äî heterocedasticidade prov√°vel!")
            elif hetero_intensity > 0:
                st.warning("‚ö†Ô∏è Leve padr√£o de dispers√£o crescente")
            else:
                st.success("‚úÖ Dispers√£o aparentemente constante")
    
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Teste de White")
            
            st.markdown("""
            **Hip√≥teses:**
            - H‚ÇÄ: Homocedasticidade (vari√¢ncia constante)
            - H‚ÇÅ: Heterocedasticidade
            
            **M√©todo:** Regride u¬≤ contra X e X¬≤ e testa se coeficientes s√£o significativos.
            """)
            
            df = make_hetero_data(n=200, hetero_intensity=hetero_intensity)
            X = np.column_stack([np.ones(len(df)), df['x'].values])
            ols = fit_ols_closed_form(X, df['y'].values)
            
            white = white_test(X, ols['residuals'])
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("Estat√≠stica LM", f"{white['lm_stat']:.2f}")
            col_m2.metric("p-valor", f"{white['p_value']:.4f}")
            
            if white['p_value'] < 0.05:
                st.error("‚ùå Rejeita H‚ÇÄ: Evid√™ncia de heterocedasticidade!")
            else:
                st.success("‚úÖ N√£o rejeita H‚ÇÄ: Sem evid√™ncia forte de heterocedasticidade")
        
        with col2:
            st.subheader("Interpreta√ß√£o Gerencial")
            
            st.markdown("""
            **Se detectar heterocedasticidade:**
            
            1. **Coeficientes (Œ≤):** Ainda s√£o n√£o-viesados ‚úì
            2. **Erros padr√£o:** S√£o incorretos ‚úó
            3. **Testes t e F:** S√£o inv√°lidos ‚úó
            4. **Intervalos de confian√ßa:** S√£o incorretos ‚úó
            
            **Risco:** Voc√™ pode pensar que uma vari√°vel √© significativa quando n√£o √©!
            """)
    
    with tab3:
        st.subheader("Solu√ß√£o: Erros Padr√£o Robustos")
        
        col1, col2 = st.columns([1, 1])
        
        df = make_hetero_data(n=200, hetero_intensity=hetero_intensity)
        X = np.column_stack([np.ones(len(df)), df['x'].values])
        ols = fit_ols_closed_form(X, df['y'].values)
        
        se_classic = ols['se']
        se_robust = robust_se(ols['X'], ols['residuals'], ols['XtX_inv'])
        
        with col1:
            st.markdown("**Compara√ß√£o de Erros Padr√£o:**")
            
            comp_df = pd.DataFrame({
                'Vari√°vel': ['Intercepto', 'X'],
                'Coeficiente': ols['beta'].round(3),
                'SE Cl√°ssico': se_classic.round(4),
                'SE Robusto': se_robust.round(4),
                'Diferen√ßa %': ((se_robust / se_classic - 1) * 100).round(1)
            })
            st.dataframe(comp_df, use_container_width=True, hide_index=True)
            
            if hetero_intensity > 0.5:
                st.warning("‚ö†Ô∏è Note como o SE robusto difere do cl√°ssico!")
        
        with col2:
            st.markdown("**Mitiga√ß√µes:**")
            
            st.markdown("""
            1. **Erros padr√£o robustos (HC):** Corrige os SEs sem alterar Œ≤
            2. **Transforma√ß√£o log:** Se vari√¢ncia proporcional ao n√≠vel
            3. **Weighted Least Squares:** Se conhece a estrutura da vari√¢ncia
            4. **Reespecifica√ß√£o:** Adicionar vari√°veis omitidas
            """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Sempre visualiza res√≠duos vs X antes de confiar nos testes
    - Usa erros padr√£o robustos como padr√£o em dados cross-section
    """)


def render_section_S3():
    """S3: Autocorrela√ß√£o (o fantasma do passado)"""
    st.header("üìà Autocorrela√ß√£o: Erros Correlacionados no Tempo")
    
    st.markdown("""
    **Autocorrela√ß√£o** ocorre quando o erro de hoje depende do erro de ontem.
    Comum em s√©ries temporais: se subestimamos hoje, provavelmente subestimamos amanh√£.
    """)
    
    tab1, tab2, tab3 = st.tabs(["üìä Visual", "üß™ Testes (DW/BG)", "üõ°Ô∏è Newey-West"])
    
    with tab1:
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("Controles")
            rho = st.slider("œÅ (autocorrela√ß√£o AR(1))", -0.9, 0.9, 0.0, 0.1,
                           help="0 = sem autocorrela√ß√£o; pr√≥ximo de ¬±1 = forte autocorrela√ß√£o")
            
            st.markdown(f"""
            **Modelo do erro:** u‚Çú = {rho:.1f} √ó u‚Çú‚Çã‚ÇÅ + e‚Çú
            
            - œÅ = 0: Erros independentes
            - œÅ > 0: Autocorrela√ß√£o positiva (mais comum)
            - œÅ < 0: Autocorrela√ß√£o negativa
            """)
        
        with col2:
            df = make_autocorr_ts_data(n=100, rho=rho)
            X = np.column_stack([np.ones(len(df)), df['x'].values])
            ols = fit_ols_closed_form(X, df['y'].values)
            
            # Gr√°fico de res√≠duos ao longo do tempo
            fig = make_subplots(rows=2, cols=1, 
                               subplot_titles=["Res√≠duos ao Longo do Tempo", "Res√≠duo t vs Res√≠duo t-1"])
            
            fig.add_trace(go.Scatter(x=df['t'], y=ols['residuals'], mode='lines+markers',
                                    marker=dict(size=5), name='Res√≠duos'),
                         row=1, col=1)
            fig.add_hline(y=0, line_dash="dash", line_color="red", row=1, col=1)
            
            # Scatter de u_t vs u_{t-1}
            fig.add_trace(go.Scatter(x=ols['residuals'][:-1], y=ols['residuals'][1:],
                                    mode='markers', name='u_t vs u_{t-1}'),
                         row=2, col=1)
            
            fig.update_layout(height=500, showlegend=False)
            fig.update_xaxes(title_text="Tempo", row=1, col=1)
            fig.update_xaxes(title_text="Res√≠duo t-1", row=2, col=1)
            fig.update_yaxes(title_text="Res√≠duo t", row=2, col=1)
            st.plotly_chart(fig, use_container_width=True)
            
            if abs(rho) > 0.5:
                st.error("üîç Padr√£o claro de persist√™ncia nos res√≠duos!")
            elif abs(rho) > 0.2:
                st.warning("‚ö†Ô∏è Alguma depend√™ncia temporal vis√≠vel")
    
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        df = make_autocorr_ts_data(n=100, rho=rho)
        X = np.column_stack([np.ones(len(df)), df['x'].values])
        ols = fit_ols_closed_form(X, df['y'].values)
        
        with col1:
            st.subheader("Teste Durbin-Watson")
            
            dw = durbin_watson(ols['residuals'])
            
            st.metric("Estat√≠stica DW", f"{dw:.2f}")
            
            st.markdown("""
            **Interpreta√ß√£o:**
            - DW ‚âà 2: Sem autocorrela√ß√£o
            - DW < 2: Autocorrela√ß√£o positiva
            - DW > 2: Autocorrela√ß√£o negativa
            
            **Regra pr√°tica:** DW < 1.5 ou DW > 2.5 ‚Üí suspeitar
            """)
            
            if dw < 1.5:
                st.error("‚ö†Ô∏è DW baixo: prov√°vel autocorrela√ß√£o positiva")
            elif dw > 2.5:
                st.warning("‚ö†Ô∏è DW alto: poss√≠vel autocorrela√ß√£o negativa")
            else:
                st.success("‚úÖ DW pr√≥ximo de 2: sem evid√™ncia forte")
        
        with col2:
            st.subheader("Teste Breusch-Godfrey")
            
            bg = breusch_godfrey(ols['residuals'], ols['X'], lags=1)
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("Estat√≠stica LM", f"{bg['lm_stat']:.2f}")
            col_m2.metric("p-valor", f"{bg['p_value']:.4f}")
            
            st.markdown("""
            **Vantagem sobre DW:**
            - Funciona com vari√°veis defasadas no modelo
            - Testa m√∫ltiplos lags
            - Fornece p-valor direto
            """)
            
            if bg['p_value'] < 0.05:
                st.error("‚ùå Rejeita H‚ÇÄ: Evid√™ncia de autocorrela√ß√£o!")
            else:
                st.success("‚úÖ N√£o rejeita H‚ÇÄ")
    
    with tab3:
        st.subheader("Solu√ß√£o: Erros Padr√£o Newey-West (HAC)")
        
        col1, col2 = st.columns([1, 1])
        
        df = make_autocorr_ts_data(n=100, rho=rho)
        X = np.column_stack([np.ones(len(df)), df['x'].values])
        ols = fit_ols_closed_form(X, df['y'].values)
        
        se_classic = ols['se']
        se_nw = newey_west_se(ols['X'], ols['residuals'], ols['XtX_inv'])
        
        with col1:
            st.markdown("**Compara√ß√£o de Erros Padr√£o:**")
            
            comp_df = pd.DataFrame({
                'Vari√°vel': ['Intercepto', 'X'],
                'Coeficiente': ols['beta'].round(3),
                'SE Cl√°ssico': se_classic.round(4),
                'SE Newey-West': se_nw.round(4),
                'Raz√£o NW/Cl√°ssico': (se_nw / se_classic).round(2)
            })
            st.dataframe(comp_df, use_container_width=True, hide_index=True)
            
            if abs(rho) > 0.3 and np.mean(se_nw / se_classic) > 1.2:
                st.warning("‚ö†Ô∏è SE Newey-West √© maior ‚Äî autocorrela√ß√£o infla a falsa precis√£o!")
        
        with col2:
            st.markdown("**Op√ß√µes de Corre√ß√£o:**")
            
            st.markdown("""
            1. **Newey-West (HAC):** Corrige SEs para heterocedasticidade E autocorrela√ß√£o
            
            2. **Modelo Din√¢mico:** Incluir vari√°vel dependente defasada:
               - y‚Çú = Œ± + Œ≤x‚Çú + Œ≥y‚Çú‚Çã‚ÇÅ + Œµ‚Çú
            
            3. **Diferencia√ß√£o:** Usar Œîy = y‚Çú - y‚Çú‚Çã‚ÇÅ como dependente
            
            4. **GLS (Cochrane-Orcutt):** Transformar o modelo
            """)
        
        st.info("""
        üí° **R¬≤ inflado:** Com autocorrela√ß√£o, o R¬≤ pode parecer alto porque o modelo 
        "segue" a tend√™ncia dos erros, n√£o porque explica bem Y.
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Em s√©ries temporais, sempre verifica DW e usa Newey-West por padr√£o
    - Questiona: "O modelo est√° prevendo bem ou apenas seguindo a tend√™ncia?"
    """)


def render_section_S4():
    """S4: Multicolinearidade (vari√°veis que dizem a mesma coisa)"""
    st.header("üîó Multicolinearidade: Vari√°veis Redundantes")
    
    st.markdown("""
    **Multicolinearidade** ocorre quando vari√°veis explicativas s√£o altamente correlacionadas.
    O modelo n√£o consegue separar seus efeitos individuais.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Controles")
        
        corr_level = st.slider("Correla√ß√£o entre X‚ÇÅ e X‚ÇÇ", 0.0, 0.99, 0.0, 0.05)
        
        st.markdown(f"""
        **Situa√ß√£o:** X‚ÇÅ e X‚ÇÇ t√™m correla√ß√£o = {corr_level:.2f}
        
        - corr = 0: Vari√°veis independentes
        - corr > 0.7: Multicolinearidade moderada
        - corr > 0.9: Multicolinearidade severa
        """)
    
    with col2:
        df = make_collinear_data(n=200, corr=corr_level)
        
        # Matriz de correla√ß√£o
        corr_matrix = df[['x1', 'x2']].corr()
        
        fig = px.imshow(corr_matrix, text_auto='.2f', 
                       color_continuous_scale='RdBu_r',
                       title="Matriz de Correla√ß√£o")
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    # VIF e resultados
    st.subheader("Diagn√≥stico: VIF (Variance Inflation Factor)")
    
    X = np.column_stack([np.ones(len(df)), df['x1'].values, df['x2'].values])
    ols = fit_ols_closed_form(X, df['y'].values)
    vifs = compute_vif(X)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("**VIF por Vari√°vel:**")
        
        vif_df = pd.DataFrame({
            'Vari√°vel': ['X‚ÇÅ', 'X‚ÇÇ'],
            'VIF': vifs.round(2),
            'Status': ['‚ö†Ô∏è Alto' if v > 10 else ('‚ö° Moderado' if v > 5 else '‚úÖ OK') for v in vifs]
        })
        st.dataframe(vif_df, use_container_width=True, hide_index=True)
        
        st.markdown("""
        **Regras de bolso:**
        - VIF < 5: Geralmente aceit√°vel
        - VIF 5-10: Preocupante
        - VIF > 10: Multicolinearidade severa
        """)
        
        if max(vifs) > 10:
            st.error("üö® Multicolinearidade severa detectada!")
        elif max(vifs) > 5:
            st.warning("‚ö†Ô∏è Multicolinearidade moderada")
        else:
            st.success("‚úÖ Sem multicolinearidade problem√°tica")
    
    with col2:
        st.markdown("**Resultados da Regress√£o:**")
        
        results_df = pd.DataFrame({
            'Vari√°vel': ['Intercepto', 'X‚ÇÅ', 'X‚ÇÇ'],
            'Œ≤': ols['beta'].round(3),
            'SE': ols['se'].round(3),
            't-stat': ols['t_stats'].round(2),
            'p-valor': ols['p_values'].round(4)
        })
        st.dataframe(results_df, use_container_width=True, hide_index=True)
        
        st.markdown("""
        **Efeitos da multicolinearidade:**
        - Œ≤'s continuam n√£o-viesados, mas...
        - Erros padr√£o ficam **inflados**
        - Coeficientes ficam **inst√°veis** (sens√≠veis a pequenas mudan√ßas)
        - Vari√°veis podem parecer n√£o-significativas mesmo sendo importantes
        """)
    
    with st.expander("üí° Solu√ß√µes para Multicolinearidade"):
        st.markdown("""
        **1. Remover redund√¢ncia:**
        - Excluir uma das vari√°veis correlacionadas
        - Escolher baseado em teoria ou relev√¢ncia pr√°tica
        
        **2. Criar √≠ndices/raz√µes:**
        - Combinar vari√°veis em um √∫nico indicador
        - Ex.: em vez de Receita e Custos, usar Margem
        
        **3. Aumentar amostra:**
        - Mais dados ajudam a separar efeitos (mas nem sempre vi√°vel)
        
        **4. Regulariza√ß√£o (avan√ßado):**
        - Ridge regression, LASSO
        - Penaliza coeficientes grandes
        
        **5. Aceitar e interpretar com cuidado:**
        - Se o objetivo √© previs√£o (n√£o interpreta√ß√£o), pode ser ok
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Verifica VIF antes de interpretar coeficientes individuais
    - Questiona: "Essas vari√°veis medem a mesma coisa de formas diferentes?"
    """)


def render_section_S5():
    """S5: Normalidade e Forma Funcional"""
    st.header("üìê Normalidade e Forma Funcional")
    
    tab1, tab2 = st.tabs(["üîî Normalidade (Jarque-Bera)", "üìà Forma Funcional (RESET)"])
    
    with tab1:
        st.subheader("Teste de Normalidade dos Res√≠duos")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            outlier_pct = st.slider("% de Outliers", 0.0, 10.0, 0.0, 0.5)
            
            st.markdown("""
            **Por que normalidade importa?**
            - Para testes t e F em amostras pequenas
            - Para intervalos de confian√ßa exatos
            
            **Em amostras grandes:** Menos cr√≠tico (Teorema Central do Limite)
            """)
            
            df = make_nonnormal_data(n=200, outlier_pct=outlier_pct)
            X = np.column_stack([np.ones(len(df)), df['x'].values])
            ols = fit_ols_closed_form(X, df['y'].values)
            
            jb = jarque_bera(ols['residuals'])
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("Estat√≠stica JB", f"{jb['jb_stat']:.2f}")
            col_m2.metric("p-valor", f"{jb['p_value']:.4f}")
            
            col_m3, col_m4 = st.columns(2)
            col_m3.metric("Assimetria", f"{jb['skewness']:.2f}", 
                         help="0 = sim√©trico")
            col_m4.metric("Curtose", f"{jb['kurtosis']:.2f}",
                         help="3 = normal")
            
            if jb['p_value'] < 0.05:
                st.error("‚ùå Rejeita normalidade ‚Äî res√≠duos n√£o s√£o normais")
            else:
                st.success("‚úÖ N√£o rejeita normalidade")
        
        with col2:
            # Histograma dos res√≠duos
            fig = go.Figure()
            fig.add_trace(go.Histogram(x=ols['residuals'], nbinsx=30, 
                                       name='Res√≠duos', opacity=0.7))
            
            # Sobrepor curva normal te√≥rica
            x_norm = np.linspace(ols['residuals'].min(), ols['residuals'].max(), 100)
            y_norm = stats.norm.pdf(x_norm, 0, np.std(ols['residuals'])) * len(ols['residuals']) * (ols['residuals'].max() - ols['residuals'].min()) / 30
            fig.add_trace(go.Scatter(x=x_norm, y=y_norm, mode='lines',
                                    line=dict(color='red', width=2),
                                    name='Normal te√≥rica'))
            
            fig.update_layout(
                title="Histograma dos Res√≠duos vs Normal",
                xaxis_title="Res√≠duos",
                yaxis_title="Frequ√™ncia",
                height=350
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("Teste RESET de Ramsey: A Forma Funcional Est√° Correta?")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("""
            **O que o RESET testa:**
            - H‚ÇÄ: Forma funcional linear √© adequada
            - H‚ÇÅ: Termos n√£o-lineares s√£o necess√°rios
            
            **M√©todo:** Adiciona ≈∑¬≤, ≈∑¬≥ ao modelo e testa se s√£o significativos.
            Se forem, a rela√ß√£o linear original est√° mal especificada.
            """)
            
            usar_quadratico = st.checkbox("Simular rela√ß√£o quadr√°tica verdadeira", value=False)
            
            # Gerar dados
            np.random.seed(42)
            n = 200
            x = np.random.uniform(0, 10, n)
            if usar_quadratico:
                y = 5 + 2*x - 0.2*x**2 + np.random.normal(0, 2, n)
            else:
                y = 5 + 2*x + np.random.normal(0, 2, n)
            
            X = np.column_stack([np.ones(n), x])
            ols = fit_ols_closed_form(X, y)
            
            reset = ramsey_reset(y, ols['X'], ols['residuals'], ols['y_hat'])
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("Estat√≠stica F", f"{reset['f_stat']:.2f}")
            col_m2.metric("p-valor", f"{reset['p_value']:.4f}")
            
            if reset['p_value'] < 0.05:
                st.error("‚ùå Rejeita H‚ÇÄ: Forma funcional inadequada! Considere termos n√£o-lineares.")
            else:
                st.success("‚úÖ N√£o rejeita H‚ÇÄ: Forma linear parece adequada")
        
        with col2:
            # Gr√°fico
            fig = px.scatter(x=x, y=y, opacity=0.6,
                            labels={'x': 'X', 'y': 'Y'},
                            title="Dados e Ajuste Linear")
            
            x_line = np.linspace(x.min(), x.max(), 100)
            y_line = ols['beta'][0] + ols['beta'][1] * x_line
            fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines',
                                    line=dict(color='red'),
                                    name='Ajuste Linear'))
            
            if usar_quadratico:
                # Mostrar ajuste quadr√°tico tamb√©m
                X_quad = np.column_stack([np.ones(n), x, x**2])
                ols_quad = fit_ols_closed_form(X_quad, y)
                y_quad = ols_quad['beta'][0] + ols_quad['beta'][1]*x_line + ols_quad['beta'][2]*x_line**2
                fig.add_trace(go.Scatter(x=x_line, y=y_quad, mode='lines',
                                        line=dict(color='green', dash='dash'),
                                        name='Ajuste Quadr√°tico'))
            
            fig.update_layout(height=350)
            st.plotly_chart(fig, use_container_width=True)
    
    with st.expander("üí° Recomenda√ß√µes Pr√°ticas"):
        st.markdown("""
        **Se normalidade falhar:**
        - Em amostras grandes (n > 100): geralmente n√£o √© cr√≠tico
        - Verifique outliers e considere remov√™-los ou usar dummies
        - Bootstrap pode dar infer√™ncia mais robusta
        
        **Se forma funcional falhar (RESET):**
        - Adicionar termos quadr√°ticos: x¬≤
        - Usar transforma√ß√£o log: log(x), log(y)
        - Adicionar intera√ß√µes: x‚ÇÅ √ó x‚ÇÇ
        - Incluir dummies para regimes (crise/normal)
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Verifica RESET para saber se a rela√ß√£o √© realmente linear
    - N√£o descarta modelo s√≥ por falhar JB em amostras grandes
    """)


def render_section_S6():
    """S6: Estabilidade do Modelo e Filosofia de Constru√ß√£o"""
    st.header("üîÑ Estabilidade e Constru√ß√£o de Modelos")
    
    tab1, tab2 = st.tabs(["üìä Teste de Chow", "üîß Geral-para-Espec√≠fico"])
    
    with tab1:
        st.subheader("Teste de Chow: O Modelo √© Est√°vel no Tempo?")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("""
            **Pergunta central:** Os coeficientes s√£o os mesmos antes e depois de um evento?
            
            Exemplos:
            - Crise de 2008 mudou a rela√ß√£o risco-retorno?
            - Nova regula√ß√£o alterou o comportamento do mercado?
            - O modelo dos anos 2000 funciona em 2020?
            """)
            
            has_break = st.checkbox("Simular quebra estrutural", value=False)
            break_point = st.slider("Ponto de quebra (observa√ß√£o)", 20, 80, 50)
            
            df = make_structural_break_data(n=100, break_point=break_point, has_break=has_break)
            X = np.column_stack([np.ones(len(df)), df['x'].values])
            
            chow = chow_test(df['y'].values, X, break_point)
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("Estat√≠stica F", f"{chow['f_stat']:.2f}")
            col_m2.metric("p-valor", f"{chow['p_value']:.4f}")
            
            if chow['p_value'] < 0.05:
                st.error("‚ùå Rejeita estabilidade: Coeficientes mudaram ap√≥s a quebra!")
            else:
                st.success("‚úÖ N√£o rejeita estabilidade: Modelo parece consistente")
        
        with col2:
            # Gr√°fico com cores por regime
            fig = px.scatter(df, x='x', y='y', color='regime',
                            title="Dados por Regime (Antes/Depois da Quebra)")
            
            # Ajustar modelos separados
            X_before = X[:break_point]
            X_after = X[break_point:]
            ols_before = fit_ols_closed_form(X_before, df['y'].values[:break_point])
            ols_after = fit_ols_closed_form(X_after, df['y'].values[break_point:])
            
            x_range = np.linspace(df['x'].min(), df['x'].max(), 50)
            
            fig.add_trace(go.Scatter(
                x=x_range, y=ols_before['beta'][0] + ols_before['beta'][1] * x_range,
                mode='lines', line=dict(color='blue', dash='dash'),
                name=f"Antes: Œ≤={ols_before['beta'][1]:.2f}"
            ))
            
            fig.add_trace(go.Scatter(
                x=x_range, y=ols_after['beta'][0] + ols_after['beta'][1] * x_range,
                mode='lines', line=dict(color='red', dash='dash'),
                name=f"Depois: Œ≤={ols_after['beta'][1]:.2f}"
            ))
            
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("Filosofia Geral-para-Espec√≠fico")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("""
            **Abordagem recomendada para construir modelos:**
            
            1. **Come√ßar amplo:** Incluir todas as vari√°veis teoricamente relevantes
            
            2. **Diagnosticar:** Verificar hetero, auto, colinearidade, forma funcional
            
            3. **Simplificar:** Remover vari√°veis n√£o significativas (uma por vez)
            
            4. **Validar:** Re-testar diagn√≥sticos ap√≥s cada mudan√ßa
            
            5. **Documentar:** Justificar exclus√µes e inclus√µes
            """)
        
        with col2:
            # Fluxograma simplificado
            st.markdown("""
            ```
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Modelo Geral       ‚îÇ
            ‚îÇ  (todas vari√°veis)  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Diagn√≥sticos       ‚îÇ
            ‚îÇ  ‚Ä¢ Hetero (White)   ‚îÇ
            ‚îÇ  ‚Ä¢ Auto (DW/BG)     ‚îÇ
            ‚îÇ  ‚Ä¢ Multicolinear    ‚îÇ
            ‚îÇ  ‚Ä¢ RESET, JB        ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Corre√ß√µes          ‚îÇ
            ‚îÇ  ‚Ä¢ Erros robustos   ‚îÇ
            ‚îÇ  ‚Ä¢ Transforma√ß√µes   ‚îÇ
            ‚îÇ  ‚Ä¢ Remover vars     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Modelo Final       ‚îÇ
            ‚îÇ  Parcim√¥nia + Fit   ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ```
            """)
        
        st.info("""
        üí° **Princ√≠pio:** Prefira modelos mais simples que passam nos diagn√≥sticos 
        a modelos complexos que "encaixam" melhor mas violam suposi√ß√µes.
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Testa estabilidade antes de usar modelo hist√≥rico para decis√µes futuras
    - Documenta o processo de constru√ß√£o do modelo para auditoria
    """)


def render_section_S7():
    """S7: Estudo de Caso: Ratings de Cr√©dito Soberano"""
    st.header("üèõÔ∏è Estudo de Caso: Determinantes de Rating Soberano")
    
    st.markdown("""
    Vamos aplicar o workflow completo de diagn√≥stico em um modelo de rating de cr√©dito soberano.
    
    **Vari√°veis:**
    - **Rating:** Score num√©rico (0-100)
    - **PIB_Crescimento:** Crescimento do PIB (%)
    - **Infla√ß√£o:** Taxa de infla√ß√£o (%)
    - **D√≠vida_PIB:** D√≠vida p√∫blica / PIB (%)
    - **Reservas_PIB:** Reservas internacionais / PIB (%)
    """)
    
    # Gerar dados
    df = make_ratings_case_data(n=50)
    
    # Mostrar dados
    with st.expander("üìä Ver Dados"):
        st.dataframe(df.round(2), use_container_width=True)
    
    st.subheader("Passo 1: Estima√ß√£o Inicial")
    
    X = np.column_stack([
        np.ones(len(df)),
        df['PIB_Crescimento'].values,
        df['Inflacao'].values,
        df['Divida_PIB'].values,
        df['Reservas_PIB'].values
    ])
    y = df['Rating'].values
    
    ols = fit_ols_closed_form(X, y)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("**Resultados da Regress√£o:**")
        
        nomes = ['Intercepto', 'PIB Crescimento', 'Infla√ß√£o', 'D√≠vida/PIB', 'Reservas/PIB']
        results_df = pd.DataFrame({
            'Vari√°vel': nomes,
            'Coeficiente': ols['beta'].round(3),
            'SE Cl√°ssico': ols['se'].round(3),
            'p-valor': ols['p_values'].round(4)
        })
        st.dataframe(results_df, use_container_width=True, hide_index=True)
    
    with col2:
        col_m1, col_m2 = st.columns(2)
        col_m1.metric("R¬≤", f"{ols['r_squared']:.3f}")
        col_m2.metric("R¬≤ Ajustado", f"{ols['r_squared_adj']:.3f}")
    
    st.subheader("Passo 2: Diagn√≥sticos")
    
    col1, col2, col3, col4 = st.columns(4)
    
    # Heterocedasticidade
    white = white_test(ols['X'], ols['residuals'])
    with col1:
        st.markdown("**Hetero (White)**")
        st.metric("p-valor", f"{white['p_value']:.3f}")
        if white['p_value'] < 0.05:
            st.error("‚ö†Ô∏è Detectada")
        else:
            st.success("‚úÖ OK")
    
    # Normalidade
    jb = jarque_bera(ols['residuals'])
    with col2:
        st.markdown("**Normal (JB)**")
        st.metric("p-valor", f"{jb['p_value']:.3f}")
        if jb['p_value'] < 0.05:
            st.warning("‚ö†Ô∏è Rejeita")
        else:
            st.success("‚úÖ OK")
    
    # Forma funcional
    reset = ramsey_reset(y, ols['X'], ols['residuals'], ols['y_hat'])
    with col3:
        st.markdown("**RESET**")
        st.metric("p-valor", f"{reset['p_value']:.3f}")
        if reset['p_value'] < 0.05:
            st.error("‚ö†Ô∏è Rejeita")
        else:
            st.success("‚úÖ OK")
    
    # Multicolinearidade
    vifs = compute_vif(ols['X'])
    with col4:
        st.markdown("**VIF m√°ximo**")
        st.metric("VIF", f"{max(vifs):.1f}")
        if max(vifs) > 10:
            st.error("‚ö†Ô∏è Alto")
        elif max(vifs) > 5:
            st.warning("‚ö†Ô∏è Moderado")
        else:
            st.success("‚úÖ OK")
    
    st.subheader("Passo 3: Compara√ß√£o com Erros Robustos")
    
    se_robust = robust_se(ols['X'], ols['residuals'], ols['XtX_inv'])
    
    comp_df = pd.DataFrame({
        'Vari√°vel': nomes,
        'Coeficiente': ols['beta'].round(3),
        'SE Cl√°ssico': ols['se'].round(3),
        'SE Robusto': se_robust.round(3),
        't Cl√°ssico': (ols['beta'] / ols['se']).round(2),
        't Robusto': (ols['beta'] / se_robust).round(2)
    })
    st.dataframe(comp_df, use_container_width=True, hide_index=True)
    
    st.subheader("Passo 4: Resumo Executivo")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### ‚úÖ Conclus√µes do Modelo")
        st.markdown(f"""
        **Vari√°veis significativas (SE robusto):**
        """)
        for i, nome in enumerate(nomes[1:], 1):
            t_rob = abs(ols['beta'][i] / se_robust[i])
            sig = "‚úì" if t_rob > 1.96 else "‚úó"
            direcao = "‚Üë" if ols['beta'][i] > 0 else "‚Üì"
            st.markdown(f"- {nome}: {sig} (Œ≤={ols['beta'][i]:.2f}, {direcao} rating)")
    
    with col2:
        st.markdown("### ‚ö†Ô∏è Riscos e Limita√ß√µes")
        st.markdown("""
        - Amostra pequena (n=50) limita infer√™ncia
        - Poss√≠vel endogeneidade: rating afeta economia?
        - Modelo simplificado: fatores pol√≠ticos n√£o inclu√≠dos
        - Estabilidade n√£o testada: modelo pode n√£o valer em crises
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa o modelo para entender drivers, n√£o para previs√£o precisa
    - Reporta resultados com erros robustos e documenta limita√ß√µes
    """)


def render_section_S8():
    """S8: Resumo Executivo e Ponte para o Pr√≥ximo M√≥dulo"""
    st.header("üìã Resumo Executivo: Diagn√≥sticos do CLRM")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### Principais Falhas e Como Lidar
        
        | Problema | Detec√ß√£o | Consequ√™ncia | Solu√ß√£o |
        |----------|----------|--------------|---------|
        | **Heterocedasticidade** | Visual (funil), White | SE incorretos | Erros robustos |
        | **Autocorrela√ß√£o** | DW, Breusch-Godfrey | SE subestimados | Newey-West, din√¢micos |
        | **Multicolinearidade** | Correla√ß√£o, VIF | SE inflados | Remover, combinar vars |
        | **N√£o-normalidade** | JB, histograma | Infer√™ncia (n pequeno) | Amostra maior, bootstrap |
        | **Forma funcional** | RESET | Œ≤ viesado | Adicionar n√£o-lineares |
        | **Instabilidade** | Chow | Modelo obsoleto | Re-estimar, dummies |
        
        ### Workflow Recomendado
        
        1. **Estimar** modelo inicial com todas vari√°veis relevantes
        2. **Visualizar** res√≠duos vs X e vs tempo
        3. **Testar** hetero (White), auto (DW/BG), forma (RESET), normalidade (JB)
        4. **Verificar** multicolinearidade (VIF) e estabilidade (Chow se aplic√°vel)
        5. **Corrigir** usando erros robustos ou reespecifica√ß√£o
        6. **Comparar** resultados antes/depois das corre√ß√µes
        7. **Documentar** limita√ß√µes e riscos
        """)
    
    with col2:
        st.markdown("### üß™ Quiz Final")
        
        st.markdown("""
        Um analista encontrou:
        - p-valor White = 0.02
        - VIF m√°ximo = 3.2
        - p-valor JB = 0.15
        - DW = 1.95
        """)
        
        resposta = st.radio(
            "Qual o principal problema?",
            ["Multicolinearidade", "Heterocedasticidade", 
             "N√£o-normalidade", "Autocorrela√ß√£o"],
            key="quiz_final"
        )
        
        if st.button("Verificar", key="btn_final"):
            if resposta == "Heterocedasticidade":
                st.success("""
                ‚úÖ **Correto!** 
                - White p=0.02 < 0.05 ‚Üí rejeita homocedasticidade
                - VIF=3.2 < 5 ‚Üí OK
                - JB p=0.15 > 0.05 ‚Üí n√£o rejeita normalidade
                - DW‚âà2 ‚Üí sem autocorrela√ß√£o
                
                **A√ß√£o:** Usar erros padr√£o robustos (HC).
                """)
            else:
                st.error("O problema √© **heterocedasticidade** (White p=0.02)")
    
    st.markdown("---")
    
    st.subheader("üîú Pr√≥ximo M√≥dulo: S√©ries Temporais")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **Processos ARIMA:**
        - AR: Autoregressivo
        - I: Integrado
        - MA: M√©dia M√≥vel
        """)
    
    with col2:
        st.markdown("""
        **Estacionariedade:**
        - Testes de raiz unit√°ria
        - Diferencia√ß√£o
        - Tend√™ncias
        """)
    
    with col3:
        st.markdown("""
        **Forecasting:**
        - Previs√£o pontual
        - Intervalos de previs√£o
        - Avalia√ß√£o de acur√°cia
        """)
    
    st.success("""
    üéì **Mensagem final:** Diagn√≥sticos n√£o s√£o formalidade ‚Äî s√£o a diferen√ßa entre 
    uma an√°lise confi√°vel e uma ilus√£o estat√≠stica. Sempre verifique antes de decidir.
    """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Exige diagn√≥sticos em toda an√°lise quantitativa apresentada
    - Questiona: "Esses resultados s√£o robustos a diferentes especifica√ß√µes?"
    """)


# =============================================================================
# FUN√á√ÉO PRINCIPAL DE RENDERIZA√á√ÉO
# =============================================================================

def render():
    """Fun√ß√£o principal que renderiza o m√≥dulo completo."""
    
    # T√≠tulo e objetivos
    st.title("üîç M√≥dulo 4: Diagn√≥sticos do CLRM")
    st.markdown("**Laborat√≥rio de Econometria** | Suposi√ß√µes, Testes e Corre√ß√µes")
    
    with st.expander("üéØ Objetivos do M√≥dulo", expanded=False):
        st.markdown("""
        - Explicar por que as **suposi√ß√µes do CLRM** s√£o cr√≠ticas para decis√µes
        - Detectar e mitigar **heterocedasticidade** (White, erros robustos)
        - Detectar e mitigar **autocorrela√ß√£o** (DW, Breusch-Godfrey, Newey-West)
        - Diagnosticar **multicolinearidade** (VIF) e discutir solu√ß√µes
        - Avaliar **normalidade** (Jarque-Bera) e **forma funcional** (RESET)
        - Testar **estabilidade** (Chow) e aplicar filosofia geral-para-espec√≠fico
        """)
    
    # Sidebar: navega√ß√£o
    st.sidebar.title("üìë Navega√ß√£o")
    
    secoes = {
        "S1": "üéØ Por que Suposi√ß√µes Importam",
        "S2": "üìä Heterocedasticidade",
        "S3": "üìà Autocorrela√ß√£o",
        "S4": "üîó Multicolinearidade",
        "S5": "üìê Normalidade e Forma Funcional",
        "S6": "üîÑ Estabilidade e Constru√ß√£o",
        "S7": "üèõÔ∏è Caso: Ratings Soberanos",
        "S8": "üìã Resumo e Pr√≥ximos Passos"
    }
    
    secao_selecionada = st.sidebar.radio(
        "Selecione a se√ß√£o:",
        list(secoes.keys()),
        format_func=lambda x: secoes[x]
    )
    
    st.sidebar.markdown("---")
    st.sidebar.info("""
    üí° **Dica:** Diagn√≥sticos s√£o essenciais 
    para confiar nos resultados do modelo.
    """)
    
    # Renderizar se√ß√£o selecionada
    if secao_selecionada == "S1":
        render_section_S1()
    elif secao_selecionada == "S2":
        render_section_S2()
    elif secao_selecionada == "S3":
        render_section_S3()
    elif secao_selecionada == "S4":
        render_section_S4()
    elif secao_selecionada == "S5":
        render_section_S5()
    elif secao_selecionada == "S6":
        render_section_S6()
    elif secao_selecionada == "S7":
        render_section_S7()
    elif secao_selecionada == "S8":
        render_section_S8()


# =============================================================================
# EXECU√á√ÉO STANDALONE (para testes)
# =============================================================================

if __name__ == "__main__":
    try:
        st.set_page_config(
            page_title="M√≥dulo 4: Diagn√≥sticos do CLRM",
            page_icon="üîç",
            layout="wide"
        )
    except st.errors.StreamlitAPIException:
        pass
    render()