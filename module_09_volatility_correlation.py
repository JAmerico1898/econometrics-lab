"""
Laborat√≥rio de Econometria - Module 9: Modelling Volatility and Correlation
Aplicativo educacional interativo para GARCH, volatilidade condicional e correla√ß√£o din√¢mica.
P√∫blico-alvo: alunos de MBA com perfis quantitativos heterog√™neos.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy import stats

# =============================================================================
# FUN√á√ïES AUXILIARES PARA SIMULA√á√ÉO E C√ÅLCULOS
# =============================================================================

def simulate_returns_stylized(n: int = 500, garch_alpha: float = 0.1, 
                              garch_beta: float = 0.85, seed: int = 42) -> dict:
    """
    Simula retornos com caracter√≠sticas estilizadas:
    - Volatility clustering
    - Caudas pesadas
    - Efeito alavancagem (assimetria)
    """
    np.random.seed(seed)
    
    # Simular GARCH(1,1) com assimetria
    omega = 0.00001
    alpha = garch_alpha
    beta = garch_beta
    gamma = 0.05  # Assimetria
    
    h = np.zeros(n)
    r = np.zeros(n)
    z = np.random.standard_t(df=5, size=n)  # Caudas pesadas
    
    h[0] = omega / (1 - alpha - beta)
    r[0] = np.sqrt(h[0]) * z[0]
    
    for t in range(1, n):
        # GJR-GARCH
        leverage = gamma * (r[t-1] < 0) * r[t-1]**2
        h[t] = omega + alpha * r[t-1]**2 + beta * h[t-1] + leverage
        h[t] = max(h[t], 1e-8)
        r[t] = np.sqrt(h[t]) * z[t]
    
    # Escalar para % (retornos di√°rios t√≠picos)
    r = r * 100
    
    return {
        'returns': r,
        'variance': h * 10000,
        'volatility': np.sqrt(h) * 100
    }


def compute_hist_vol(returns: np.ndarray, window: int = 20) -> np.ndarray:
    """Calcula volatilidade hist√≥rica com janela m√≥vel."""
    n = len(returns)
    vol = np.full(n, np.nan)
    
    for t in range(window, n):
        vol[t] = np.std(returns[t-window:t], ddof=1)
    
    return vol


def compute_ewma_vol(returns: np.ndarray, lambd: float = 0.94) -> np.ndarray:
    """Calcula volatilidade EWMA (RiskMetrics)."""
    n = len(returns)
    var = np.zeros(n)
    
    # Inicializar com vari√¢ncia amostral dos primeiros 20 obs
    var[0] = np.var(returns[:min(20, n)])
    
    for t in range(1, n):
        var[t] = lambd * var[t-1] + (1 - lambd) * returns[t-1]**2
    
    return np.sqrt(var)


def simulate_garch(n: int = 300, omega: float = 0.00001, alpha: float = 0.1, 
                   beta: float = 0.85, seed: int = 42) -> dict:
    """Simula GARCH(1,1) puro."""
    np.random.seed(seed)
    
    h = np.zeros(n)
    r = np.zeros(n)
    z = np.random.normal(0, 1, n)
    
    # Vari√¢ncia incondicional
    if alpha + beta < 1:
        h[0] = omega / (1 - alpha - beta)
    else:
        h[0] = omega
    
    r[0] = np.sqrt(h[0]) * z[0]
    
    for t in range(1, n):
        h[t] = omega + alpha * r[t-1]**2 + beta * h[t-1]
        h[t] = max(h[t], 1e-10)
        r[t] = np.sqrt(h[t]) * z[t]
    
    # Escalar
    r = r * 100
    h = h * 10000
    
    return {
        'returns': r,
        'variance': h,
        'volatility': np.sqrt(h)
    }


def fit_garch_mle_simple(returns: np.ndarray, omega_init: float = 0.01,
                         alpha_init: float = 0.1, beta_init: float = 0.8) -> dict:
    """
    Ajusta GARCH(1,1) por m√°xima verossimilhan√ßa (simplificado).
    Usa grid search para demonstra√ß√£o did√°tica.
    """
    r = returns / 100  # Desescalar
    n = len(r)
    
    best_ll = -np.inf
    best_params = None
    
    # Grid search simplificado
    for alpha in np.arange(0.02, 0.25, 0.02):
        for beta in np.arange(0.7, 0.95, 0.02):
            if alpha + beta >= 0.999:
                continue
            
            omega = np.var(r) * (1 - alpha - beta)
            omega = max(omega, 1e-8)
            
            # Calcular vari√¢ncia condicional
            h = np.zeros(n)
            h[0] = np.var(r)
            
            for t in range(1, n):
                h[t] = omega + alpha * r[t-1]**2 + beta * h[t-1]
                h[t] = max(h[t], 1e-10)
            
            # Log-verossimilhan√ßa (normal)
            ll = -0.5 * np.sum(np.log(h) + r**2 / h)
            
            if ll > best_ll:
                best_ll = ll
                best_params = {'omega': omega, 'alpha': alpha, 'beta': beta}
    
    if best_params is None:
        best_params = {'omega': omega_init, 'alpha': alpha_init, 'beta': beta_init}
        best_ll = -np.inf
    
    # Calcular vari√¢ncia condicional com melhores par√¢metros
    h = np.zeros(n)
    h[0] = np.var(r)
    for t in range(1, n):
        h[t] = best_params['omega'] + best_params['alpha'] * r[t-1]**2 + best_params['beta'] * h[t-1]
        h[t] = max(h[t], 1e-10)
    
    return {
        'omega': best_params['omega'],
        'alpha': best_params['alpha'],
        'beta': best_params['beta'],
        'persistence': best_params['alpha'] + best_params['beta'],
        'log_likelihood': best_ll,
        'variance': h * 10000,
        'volatility': np.sqrt(h) * 100
    }


def arch_effects_test(returns: np.ndarray, lags: int = 5) -> dict:
    """
    Teste de efeitos ARCH (Engle's ARCH-LM test).
    Regressa res√≠duos¬≤ em seus lags e testa signific√¢ncia conjunta.
    """
    r2 = returns**2
    n = len(r2)
    
    # Construir matriz de lags
    y = r2[lags:]
    X = np.column_stack([np.ones(n - lags)] + [r2[lags-i-1:n-i-1] for i in range(lags)])
    
    # OLS
    XtX_inv = np.linalg.inv(X.T @ X)
    beta = XtX_inv @ X.T @ y
    y_hat = X @ beta
    residuals = y - y_hat
    
    # R¬≤
    sse = np.sum(residuals**2)
    sst = np.sum((y - np.mean(y))**2)
    r_squared = 1 - sse / sst
    
    # Estat√≠stica LM = n * R¬≤
    lm_stat = (n - lags) * r_squared
    p_value = 1 - stats.chi2.cdf(lm_stat, lags)
    
    return {
        'lm_stat': lm_stat,
        'p_value': p_value,
        'r_squared': r_squared,
        'lags': lags
    }


def simulate_asymmetric_garch(n: int = 300, omega: float = 0.00001, alpha: float = 0.05,
                               beta: float = 0.85, gamma: float = 0.1, 
                               model: str = 'GJR', seed: int = 42) -> dict:
    """Simula GJR-GARCH ou EGARCH com assimetria."""
    np.random.seed(seed)
    
    h = np.zeros(n)
    r = np.zeros(n)
    z = np.random.normal(0, 1, n)
    
    h[0] = omega / (1 - alpha - beta - gamma/2) if (alpha + beta + gamma/2) < 1 else omega * 10
    r[0] = np.sqrt(h[0]) * z[0]
    
    for t in range(1, n):
        if model == 'GJR':
            # GJR-GARCH: termo adicional se retorno negativo
            indicator = 1 if r[t-1] < 0 else 0
            h[t] = omega + alpha * r[t-1]**2 + gamma * indicator * r[t-1]**2 + beta * h[t-1]
        else:
            # EGARCH simplificado (em vari√¢ncia, n√£o log)
            shock = np.abs(r[t-1]) / np.sqrt(max(h[t-1], 1e-10))
            asym = gamma * r[t-1] / np.sqrt(max(h[t-1], 1e-10))
            h[t] = omega + alpha * shock**2 * h[t-1] + beta * h[t-1] + asym * h[t-1]
        
        h[t] = max(h[t], 1e-10)
        r[t] = np.sqrt(h[t]) * z[t]
    
    r = r * 100
    h = h * 10000
    
    return {
        'returns': r,
        'variance': h,
        'volatility': np.sqrt(h)
    }


def news_impact_curve(omega: float, alpha: float, beta: float, gamma: float = 0.0,
                      h_prev: float = 1.0) -> dict:
    """Calcula curva de impacto de not√≠cias (News Impact Curve)."""
    shocks = np.linspace(-3, 3, 100)
    
    # GARCH sim√©trico
    h_symmetric = omega + alpha * shocks**2 + beta * h_prev
    
    # GJR assim√©trico
    h_asymmetric = np.where(
        shocks < 0,
        omega + (alpha + gamma) * shocks**2 + beta * h_prev,
        omega + alpha * shocks**2 + beta * h_prev
    )
    
    return {
        'shocks': shocks,
        'h_symmetric': h_symmetric,
        'h_asymmetric': h_asymmetric
    }


def simulate_time_varying_corr(n: int = 300, base_corr: float = 0.5, 
                               crisis_corr: float = 0.9, crisis_start: int = 150,
                               crisis_end: int = 200, seed: int = 42) -> dict:
    """Simula dois ativos com correla√ß√£o que muda no tempo."""
    np.random.seed(seed)
    
    # Correla√ß√£o variante no tempo
    rho = np.full(n, base_corr)
    rho[crisis_start:crisis_end] = crisis_corr
    
    # Suavizar transi√ß√£o
    for t in range(crisis_start, min(crisis_start + 10, n)):
        rho[t] = base_corr + (crisis_corr - base_corr) * (t - crisis_start) / 10
    for t in range(crisis_end - 10, crisis_end):
        rho[t] = crisis_corr - (crisis_corr - base_corr) * (crisis_end - t) / 10
    
    # Volatilidades
    vol1 = np.full(n, 0.01)
    vol2 = np.full(n, 0.015)
    vol1[crisis_start:crisis_end] = 0.025
    vol2[crisis_start:crisis_end] = 0.03
    
    # Gerar retornos correlacionados
    r1 = np.zeros(n)
    r2 = np.zeros(n)
    
    for t in range(n):
        z1 = np.random.normal()
        z2 = rho[t] * z1 + np.sqrt(1 - rho[t]**2) * np.random.normal()
        r1[t] = vol1[t] * z1
        r2[t] = vol2[t] * z2
    
    return {
        'r1': r1 * 100,
        'r2': r2 * 100,
        'vol1': vol1 * 100,
        'vol2': vol2 * 100,
        'true_corr': rho
    }


def compute_dcc_proxy(r1: np.ndarray, r2: np.ndarray, lambd: float = 0.94) -> np.ndarray:
    """
    Aproxima√ß√£o did√°tica de DCC usando EWMA para covari√¢ncia.
    """
    n = len(r1)
    
    # EWMA para vari√¢ncias
    var1 = compute_ewma_vol(r1, lambd)**2
    var2 = compute_ewma_vol(r2, lambd)**2
    
    # EWMA para covari√¢ncia
    cov = np.zeros(n)
    cov[0] = np.cov(r1[:20], r2[:20])[0, 1] if n > 20 else r1[0] * r2[0]
    
    for t in range(1, n):
        cov[t] = lambd * cov[t-1] + (1 - lambd) * r1[t-1] * r2[t-1]
    
    # Correla√ß√£o condicional
    corr = cov / (np.sqrt(var1) * np.sqrt(var2) + 1e-10)
    corr = np.clip(corr, -0.999, 0.999)
    
    return corr


def compute_dynamic_hedge_ratio(r_asset: np.ndarray, r_hedge: np.ndarray, 
                                 lambd: float = 0.94) -> np.ndarray:
    """Calcula hedge ratio din√¢mico: h = Cov(asset, hedge) / Var(hedge)."""
    n = len(r_asset)
    
    # EWMA para vari√¢ncia do hedge
    var_hedge = compute_ewma_vol(r_hedge, lambd)**2
    
    # EWMA para covari√¢ncia
    cov = np.zeros(n)
    cov[0] = np.cov(r_asset[:20], r_hedge[:20])[0, 1] if n > 20 else 0
    
    for t in range(1, n):
        cov[t] = lambd * cov[t-1] + (1 - lambd) * r_asset[t-1] * r_hedge[t-1]
    
    # Hedge ratio
    h = cov / (var_hedge + 1e-10)
    
    return h


def compute_time_varying_beta(r_asset: np.ndarray, r_market: np.ndarray,
                               lambd: float = 0.94) -> np.ndarray:
    """Calcula beta variante no tempo usando EWMA."""
    return compute_dynamic_hedge_ratio(r_asset, r_market, lambd)


def compute_var_models(returns: np.ndarray, confidence: float = 0.95) -> dict:
    """Calcula VaR usando diferentes m√©todos."""
    n = len(returns)
    
    # VaR Hist√≥rico (janela de 60 dias)
    var_hist = np.full(n, np.nan)
    window = 60
    for t in range(window, n):
        var_hist[t] = -np.percentile(returns[t-window:t], (1 - confidence) * 100)
    
    # VaR EWMA
    vol_ewma = compute_ewma_vol(returns, 0.94)
    z_score = stats.norm.ppf(confidence)
    var_ewma = vol_ewma * z_score
    
    # VaR GARCH (simplificado - usando EWMA como proxy)
    var_garch = var_ewma * 1.05  # Ajuste para simular diferen√ßa
    
    return {
        'var_hist': var_hist,
        'var_ewma': var_ewma,
        'var_garch': var_garch
    }


def backtest_var_exceedances(returns: np.ndarray, var: np.ndarray) -> dict:
    """Backtest de VaR: conta viola√ß√µes."""
    # Viola√ß√£o quando perda > VaR
    violations = (-returns) > var
    
    # Desconsiderar NaN
    valid = ~np.isnan(var)
    n_valid = np.sum(valid)
    n_violations = np.sum(violations & valid)
    
    violation_rate = n_violations / n_valid if n_valid > 0 else 0
    
    return {
        'n_violations': n_violations,
        'n_observations': n_valid,
        'violation_rate': violation_rate,
        'violations': violations
    }


# =============================================================================
# FUN√á√ïES DE RENDERIZA√á√ÉO POR SE√á√ÉO
# =============================================================================

def render_section_S1():
    """S1: Por que a volatilidade importa? (fatos estilizados)"""
    st.header("üìä Por que a Volatilidade Importa?")
    
    st.markdown("""
    Modelos lineares com vari√¢ncia constante **falham em finan√ßas** porque:
    - Volatilidade varia ao longo do tempo
    - Retornos t√™m caudas pesadas
    - Quedas geram mais volatilidade que altas
    """)
    
    tab1, tab2, tab3 = st.tabs(["üìà Clustering", "üìä Caudas Pesadas", "‚ÜòÔ∏è Alavancagem"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Volatility Clustering")
            
            st.markdown("""
            **Fato estilizado #1:**
            > "Grandes retornos tendem a ser seguidos por grandes retornos"
            
            Per√≠odos de alta volatilidade se agrupam:
            - Crises: sequ√™ncia de dias turbulentos
            - Calmaria: sequ√™ncia de dias tranquilos
            
            **Implica√ß√£o:** Volatilidade de ontem prev√™ volatilidade de hoje.
            """)
        
        with col2:
            data = simulate_returns_stylized(n=400, seed=42)
            
            fig = make_subplots(rows=2, cols=1,
                               subplot_titles=["Retornos", "Volatilidade Condicional"],
                               row_heights=[0.5, 0.5])
            
            fig.add_trace(go.Scatter(y=data['returns'], mode='lines',
                                    line=dict(width=0.8)), row=1, col=1)
            fig.add_trace(go.Scatter(y=data['volatility'], mode='lines',
                                    line=dict(color='red')), row=2, col=1)
            
            fig.update_layout(height=400, showlegend=False)
            fig.update_yaxes(title_text="Retorno (%)", row=1, col=1)
            fig.update_yaxes(title_text="Volatilidade (%)", row=2, col=1)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Caudas Pesadas (Leptocurtose)")
            
            st.markdown("""
            **Fato estilizado #2:**
            > "Eventos extremos s√£o mais frequentes que a Normal prev√™"
            
            - Distribui√ß√£o Normal subestima crashes
            - Retornos t√™m curtose > 3 (leptocurtose)
            - VaR baseado em Normal √© otimista demais
            
            **Implica√ß√£o:** Modelos de risco devem considerar caudas pesadas.
            """)
            
            data = simulate_returns_stylized(n=1000, seed=42)
            curtose = stats.kurtosis(data['returns']) + 3
            st.metric("Curtose dos retornos", f"{curtose:.2f}", 
                     help="Normal = 3.0")
        
        with col2:
            # QQ Plot
            fig = go.Figure()
            
            # Quantis te√≥ricos vs emp√≠ricos
            sorted_returns = np.sort(data['returns'])
            theoretical = stats.norm.ppf(np.linspace(0.01, 0.99, len(sorted_returns)))
            
            fig.add_trace(go.Scatter(x=theoretical, y=sorted_returns,
                                    mode='markers', name='Dados', 
                                    marker=dict(size=3, opacity=0.5)))
            
            # Linha 45¬∞
            min_val = min(theoretical.min(), sorted_returns.min())
            max_val = max(theoretical.max(), sorted_returns.max())
            fig.add_trace(go.Scatter(x=[min_val, max_val], y=[min_val, max_val],
                                    mode='lines', name='Normal',
                                    line=dict(color='red', dash='dash')))
            
            fig.update_layout(
                title="QQ-Plot: Retornos vs Normal",
                xaxis_title="Quantis Te√≥ricos (Normal)",
                yaxis_title="Quantis Emp√≠ricos",
                height=350
            )
            st.plotly_chart(fig, use_container_width=True)
            
            st.caption("Pontos afastados da linha = caudas mais pesadas que Normal")
    
    with tab3:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Efeito de Alavancagem")
            
            st.markdown("""
            **Fato estilizado #3:**
            > "Retornos negativos aumentam mais a volatilidade que positivos"
            
            **Por qu√™?**
            - Queda de pre√ßo ‚Üí aumento de alavancagem (d√≠vida/equity)
            - Maior alavancagem ‚Üí maior risco
            - Tamb√©m: feedback comportamental (p√¢nico)
            
            **Implica√ß√£o:** Modelos devem capturar assimetria (GJR, EGARCH).
            """)
        
        with col2:
            # Scatter: retorno vs volatilidade futura
            data = simulate_returns_stylized(n=500, seed=42)
            
            r_lag = data['returns'][:-1]
            vol_next = data['volatility'][1:]
            
            fig = px.scatter(x=r_lag, y=vol_next, opacity=0.5,
                            labels={'x': 'Retorno t', 'y': 'Volatilidade t+1'})
            
            # Linhas de tend√™ncia para cada lado
            neg_mask = r_lag < 0
            pos_mask = r_lag >= 0
            
            if np.sum(neg_mask) > 2:
                z_neg = np.polyfit(r_lag[neg_mask], vol_next[neg_mask], 1)
                x_neg = np.linspace(r_lag[neg_mask].min(), 0, 20)
                fig.add_trace(go.Scatter(x=x_neg, y=z_neg[0]*x_neg + z_neg[1],
                                        mode='lines', name='Negativos',
                                        line=dict(color='red')))
            
            if np.sum(pos_mask) > 2:
                z_pos = np.polyfit(r_lag[pos_mask], vol_next[pos_mask], 1)
                x_pos = np.linspace(0, r_lag[pos_mask].max(), 20)
                fig.add_trace(go.Scatter(x=x_pos, y=z_pos[0]*x_pos + z_pos[1],
                                        mode='lines', name='Positivos',
                                        line=dict(color='green')))
            
            fig.update_layout(title="Assimetria: Efeito Alavancagem", height=350)
            st.plotly_chart(fig, use_container_width=True)
    
    with st.expander("üíº Conex√£o com Decis√µes"):
        st.markdown("""
        **VaR (Value-at-Risk):**
        - Caudas pesadas ‚Üí VaR Normal subestima perdas extremas
        - Clustering ‚Üí VaR deve variar no tempo
        
        **Op√ß√µes (Black-Scholes):**
        - BS assume volatilidade constante
        - Smile de volatilidade: mercado precifica vol diferente por strike
        - Modelos GARCH melhoram precifica√ß√£o
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa modelos que capturam volatilidade vari√°vel
    - N√£o confia em VaR baseado em Normal
    - Monitora clustering para ajustar limites de risco
    """)


def render_section_S2():
    """S2: Da volatilidade hist√≥rica ao EWMA"""
    st.header("üìè Volatilidade Hist√≥rica vs EWMA")
    
    st.markdown("""
    Antes de GARCH, vamos comparar m√©todos mais simples:
    - **Hist√≥rica:** Desvio padr√£o de uma janela fixa
    - **EWMA:** M√©dia ponderada exponencial (RiskMetrics)
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Par√¢metros")
        
        window = st.slider("Janela hist√≥rica (dias)", 10, 60, 20, key="window_hist")
        lambd = st.slider("Lambda EWMA", 0.85, 0.99, 0.94, 0.01, key="lambda_ewma",
                         help="RiskMetrics usa Œª=0.94")
        
        st.markdown("""
        **Volatilidade Hist√≥rica:**
        - Todos os dias na janela t√™m peso igual
        - Reage lentamente a choques
        - Demora para "esquecer" eventos antigos
        
        **EWMA:**
        - Pesos decrescem exponencialmente
        - Reage mais r√°pido a choques recentes
        - N√£o tem n√≠vel de "longo prazo"
        """)
    
    with col2:
        # Simular dados com um choque
        np.random.seed(42)
        n = 200
        returns = np.random.normal(0, 1, n)
        # Adicionar choque
        returns[100:110] = returns[100:110] * 4  # Per√≠odo de alta vol
        
        vol_hist = compute_hist_vol(returns, window)
        vol_ewma = compute_ewma_vol(returns, lambd)
        
        fig = make_subplots(rows=2, cols=1,
                           subplot_titles=["Retornos (com choque)", "Volatilidade Estimada"],
                           row_heights=[0.4, 0.6])
        
        fig.add_trace(go.Scatter(y=returns, mode='lines', name='Retornos',
                                line=dict(width=0.8)), row=1, col=1)
        
        fig.add_trace(go.Scatter(y=vol_hist, mode='lines', name=f'Hist√≥rica ({window}d)',
                                line=dict(color='blue')), row=2, col=1)
        fig.add_trace(go.Scatter(y=vol_ewma, mode='lines', name=f'EWMA (Œª={lambd})',
                                line=dict(color='red')), row=2, col=1)
        
        # Marcar per√≠odo de choque
        fig.add_vrect(x0=100, x1=110, fillcolor="yellow", opacity=0.2,
                     annotation_text="Choque", row=1, col=1)
        fig.add_vrect(x0=100, x1=110, fillcolor="yellow", opacity=0.2, row=2, col=1)
        
        fig.update_layout(height=450)
        st.plotly_chart(fig, use_container_width=True, key=f"vol_comp_{window}_{lambd}")
    
    # Compara√ß√£o de VaR
    st.subheader("Impacto no VaR (95%)")
    
    z_95 = stats.norm.ppf(0.95)
    var_hist = vol_hist * z_95
    var_ewma = vol_ewma * z_95
    
    col1, col2, col3 = st.columns(3)
    col1.metric("VaR Hist√≥rico (m√©dia)", f"{np.nanmean(var_hist):.2f}%")
    col2.metric("VaR EWMA (m√©dia)", f"{np.nanmean(var_ewma):.2f}%")
    col3.metric("VaR EWMA no pico", f"{np.nanmax(var_ewma):.2f}%")
    
    with st.expander("üìñ Limita√ß√µes"):
        st.markdown("""
        **Hist√≥rica:**
        - Ghost effect: choque antigo continua afetando at√© sair da janela
        - Rea√ß√£o em degrau (n√£o suave)
        
        **EWMA:**
        - N√£o tem revers√£o √† m√©dia
        - Ap√≥s choque, volatilidade s√≥ cai se retornos forem pequenos
        - N√£o captura bem a din√¢mica de longo prazo
        """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - EWMA √© melhor que hist√≥rica para reagir a mudan√ßas
    - Mas GARCH √© ainda melhor para capturar din√¢mica completa
    """)


def render_section_S3():
    """S3: GARCH(1,1): risco que muda com o tempo"""
    st.header("üìà GARCH(1,1): Risco que Muda com o Tempo")
    
    st.markdown("""
    **GARCH (Generalized AutoRegressive Conditional Heteroskedasticity)**
    combina mem√≥ria (persist√™ncia) com rea√ß√£o a choques.
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Intui√ß√£o do GARCH(1,1)")
        
        st.markdown("""
        **Equa√ß√£o:**
        $$h_t = \\omega + \\alpha \\cdot r_{t-1}^2 + \\beta \\cdot h_{t-1}$$
        
        **Componentes:**
        - **œâ (omega):** N√≠vel base de vari√¢ncia
        - **Œ± (alpha):** Rea√ß√£o ao choque de ontem
        - **Œ≤ (beta):** Persist√™ncia (mem√≥ria)
        
        **Persist√™ncia:** Œ± + Œ≤
        - Pr√≥ximo de 1 = alta mem√≥ria
        - < 1 = reverte √† m√©dia de longo prazo
        
        **Vari√¢ncia incondicional:**
        $$\\bar{h} = \\frac{\\omega}{1 - \\alpha - \\beta}$$
        """)
        
        st.subheader("Simulador")
        
        alpha = st.slider("Œ± (choque)", 0.01, 0.3, 0.1, 0.01, key="alpha_garch")
        beta = st.slider("Œ≤ (persist√™ncia)", 0.5, 0.95, 0.85, 0.01, key="beta_garch")
        
        persistence = alpha + beta
        
        if persistence >= 1:
            st.error(f"‚ö†Ô∏è Œ± + Œ≤ = {persistence:.2f} ‚â• 1: Processo explosivo!")
        else:
            st.success(f"‚úÖ Persist√™ncia: Œ± + Œ≤ = {persistence:.2f}")
    
    with col2:
        omega = 0.00001  # Fixo para simplicidade
        
        if alpha + beta < 1:
            data = simulate_garch(n=300, omega=omega, alpha=alpha, beta=beta, seed=42)
            
            fig = make_subplots(rows=2, cols=1,
                               subplot_titles=["Retornos Simulados", "Vari√¢ncia Condicional h_t"],
                               row_heights=[0.5, 0.5])
            
            fig.add_trace(go.Scatter(y=data['returns'], mode='lines',
                                    line=dict(width=0.8)), row=1, col=1)
            fig.add_trace(go.Scatter(y=data['variance'], mode='lines',
                                    line=dict(color='red')), row=2, col=1)
            
            # Vari√¢ncia incondicional
            h_bar = omega * 10000 / (1 - alpha - beta)
            fig.add_hline(y=h_bar, line_dash="dash", line_color="green",
                         annotation_text=f"hÃÑ = {h_bar:.4f}", row=2, col=1)
            
            fig.update_layout(height=450, showlegend=False)
            fig.update_yaxes(title_text="Retorno (%)", row=1, col=1)
            fig.update_yaxes(title_text="Vari√¢ncia", row=2, col=1)
            st.plotly_chart(fig, use_container_width=True, key=f"garch_{alpha}_{beta}")
            
            # Meia-vida
            half_life = np.log(0.5) / np.log(persistence)
            st.metric("Meia-vida do choque", f"{half_life:.1f} dias",
                     help="Tempo para efeito de choque reduzir pela metade")
        else:
            st.warning("Ajuste os par√¢metros para Œ± + Œ≤ < 1")
    
    # Quiz
    st.subheader("üß™ Quiz")
    
    st.markdown("Se Œ± = 0.05 e Œ≤ = 0.90, qual √© a persist√™ncia e o que isso significa?")
    
    resposta = st.radio(
        "Selecione:",
        ["0.95 - volatilidade muda muito r√°pido",
         "0.95 - choques demoram muito para dissipar",
         "0.85 - volatilidade √© praticamente constante"],
        key="quiz_garch"
    )
    
    if st.button("Ver resposta", key="btn_garch"):
        if resposta == "0.95 - choques demoram muito para dissipar":
            st.success("""
            ‚úÖ **Correto!**
            
            Persist√™ncia = 0.05 + 0.90 = 0.95
            
            Alta persist√™ncia significa que choques t√™m efeito duradouro.
            Meia-vida ‚âà 14 dias.
            """)
        else:
            st.error("A persist√™ncia √© 0.95, e valores pr√≥ximos de 1 indicam mem√≥ria longa.")
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa Œ± + Œ≤ para entender qu√£o r√°pido risco muda
    - Alta persist√™ncia ‚Üí ajustes de hedge mais frequentes
    - GARCH permite previs√£o de volatilidade para VaR e op√ß√µes
    """)


def render_section_S4():
    """S4: Estima√ß√£o e Diagn√≥stico (funciona mesmo?)"""
    st.header("üîß Estima√ß√£o e Diagn√≥stico")
    
    tab1, tab2, tab3 = st.tabs(["üìä M√°xima Verossimilhan√ßa", "üß™ Teste ARCH", "‚úÖ Checklist"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("M√°xima Verossimilhan√ßa (MLE)")
            
            st.markdown("""
            **Intui√ß√£o:**
            > "Encontrar os par√¢metros que tornam os dados observados mais prov√°veis"
            
            **Log-verossimilhan√ßa Normal:**
            $$\\ell = -\\frac{1}{2} \\sum_t \\left( \\log h_t + \\frac{r_t^2}{h_t} \\right)$$
            
            **Processo:**
            1. Chutar valores iniciais de œâ, Œ±, Œ≤
            2. Calcular h_t para toda a s√©rie
            3. Calcular log-verossimilhan√ßa
            4. Otimizar (maximizar ‚Ñì)
            
            **Cuidado:** √ìtimos locais! Resultado pode depender do ponto inicial.
            """)
            
            seed_data = st.slider("Seed dos dados", 1, 100, 42, key="seed_mle")
        
        with col2:
            # Simular e estimar
            true_alpha = 0.10
            true_beta = 0.85
            
            data = simulate_garch(n=500, alpha=true_alpha, beta=true_beta, seed=seed_data)
            
            # Estimar
            result = fit_garch_mle_simple(data['returns'])
            
            st.markdown("**Par√¢metros Verdadeiros vs Estimados:**")
            
            comp_df = pd.DataFrame({
                'Par√¢metro': ['Œ±', 'Œ≤', 'Persist√™ncia'],
                'Verdadeiro': [true_alpha, true_beta, true_alpha + true_beta],
                'Estimado': [result['alpha'], result['beta'], result['persistence']]
            })
            st.dataframe(comp_df, use_container_width=True, hide_index=True)
            
            st.metric("Log-Verossimilhan√ßa", f"{result['log_likelihood']:.1f}")
            
            # Plot
            fig = go.Figure()
            fig.add_trace(go.Scatter(y=np.sqrt(data['variance']), mode='lines',
                                    name='Verdadeira'))
            fig.add_trace(go.Scatter(y=result['volatility'], mode='lines',
                                    name='Estimada', line=dict(dash='dash')))
            fig.update_layout(title="Volatilidade: Verdadeira vs Estimada", height=300)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Teste de Efeitos ARCH")
            
            st.markdown("""
            **Pergunta:** "H√° heterocedasticidade condicional nos dados?"
            
            **Teste ARCH-LM (Engle):**
            1. Regressa r¬≤ contra seus lags
            2. Testa se coeficientes s√£o conjuntamente zero
            
            **Hip√≥teses:**
            - H‚ÇÄ: Sem efeitos ARCH (vari√¢ncia constante)
            - H‚ÇÅ: H√° efeitos ARCH (vari√¢ncia muda)
            
            **Decis√£o:**
            - p < 0.05: Rejeita H‚ÇÄ ‚Üí Use GARCH!
            - p ‚â• 0.05: N√£o rejeita H‚ÇÄ ‚Üí GARCH pode ser overkill
            """)
            
            lags_test = st.slider("N√∫mero de lags", 1, 10, 5, key="lags_arch")
        
        with col2:
            # Testar nos dados simulados
            data = simulate_garch(n=500, alpha=0.1, beta=0.85, seed=42)
            arch_test = arch_effects_test(data['returns'], lags=lags_test)
            
            st.markdown("**Resultado do Teste ARCH-LM:**")
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("LM Statistic", f"{arch_test['lm_stat']:.2f}")
            col_m2.metric("p-valor", f"{arch_test['p_value']:.4f}")
            
            if arch_test['p_value'] < 0.05:
                st.success("‚úÖ Rejeita H‚ÇÄ: H√° efeitos ARCH ‚Äî GARCH √© justificado!")
            else:
                st.info("N√£o rejeita H‚ÇÄ: Talvez GARCH n√£o seja necess√°rio.")
            
            # Comparar com dados sem ARCH
            st.markdown("---")
            st.markdown("**Compara√ß√£o: Dados com vs sem efeitos ARCH**")
            
            np.random.seed(42)
            returns_no_arch = np.random.normal(0, 1, 500)
            arch_test_no = arch_effects_test(returns_no_arch, lags=lags_test)
            
            comp_df = pd.DataFrame({
                'Dados': ['GARCH (com ARCH)', 'Normal (sem ARCH)'],
                'LM Stat': [arch_test['lm_stat'], arch_test_no['lm_stat']],
                'p-valor': [arch_test['p_value'], arch_test_no['p_value']]
            })
            st.dataframe(comp_df, use_container_width=True, hide_index=True)
    
    with tab3:
        st.subheader("Checklist: Quando Usar GARCH?")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **‚úÖ Use GARCH quando:**
            - Retornos mostram clustering de volatilidade
            - Teste ARCH rejeita H‚ÇÄ
            - Previs√£o de volatilidade √© importante
            - Precifica√ß√£o de derivativos
            - C√°lculo de VaR din√¢mico
            """)
        
        with col2:
            st.markdown("""
            **‚ùå GARCH √© overkill quando:**
            - S√©rie √© muito curta (< 100 obs)
            - N√£o h√° evid√™ncia de clustering
            - Teste ARCH n√£o rejeita H‚ÇÄ
            - Volatilidade parece constante
            - Objetivo √© apenas m√©dia condicional
            """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Sempre testa efeitos ARCH antes de modelar
    - Usa m√∫ltiplos pontos iniciais na estima√ß√£o
    - Verifica se modelo estimado faz sentido econ√¥mico
    """)


def render_section_S5():
    """S5: Assimetria: quedas doem mais (GJR/EGARCH)"""
    st.header("‚ÜòÔ∏è Assimetria: Quedas Doem Mais")
    
    st.markdown("""
    GARCH sim√©trico trata choques positivos e negativos igualmente.
    Mas em finan√ßas, **quedas aumentam mais a volatilidade** (efeito alavancagem).
    """)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Modelos Assim√©tricos")
        
        st.markdown("""
        **GJR-GARCH:**
        $$h_t = \\omega + (\\alpha + \\gamma \\cdot I_{t-1}) r_{t-1}^2 + \\beta h_{t-1}$$
        
        Onde I = 1 se r < 0 (retorno negativo).
        
        **EGARCH (em log):**
        $$\\log h_t = \\omega + \\alpha |z_{t-1}| + \\gamma z_{t-1} + \\beta \\log h_{t-1}$$
        
        **Par√¢metro Œ≥ (gamma):**
        - Œ≥ > 0: Retornos negativos aumentam mais a volatilidade
        - Œ≥ = 0: Sim√©trico (GARCH padr√£o)
        """)
        
        gamma = st.slider("Œ≥ (assimetria)", 0.0, 0.2, 0.1, 0.02, key="gamma_gjr")
        model = st.radio("Modelo:", ["GJR", "EGARCH"], horizontal=True, key="model_asym")
    
    with col2:
        # Simular
        data = simulate_asymmetric_garch(n=300, gamma=gamma, model=model, seed=42)
        
        fig = make_subplots(rows=2, cols=1,
                           subplot_titles=["Retornos", f"Volatilidade ({model})"],
                           row_heights=[0.5, 0.5])
        
        fig.add_trace(go.Scatter(y=data['returns'], mode='lines',
                                line=dict(width=0.8)), row=1, col=1)
        fig.add_trace(go.Scatter(y=data['volatility'], mode='lines',
                                line=dict(color='red')), row=2, col=1)
        
        fig.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig, use_container_width=True, key=f"asym_{gamma}_{model}")
    
    # News Impact Curve
    st.subheader("Curva de Impacto de Not√≠cias")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        **News Impact Curve:**
        > "Como a volatilidade de amanh√£ responde a choques de diferentes tamanhos?"
        
        - Eixo X: Tamanho do choque (r_{t-1})
        - Eixo Y: Vari√¢ncia futura (h_t)
        
        **Com assimetria:**
        - Curva √© mais √≠ngreme para choques negativos
        - Mesma magnitude, dire√ß√µes opostas ‚Üí efeitos diferentes
        """)
    
    with col2:
        nic = news_impact_curve(omega=0.00001, alpha=0.1, beta=0.85, gamma=gamma)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=nic['shocks'], y=nic['h_symmetric'],
                                mode='lines', name='GARCH Sim√©trico'))
        fig.add_trace(go.Scatter(x=nic['shocks'], y=nic['h_asymmetric'],
                                mode='lines', name=f'GJR (Œ≥={gamma})'))
        fig.add_vline(x=0, line_dash="dash", line_color="gray")
        
        fig.update_layout(
            title="News Impact Curve",
            xaxis_title="Choque (r_{t-1} / œÉ)",
            yaxis_title="Vari√¢ncia h_t",
            height=350
        )
        st.plotly_chart(fig, use_container_width=True, key=f"nic_{gamma}")
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Usa modelos assim√©tricos para risco de queda (downside risk)
    - GJR/EGARCH para VaR e stress testing
    - Importante para prote√ß√£o de portf√≥lios
    """)


def render_section_S6():
    """S6: Correla√ß√£o din√¢mica e aplica√ß√µes estrat√©gicas (DCC, hedge, beta)"""
    st.header("üîó Correla√ß√£o Din√¢mica e Aplica√ß√µes")
    
    st.markdown("""
    Correla√ß√µes entre ativos **mudam no tempo**, especialmente em crises.
    Isso afeta hedge, diversifica√ß√£o e risco de portf√≥lio.
    """)
    
    tab1, tab2, tab3 = st.tabs(["üìä DCC", "üõ°Ô∏è Hedge Din√¢mico", "üìà Beta Variante"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Correla√ß√£o Condicional Din√¢mica")
            
            st.markdown("""
            **DCC-GARCH:**
            - Modela volatilidade de cada ativo (univariado)
            - Depois modela correla√ß√£o que muda no tempo
            
            **Fato estilizado:**
            > "Correla√ß√µes aumentam em crises"
            
            - Em per√≠odos normais: correla√ß√£o moderada
            - Em crises: correla√ß√£o dispara ‚Üí diversifica√ß√£o falha
            """)
            
            base_corr = st.slider("Correla√ß√£o base", 0.2, 0.7, 0.5, 0.1, key="base_corr")
            crisis_corr = st.slider("Correla√ß√£o na crise", 0.7, 0.99, 0.9, 0.05, key="crisis_corr")
        
        with col2:
            data = simulate_time_varying_corr(n=300, base_corr=base_corr, 
                                             crisis_corr=crisis_corr, seed=42)
            
            # Calcular DCC proxy
            dcc = compute_dcc_proxy(data['r1'], data['r2'], lambd=0.94)
            
            fig = make_subplots(rows=2, cols=1,
                               subplot_titles=["Retornos dos Ativos", "Correla√ß√£o Condicional"],
                               row_heights=[0.5, 0.5])
            
            fig.add_trace(go.Scatter(y=data['r1'], name='Ativo 1',
                                    line=dict(width=0.8)), row=1, col=1)
            fig.add_trace(go.Scatter(y=data['r2'], name='Ativo 2',
                                    line=dict(width=0.8)), row=1, col=1)
            
            fig.add_trace(go.Scatter(y=data['true_corr'], name='Correla√ß√£o Real',
                                    line=dict(color='green')), row=2, col=1)
            fig.add_trace(go.Scatter(y=dcc, name='DCC Estimada',
                                    line=dict(color='red', dash='dash')), row=2, col=1)
            
            # Marcar crise
            fig.add_vrect(x0=150, x1=200, fillcolor="yellow", opacity=0.2,
                         annotation_text="Crise", row=1, col=1)
            fig.add_vrect(x0=150, x1=200, fillcolor="yellow", opacity=0.2, row=2, col=1)
            
            fig.update_layout(height=450)
            st.plotly_chart(fig, use_container_width=True, key=f"dcc_{base_corr}_{crisis_corr}")
    
    with tab2:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Hedge Ratio Din√¢mico")
            
            st.markdown("""
            **Hedge ratio √≥timo:**
            $$h^* = \\frac{Cov(r_{asset}, r_{hedge})}{Var(r_{hedge})}$$
            
            **Problema:** Com vari√¢ncias e correla√ß√µes que mudam, 
            o hedge ratio tamb√©m deve mudar!
            
            **Exemplo:**
            - Hedge de a√ß√£o com futuro de √≠ndice
            - Correla√ß√£o aumenta em crise ‚Üí hedge ratio muda
            - N√£o ajustar = sub ou sobre-hedging
            """)
        
        with col2:
            data = simulate_time_varying_corr(n=300, base_corr=0.6, 
                                             crisis_corr=0.9, seed=42)
            
            h_ratio = compute_dynamic_hedge_ratio(data['r1'], data['r2'], lambd=0.94)
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(y=h_ratio, mode='lines', name='Hedge Ratio'))
            fig.add_hline(y=np.nanmean(h_ratio), line_dash="dash", line_color="red",
                         annotation_text=f"M√©dia: {np.nanmean(h_ratio):.2f}")
            fig.add_vrect(x0=150, x1=200, fillcolor="yellow", opacity=0.2)
            
            fig.update_layout(
                title="Hedge Ratio Din√¢mico",
                xaxis_title="Tempo",
                yaxis_title="h*",
                height=350
            )
            st.plotly_chart(fig, use_container_width=True)
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("h* na calmaria", f"{np.nanmean(h_ratio[:140]):.2f}")
            col_m2.metric("h* na crise", f"{np.nanmean(h_ratio[150:200]):.2f}")
    
    with tab3:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("Beta Variante no Tempo")
            
            st.markdown("""
            **CAPM assume beta constante:**
            $$r_i = \\alpha + \\beta r_m + \\varepsilon$$
            
            **Na realidade:**
            - Beta muda com condi√ß√µes de mercado
            - Em crises, muitos betas aumentam
            - Subestimar beta em crise = subestimar risco
            
            **Implica√ß√µes:**
            - Aloca√ß√£o de risco incorreta
            - Capital mal dimensionado
            - Limites de risco inadequados
            """)
        
        with col2:
            data = simulate_time_varying_corr(n=300, base_corr=0.6, 
                                             crisis_corr=0.9, seed=42)
            
            beta_tv = compute_time_varying_beta(data['r1'], data['r2'], lambd=0.94)
            
            # Beta fixo (OLS)
            valid = ~np.isnan(beta_tv)
            beta_fix = np.cov(data['r1'][valid], data['r2'][valid])[0, 1] / np.var(data['r2'][valid])
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(y=beta_tv, mode='lines', name='Beta Variante'))
            fig.add_hline(y=beta_fix, line_dash="dash", line_color="red",
                         annotation_text=f"Beta Fixo: {beta_fix:.2f}")
            fig.add_vrect(x0=150, x1=200, fillcolor="yellow", opacity=0.2)
            
            fig.update_layout(
                title="Beta: Fixo vs Variante no Tempo",
                xaxis_title="Tempo",
                yaxis_title="Beta",
                height=350
            )
            st.plotly_chart(fig, use_container_width=True)
            
            col_m1, col_m2 = st.columns(2)
            col_m1.metric("Beta Fixo (OLS)", f"{beta_fix:.2f}")
            col_m2.metric("Beta na Crise", f"{np.nanmean(beta_tv[150:200]):.2f}")
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Ajusta hedge ratio dinamicamente
    - N√£o confia em beta fixo para gest√£o de risco
    - Considera aumento de correla√ß√£o em stress tests
    """)


def render_section_S7():
    """S7: Estudo de Caso MBA: VaR em crise (hist√≥rico vs EWMA vs GARCH)"""
    st.header("üíº Caso MBA: VaR em Crise")
    
    st.markdown("""
    Vamos comparar tr√™s m√©todos de VaR durante um per√≠odo com choque de volatilidade.
    """)
    
    # Simular dados com crise
    np.random.seed(42)
    n = 300
    returns = np.zeros(n)
    
    # Per√≠odo normal
    returns[:150] = np.random.normal(0, 1, 150)
    # Crise
    returns[150:200] = np.random.normal(0, 3, 50)
    # Recupera√ß√£o
    returns[200:] = np.random.normal(0, 1.5, 100)
    
    # Calcular VaR pelos tr√™s m√©todos
    var_models = compute_var_models(returns, confidence=0.95)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Retornos e VaR")
        
        fig = go.Figure()
        
        # Retornos
        fig.add_trace(go.Scatter(y=returns, mode='lines', name='Retornos',
                                line=dict(width=0.8, color='blue')))
        
        # VaRs (negativos para comparar com perdas)
        fig.add_trace(go.Scatter(y=-var_models['var_hist'], mode='lines',
                                name='VaR Hist√≥rico', line=dict(color='green')))
        fig.add_trace(go.Scatter(y=-var_models['var_ewma'], mode='lines',
                                name='VaR EWMA', line=dict(color='orange')))
        fig.add_trace(go.Scatter(y=-var_models['var_garch'], mode='lines',
                                name='VaR GARCH', line=dict(color='red', dash='dash')))
        
        fig.add_vrect(x0=150, x1=200, fillcolor="red", opacity=0.1,
                     annotation_text="Crise")
        
        fig.update_layout(
            title="Retornos vs VaR 95% (3 m√©todos)",
            xaxis_title="Dias",
            yaxis_title="Retorno / -VaR (%)",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("Backtest: Viola√ß√µes")
        
        # Backtest
        bt_hist = backtest_var_exceedances(returns, var_models['var_hist'])
        bt_ewma = backtest_var_exceedances(returns, var_models['var_ewma'])
        bt_garch = backtest_var_exceedances(returns, var_models['var_garch'])
        
        results_df = pd.DataFrame({
            'M√©todo': ['Hist√≥rico', 'EWMA', 'GARCH'],
            'Viola√ß√µes': [bt_hist['n_violations'], bt_ewma['n_violations'], bt_garch['n_violations']],
            'Taxa': [f"{bt_hist['violation_rate']*100:.1f}%", 
                    f"{bt_ewma['violation_rate']*100:.1f}%",
                    f"{bt_garch['violation_rate']*100:.1f}%"],
            'Esperado (5%)': ['5%', '5%', '5%']
        })
        st.dataframe(results_df, use_container_width=True, hide_index=True)
        
        st.markdown("""
        **Interpreta√ß√£o:**
        - Taxa > 5%: Modelo subestima risco
        - Taxa < 5%: Modelo √© conservador
        - Taxa ‚âà 5%: Modelo bem calibrado
        """)
        
        # Viola√ß√µes no tempo
        fig2 = go.Figure()
        
        violations_hist = bt_hist['violations'].astype(int)
        violations_ewma = bt_ewma['violations'].astype(int)
        
        fig2.add_trace(go.Scatter(y=np.cumsum(violations_hist), mode='lines',
                                 name='Hist√≥rico'))
        fig2.add_trace(go.Scatter(y=np.cumsum(violations_ewma), mode='lines',
                                 name='EWMA'))
        
        # Linha esperada
        expected = np.arange(n) * 0.05
        fig2.add_trace(go.Scatter(y=expected, mode='lines', name='Esperado (5%)',
                                 line=dict(dash='dash', color='gray')))
        
        fig2.update_layout(
            title="Viola√ß√µes Acumuladas",
            xaxis_title="Dias",
            yaxis_title="# Viola√ß√µes",
            height=300
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    st.subheader("üìã Discuss√£o")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **Trade-offs:**
        - Hist√≥rico: simples, mas lento
        - EWMA: r√°pido, mas sem revers√£o
        - GARCH: completo, mas complexo
        """)
    
    with col2:
        st.markdown("""
        **Custos de Modelo:**
        - Hist√≥rico: quase zero
        - EWMA: baixo
        - GARCH: estima√ß√£o, valida√ß√£o
        """)
    
    with col3:
        st.markdown("""
        **Governan√ßa:**
        - Documentar metodologia
        - Backtest regular
        - Comunicar limita√ß√µes
        """)
    
    st.warning("""
    ‚ö†Ô∏è **Li√ß√£o principal:** Em crises, todos os modelos tendem a falhar inicialmente.
    VaR din√¢mico (EWMA/GARCH) reage mais r√°pido, mas ainda com atraso.
    Stress testing complementa VaR!
    """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - N√£o depende de um √∫nico modelo de VaR
    - Faz backtest regularmente
    - Complementa VaR com stress testing
    - Comunica limita√ß√µes aos stakeholders
    """)


def render_section_S8():
    """S8: Resumo Executivo e Ponte para o Pr√≥ximo M√≥dulo"""
    st.header("üìã Resumo Executivo")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### O que Aprendemos sobre Volatilidade e Correla√ß√£o
        
        ‚úÖ **Fatos Estilizados:**
        - Volatility clustering: turbul√™ncia gera turbul√™ncia
        - Caudas pesadas: eventos extremos mais frequentes
        - Efeito alavancagem: quedas aumentam mais a volatilidade
        
        ‚úÖ **Volatilidade Hist√≥rica vs EWMA:**
        - Hist√≥rica: simples, mas rea√ß√£o lenta
        - EWMA: mais r√°pido, mas sem revers√£o √† m√©dia
        
        ‚úÖ **GARCH(1,1):**
        - h_t = œâ + Œ±¬∑r¬≤_{t-1} + Œ≤¬∑h_{t-1}
        - Persist√™ncia: Œ± + Œ≤ (pr√≥ximo de 1 = mem√≥ria longa)
        - Previs√£o de volatilidade para VaR e op√ß√µes
        
        ‚úÖ **Estima√ß√£o e Diagn√≥stico:**
        - M√°xima verossimilhan√ßa (cuidado com √≥timos locais)
        - Teste ARCH-LM antes de modelar
        
        ‚úÖ **Assimetria (GJR/EGARCH):**
        - Retornos negativos aumentam mais a volatilidade
        - News Impact Curve mostra assimetria
        
        ‚úÖ **Correla√ß√£o Din√¢mica:**
        - DCC: correla√ß√£o aumenta em crises
        - Hedge ratio e beta variam no tempo
        - Diversifica√ß√£o falha quando mais precisamos
        
        ‚úÖ **VaR:**
        - Comparar m√©todos: hist√≥rico, EWMA, GARCH
        - Backtest: verificar viola√ß√µes
        - Complementar com stress testing
        """)
    
    with col2:
        st.markdown("### üí° Mensagem-Chave")
        
        st.info("""
        **"Risco muda com o tempo"**
        
        Modelos com vari√¢ncia constante falham em finan√ßas.
        
        GARCH e DCC capturam din√¢mica de risco essencial para:
        - VaR e limites de risco
        - Hedge e aloca√ß√£o
        - Precifica√ß√£o de derivativos
        """)
        
        st.markdown("### üß™ Quiz Final")
        
        resposta = st.radio(
            "Se Œ± + Œ≤ = 0.98, o que isso significa?",
            ["Volatilidade √© praticamente constante",
             "Choques se dissipam em poucos dias",
             "Choques t√™m efeito muito persistente"],
            key="quiz_final"
        )
        
        if st.button("Ver resposta", key="btn_final"):
            if resposta == "Choques t√™m efeito muito persistente":
                st.success("""
                ‚úÖ **Correto!**
                
                Persist√™ncia de 0.98 significa:
                - Meia-vida ‚âà 34 dias
                - Choques demoram muito para dissipar
                - Volatilidade alta persiste por semanas
                """)
            else:
                st.error("Alta persist√™ncia (pr√≥ximo de 1) = mem√≥ria longa, choques demoram a dissipar.")
    
    st.markdown("---")
    
    st.subheader("üîú Pr√≥ximo M√≥dulo: Dados em Painel")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **Estrutura de Painel:**
        - M√∫ltiplas unidades (empresas, pa√≠ses)
        - M√∫ltiplos per√≠odos
        - Heterogeneidade
        """)
    
    with col2:
        st.markdown("""
        **Modelos:**
        - Efeitos fixos
        - Efeitos aleat√≥rios
        - GMM din√¢mico
        """)
    
    with col3:
        st.markdown("""
        **Aplica√ß√µes:**
        - Finan√ßas corporativas
        - Macroeconomia
        - Organiza√ß√£o industrial
        """)
    
    st.success("""
    üéì **Mensagem final:** Volatilidade e correla√ß√£o n√£o s√£o constantes.
    Modelos din√¢micos (GARCH, DCC) s√£o essenciais para gest√£o de risco moderna.
    Combine com backtest e stress testing para decis√µes robustas.
    """)
    
    st.markdown("""
    ---
    **üéØ O que um gestor faz com isso?**
    - Implementa modelos de volatilidade condicional para VaR
    - Monitora correla√ß√µes em tempo real
    - Ajusta hedge e limites de risco dinamicamente
    - N√£o esquece: modelos falham em crises extremas
    """)


# =============================================================================
# FUN√á√ÉO PRINCIPAL DE RENDERIZA√á√ÉO
# =============================================================================

def render():
    """Fun√ß√£o principal que renderiza o m√≥dulo completo."""
    
    # T√≠tulo e objetivos
    st.title("üìä M√≥dulo 9: Modelagem de Volatilidade e Correla√ß√£o")
    st.markdown("**Laborat√≥rio de Econometria** | GARCH, Assimetria e DCC")
    
    with st.expander("üéØ Objetivos do M√≥dulo", expanded=False):
        st.markdown("""
        - Explicar **fatos estilizados** de retornos financeiros
        - Comparar **volatilidade hist√≥rica** e **EWMA**
        - Introduzir **GARCH(1,1)** como modelo de risco vari√°vel
        - Ensinar **estima√ß√£o** por m√°xima verossimilhan√ßa e **diagn√≥stico**
        - Mostrar **assimetria** (GJR/EGARCH) e impacto de not√≠cias
        - Introduzir **correla√ß√£o din√¢mica** (DCC) e aplica√ß√µes
        - Comparar m√©todos de **VaR** e fazer backtest
        """)
    
    # Sidebar: navega√ß√£o
    st.sidebar.title("üìë Navega√ß√£o")
    
    secoes = {
        "S1": "üìä Fatos Estilizados",
        "S2": "üìè Hist√≥rica vs EWMA",
        "S3": "üìà GARCH(1,1)",
        "S4": "üîß Estima√ß√£o e Diagn√≥stico",
        "S5": "‚ÜòÔ∏è Assimetria",
        "S6": "üîó Correla√ß√£o Din√¢mica",
        "S7": "üíº Caso: VaR",
        "S8": "üìã Resumo"
    }
    
    secao_selecionada = st.sidebar.radio(
        "Selecione a se√ß√£o:",
        list(secoes.keys()),
        format_func=lambda x: secoes[x]
    )
    
    st.sidebar.markdown("---")
    st.sidebar.info("""
    üí° **Dica:** Volatilidade que muda 
    no tempo √© a base da gest√£o 
    de risco moderna em finan√ßas.
    """)
    
    # Renderizar se√ß√£o selecionada
    if secao_selecionada == "S1":
        render_section_S1()
    elif secao_selecionada == "S2":
        render_section_S2()
    elif secao_selecionada == "S3":
        render_section_S3()
    elif secao_selecionada == "S4":
        render_section_S4()
    elif secao_selecionada == "S5":
        render_section_S5()
    elif secao_selecionada == "S6":
        render_section_S6()
    elif secao_selecionada == "S7":
        render_section_S7()
    elif secao_selecionada == "S8":
        render_section_S8()


# =============================================================================
# EXECU√á√ÉO STANDALONE (para testes)
# =============================================================================

if __name__ == "__main__":
    try:
        st.set_page_config(
            page_title="M√≥dulo 9: Volatilidade e Correla√ß√£o",
            page_icon="üìä",
            layout="wide"
        )
    except st.errors.StreamlitAPIException:
        pass
    render()